{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a prediction model for the final selling price of the auctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT REMARK:\n",
    "\n",
    "This code shall be executed from start to finish in the defined order. Errors may occur if the cells are executed in a different order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "    \n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, different prediction models to predict the final selling price of an auction before it starts have been built. The predictions are made with the intention that having an estimation of the final selling price of an auction could be very helpful for auction business owners (in this case Swoopo).\n",
    "\n",
    "Since the final selling price of an auction item is obtained by multiplying the bid price increment for that auction and the number of bids placed, and the bid price increment for an auction is known data, we are also indirectly predicting the number of bids placed for the auction. Swoopo's gain is obtained by multiplying the number of bids placed (predicted) and the bid fee (known data), and summing the result to the final price of the auction (predicted). Therefore, Swoopo's gain is also being indirectly predicted. Swoopo's profit would be calculated as the difference between the gain (predicted) and the retail price of the item (known data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>item</th>\n",
       "      <th>desc</th>\n",
       "      <th>retail</th>\n",
       "      <th>price</th>\n",
       "      <th>finalprice</th>\n",
       "      <th>bidincrement</th>\n",
       "      <th>bidfee</th>\n",
       "      <th>winner</th>\n",
       "      <th>...</th>\n",
       "      <th>freebids</th>\n",
       "      <th>endtime_str</th>\n",
       "      <th>flg_click_only</th>\n",
       "      <th>flg_beginnerauction</th>\n",
       "      <th>flg_fixedprice</th>\n",
       "      <th>flg_endprice</th>\n",
       "      <th>bids_placed</th>\n",
       "      <th>swoopo_sale_price</th>\n",
       "      <th>swoopo_profit</th>\n",
       "      <th>winner_benefit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86827</td>\n",
       "      <td>10009602</td>\n",
       "      <td>sony-ericsson-s500i-unlocked-mysterious-</td>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>499.99</td>\n",
       "      <td>13.35</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Racer11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-09-16 19:52:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>77.060489</td>\n",
       "      <td>-422.929511</td>\n",
       "      <td>467.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   auction_id  product_id                                      item  \\\n",
       "0       86827    10009602  sony-ericsson-s500i-unlocked-mysterious-   \n",
       "\n",
       "                                            desc  retail  price  finalprice  \\\n",
       "0  Sony Ericsson S500i Unlocked Mysterious Green  499.99  13.35       13.35   \n",
       "\n",
       "   bidincrement  bidfee   winner       ...        freebids  \\\n",
       "0          0.15    0.75  Racer11       ...               0   \n",
       "\n",
       "           endtime_str flg_click_only  flg_beginnerauction  flg_fixedprice  \\\n",
       "0  2008-09-16 19:52:00              0                    0               0   \n",
       "\n",
       "   flg_endprice  bids_placed  swoopo_sale_price  swoopo_profit  winner_benefit  \n",
       "0             0         89.0          77.060489    -422.929511          467.14  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomesDf = pd.read_csv('./outcomes_clean.tsv',sep='\\t')\n",
    "outcomesDf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns that are given as input for the prediction model are: \"retail\" (the retail price of the item), \"bidincrement\" (the bid increment), \"bidfee\" (the bid fee), and the flags that indicate whether the auction is a click-only auction, a beginner auction, a fixed-price auction or and end-price auction. \n",
    "\n",
    "The retail price of the item will clearly influence the final price that the auction reaches (in general, users will place more bids for more expensive items). The bid increment directly influences the final price that the auction reaches, because the last one is calculated by multiplying the bid increment and the number of bids placed in the auction. The bid fee will also influence the final price of the item, since users will be willing to place more bids if the bid fee is low, and placing more bids implies that the final price reached increases. The flags indicating the type of auction might have an influence for some users on whether they are willing to place more or less bids for the auction, so that is why they have been included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_column_names = [\"retail\",\"bidincrement\",\"bidfee\",\"flg_click_only\",\"flg_beginnerauction\",\"flg_fixedprice\",\"flg_endprice\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"auction_id\" (auction id) column has not been included as an input variable for the model because it is unique for each auction, and therefore, it does not provide any useful information for the predictions.\n",
    "\n",
    "The columns \"product_id\" (product id), \"desc\" (product description) and \"item\" have not been included as input for the model either. The product that is being sold (i.e., the product id) can certainly influence the final price that the auction reaches, but if we were to include this variable as input for the model, we would have to one-hot encode it, as it is expressed as a number, but there is no actual order defined for the values that it contains (a product with a larger product id than another one is not \"larger\" than that product. The number is just used as an identifier). If we were to include the other two columns (\"desc\", containing the product description, and \"item\", containing an item string associated to the product), they would also have to be one-hot encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, all of these columns contain many unique values. In the previous section, the item categories have been obtained from Amazon, and have been converted into a Word2Vec vector. The distances that these vectors define can be used to create clusters for the product categories that can be used as input for the prediction models rather than the other mentioned columns (which contain way too many different values, and the prediction model would not be able to generalize well if we used them as input variables to express diferences between the type of auctioned items)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2080\n",
      "1769\n",
      "1767\n"
     ]
    }
   ],
   "source": [
    "print(len(outcomesDf[\"product_id\"].unique()))\n",
    "print(len(outcomesDf[\"desc\"].unique()))\n",
    "print(len(outcomesDf[\"item\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns \"price\" and \"finalprice\" contain the final selling price reached for the auction (with a small difference between each other that will later be reminded), which is exactly what we want to predict, and therefore, they cannot be an input for the prediction model.\n",
    "\n",
    "The columns \"winner\" (winner of the auction) 'placedbids' (number of paid bids placed by the winnner of the auction), \"freebids\" (number of free bids placed by the winner of the auction) and \"endtime_str' (time in which the auction finished) contain information that is not known until the auction finishes, and therefore, they cannot be used as input for the model to predict the final selling price before the auction starts.\n",
    "\n",
    "The same thing happens with the other columns that were added in previous sections to the dataset: \"bids_placed\" (total number of bids placed for the auction), \"swoopo_sale_price\" (total gain obtained by Swoopo for the auction), \"swoopo_profit\" (total profit obtained by Swoopo for the auction, calculated as the gain obtained minus the retail price of the item), and \"winner_benefit\" (the difference between the money paid by the winner for the item and the retail price of the item). They cannot be used as input data for the model because they contain data that is not known at the beginning of the auction (and also, even if the data was known at the beginning of the auction, they have been calculated using the values of the other variables, so they could lead to multicollinearity problems if they were included in that case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns \"flg_fixedprice\" and \"flg_endprice\" indicate whether the auction is a fixed-price auction or and end-price auction. Fixed-price actions are auctions for which the final selling price of the item is set from the beginning. End-price auctions are auctions in which the final selling price of the item is zero independently of the bids that are placed, and the revenue for Swoopo comes exclusively from the bids that are placed).\n",
    "\n",
    "The column \"finalprice\" contains the real final selling price of the auction (that is, the fixed price for fixed-price auctions and zero for end-price auctions), while the \"price\" column contains the selling price of the auction calculated as the number of bids placed multiplied by the bid increment. Since the final selling price is already known from the beginning for fixed-price auctions and end-price auctions, and we are interested in knowing the gain that the auction provides for Swoopo, it has been chosen to predict the value in column \"price\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = outcomesDf[x_column_names]\n",
    "y = outcomesDf[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Single model - Without having into account the product categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first models that have been built do not take into account the product categories. The input variables for the model are: the retail price of the item, the bid increment, the bid fee, and the flags that indicate whether the auction is a click-only auction, a beginner auction, a fixed-price auction or and end-price auction.\n",
    "\n",
    "In order to be able to compare the results for different models, it has been chosen to develop the following ones: a random forest regressor, a k-neighbors regressor, a decision tree regressor, a linear regression and a RANSAC regressor.\n",
    "\n",
    "The dataset has been divided into different parts for the training and the testing phases, and 5-fold cross-validation has been applied so that the resulting quality metrics are more reliable.\n",
    "\n",
    "The metrics that have been calculated are the mean absolute error and the median absolute error. \n",
    "\n",
    "The mean absolute error gives an idea about the error that the model incurs in when performing final price predictions for individual auctions. Nevertheless, the final selling price of an auction depends on a lot of things: the users that are monitoring the auction, the amount of money that they have and their interests at the moment of the auction, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even when the item that is auctioned is the same one, the final price that is reached for each one of the auctions can be very different. As an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>13.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>19.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>47.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>55.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>86.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>48.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>113.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>75.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>35.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>19.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>36.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>41.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>123.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>49.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>63.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             desc   price\n",
       "0   Sony Ericsson S500i Unlocked Mysterious Green   13.35\n",
       "3   Sony Ericsson S500i Unlocked Mysterious Green   19.65\n",
       "4   Sony Ericsson S500i Unlocked Mysterious Green   47.10\n",
       "5   Sony Ericsson S500i Unlocked Mysterious Green   55.20\n",
       "6   Sony Ericsson S500i Unlocked Mysterious Green   86.10\n",
       "17  Sony Ericsson S500i Unlocked Mysterious Green   48.60\n",
       "18  Sony Ericsson S500i Unlocked Mysterious Green  113.10\n",
       "48  Sony Ericsson S500i Unlocked Mysterious Green   75.15\n",
       "49  Sony Ericsson S500i Unlocked Mysterious Green   35.10\n",
       "50  Sony Ericsson S500i Unlocked Mysterious Green   19.20\n",
       "53  Sony Ericsson S500i Unlocked Mysterious Green   36.60\n",
       "54  Sony Ericsson S500i Unlocked Mysterious Green   41.55\n",
       "55  Sony Ericsson S500i Unlocked Mysterious Green  123.75\n",
       "56  Sony Ericsson S500i Unlocked Mysterious Green   49.50\n",
       "57  Sony Ericsson S500i Unlocked Mysterious Green   63.75"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomesDf[outcomesDf[\"desc\"] == \"Sony Ericsson S500i Unlocked Mysterious Green\"][[\"desc\",\"price\"]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most extreme values could be considered outliers and be removed from the dataset so that they do not negatively influence the model. However, in this case, the extreme values are legitimate observations and they are most likely not incorrectly entered data. Therefore, instead of removing them, it has been decided to include some prediction models that are robust to outliers. For example, random forests and decision trees isolate atypical observations into small leaves, and the RANSAC algorithm provides a robust linear model estimation.\n",
    "\n",
    "Because of the high variance of the final selling price of the auctions, appart from the mean absolute error, it has also been decided to use the median absolute error as a metric. This metric is not be so highly influenced by extreme values. Making final selling price predictions can help Swoopo or similar businesses to have an estimation of the money that they will earn before a group of auctions start. However, we consider it more important to have an accurate estimation of groups of several auctions (for example, accurate weekly or monthly profit estimations, which can be calculated by using the estimations of the final price of the auctions included in those time periods), rather than accurate estimations for individual auctions, since Swoopo will profit of the total result of all of their auctions. Because of this reason, although the mean absolute error has been calculated, the median absolute error is considered to be a more appropiate metric in this case.\n",
    "\n",
    "The mean absolute percentage error (MAPE) has also been considered as a metric. Nevertheless, if a video game is predicted to reach a selling price of 20\\$, and the real selling price ends up being 30\\$,the MAPE would be 33%. However, if a laptop is predicted to reach a selling price of 700\\$ and the real selling price ends up being 800\\$, the MAPE is only 12.50%, but there is a prediction error of 100\\$ between the predicted price and the final price, which can have a higher impact in the business than the error in the video game prediction. For this reason, it has been decided not to use a metric that indicates a percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, in this section, the models that have been built do not take into account the product categories. The input variables for the models are: the retail price of the item, the bid increment, the bid fee, and the flags that indicate whether the auction is a click-only auction, a beginner auction, a fixed-price auction or and end-price auction.\n",
    "\n",
    "The following code is used to calculate the mean absolute error and the median absolute error (as the average of the results obtained for these two metrics over the 5 cross-validation folds) for the previously mentioned models. The results are analyzed after the lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "--\n",
      "Random Forest Regressor\n",
      "Median absolute error: 11.1752458141\n",
      "Mean absolute error: 29.3445832716\n",
      "--\n",
      "K Neighbors Regressor\n",
      "Median absolute error: 11.9772\n",
      "Mean absolute error: 31.8406889199\n",
      "--\n",
      "Decision Tree Regressor\n",
      "Median absolute error: 11.0515522817\n",
      "Mean absolute error: 29.7732089678\n",
      "--\n",
      "Linear Regression\n",
      "Median absolute error: 24.2493912238\n",
      "Mean absolute error: 42.0046659273\n",
      "--\n",
      "RANSAC Regressor\n",
      "Median absolute error: 10.4691486861\n",
      "Mean absolute error: 38.1582942494\n"
     ]
    }
   ],
   "source": [
    "kFoldMedianAbsoluteErrorsRandomForestRegressor = []\n",
    "kFoldMedianAbsoluteErrorsKNeighborsRegressor = []\n",
    "kFoldMedianAbsoluteErrorsDecisionTreeRegressor = []\n",
    "kFoldMedianAbsoluteErrorsLinearRegression = []\n",
    "kFoldMedianAbsoluteErrorsRANSACRegressor = []\n",
    "\n",
    "kFoldMeanAbsoluteErrorsRandomForestRegressor = []\n",
    "kFoldMeanAbsoluteErrorsKNeighborsRegressor = []\n",
    "kFoldMeanAbsoluteErrorsDecisionTreeRegressor = []\n",
    "kFoldMeanAbsoluteErrorsLinearRegression = []\n",
    "kFoldMeanAbsoluteErrorsRANSACRegressor = []\n",
    "\n",
    "kFoldNumber = 1\n",
    "kf = KFold(n_splits=5, random_state=1)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #5-fold cross-validation\n",
    "    print(\"Executing k fold = \"+str(kFoldNumber))\n",
    "    kFoldNumber=kFoldNumber+1\n",
    "    \n",
    "    #train and test split\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #RandomForestRegressor\n",
    "    model=RandomForestRegressor(random_state=1)\n",
    "    model.fit(X_train,y_train)\n",
    "    P_price = model.predict(X_test)\n",
    "    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsRandomForestRegressor.append(kFoldMedianAbsoluteError)    \n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsRandomForestRegressor.append(kFoldMeanAbsoluteError)  \n",
    "\n",
    "    #KNeighborsRegressor\n",
    "    model = KNeighborsRegressor()\n",
    "    model.fit(X_train,y_train)\n",
    "    P_price = model.predict(X_test)\n",
    "    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsKNeighborsRegressor.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsKNeighborsRegressor.append(kFoldMeanAbsoluteError)\n",
    "    \n",
    "    #DecisionTreeRegressor\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_train,y_train)\n",
    "    P_price = model.predict(X_test)\n",
    "    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsDecisionTreeRegressor.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsDecisionTreeRegressor.append(kFoldMeanAbsoluteError)\n",
    "    \n",
    "    #LinearRegression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    P_price = model.predict(X_test)\n",
    "    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsLinearRegression.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsLinearRegression.append(kFoldMeanAbsoluteError)\n",
    "    \n",
    "    #RANSACRegressor\n",
    "    model = RANSACRegressor(random_state=1)\n",
    "    model.fit(X_train,y_train)\n",
    "    P_price = model.predict(X_test)\n",
    "    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsRANSACRegressor.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsRANSACRegressor.append(kFoldMeanAbsoluteError)\n",
    "    \n",
    "medianAbsoluteErrorsRandomForestRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsRandomForestRegressor)\n",
    "meanAbsoluteErrorsRandomForestRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsRandomForestRegressor)\n",
    "medianAbsoluteErrorsKNeighborsRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsKNeighborsRegressor)\n",
    "meanAbsoluteErrorsKNeighborsRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsKNeighborsRegressor)\n",
    "medianAbsoluteErrorsDecisionTreeRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsDecisionTreeRegressor)\n",
    "meanAbsoluteErrorsDecisionTreeRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsDecisionTreeRegressor)\n",
    "medianAbsoluteErrorsLinearRegressionAverage = np.mean(kFoldMedianAbsoluteErrorsLinearRegression)\n",
    "meanAbsoluteErrorsLinearRegressionAverage = np.mean(kFoldMeanAbsoluteErrorsLinearRegression)\n",
    "medianAbsoluteErrorsRANSACRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsRANSACRegressor)\n",
    "meanAbsoluteErrorsRANSACRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsRANSACRegressor)\n",
    "\n",
    "print(\"--\")\n",
    "print(\"Random Forest Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsRandomForestRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsRandomForestRegressorAverage))\n",
    "print(\"--\")\n",
    "print(\"K Neighbors Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsKNeighborsRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsKNeighborsRegressorAverage))\n",
    "print(\"--\")\n",
    "print(\"Decision Tree Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsDecisionTreeRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsDecisionTreeRegressorAverage))\n",
    "print(\"--\")\n",
    "print(\"Linear Regression\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsLinearRegressionAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsLinearRegressionAverage))\n",
    "print(\"--\")\n",
    "print(\"RANSAC Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsRANSACRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsRANSACRegressorAverage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen above, the model with the best results in terms of the median absolute error is the RANSAC regressor. Nevertheless, its mean absolute error is much higher than for other models, which indicates that the deviation between individual prediction results and real results is higher than for other models. The decision tree regresor and the random forest regressor both present good results for the two metrics. The k-neighbors regressor performs alright, but worse than the other two. The worst results are obtained with the linear regression, probably because it is more sensitive to outliers than the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Single Model - Clustering by product categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second set of models that have into account the product categories have been built. As specified in previous sections, with the use of the product description available for each product in the column \"desc\" of the dataset, the Amazon product category has been obtained. A word embedding vector representing the product category has been calculated based on Google's pre-trained Word2Vec model. The distances defined by these vectors can be used to perform a distance-based clustering. For these models, a K-Means clustering has been used to group the products belonging to semantically similar categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind categorizing the products is that, if the final selling price of the items have similar patterns for similar products, a prediction model will perform better if a grouping based on the product categories is given as input. In this case, the input is the cluster identifier that each product belongs to. Since this is a categorical integer feature, a one-hot encoder has been used.\n",
    "\n",
    "Therefore, for this set of models, the input variables are: the retail price of the item, the bid increment, the bid fee, the flags that indicate the type of auction, and the one-hot encoded cluster identifier. The prediction models and the metrics are the same as in the previous part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to take into account for these set of models is that they require a preprocessing step that has to be performed both for the training data and the test data. This preprocessing step consists on, given the product description of an item in the column \"desc\", its Amazon category must be obtained, and afterwards, the corresponding word embedding vector.\n",
    "\n",
    "Also, the product category clustering must be performed with the training data. Each product appearing in the test data is then assigned one of the clusters obtained during the training part. The cluster that it is assigned to is the nearest one (according to the distance defined by the word embedding vector of the product appearing in the test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomesDf = pd.read_csv('./outcomes_clean.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following file contains the word embedding vectors associated to each product in the dataset that have been calculated in previous sections. If the prediction models were to be used in real life, a word embedding vector would have to be calculated for each new product following the procedure explained in previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "productDescriptionToVectorDf = pd.read_excel('./productDescriptionToVector.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is given as input a DataFrame that contains the cluster assigned to each product. The output of the function is the one-hot encoded version of the DataFrame given as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertCategoryDataFrameToOneHotEncodedVersion(clusteredCategoriesDf, categoryColumnName, trainClusterColumNames = None):\n",
    "    #categories assigned to each row of the DataFrame\n",
    "    categories = clusteredCategoriesDf[categoryColumnName]\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    categories = categories.values.reshape(len(categories), 1)\n",
    "    #One-Hot encoded version of the categories, where each column represents a category,\n",
    "    #and each row has the value \"1\" on the column of the category that it belongs to,\n",
    "    #and \"0\" on the other columns.\n",
    "    onehot_encoded = onehot_encoder.fit_transform(categories)\n",
    "    ncolumns = np.shape(onehot_encoded)[1]\n",
    "    #array that will contain the column names for the category clusters\n",
    "    clusterColumNames = ['cluster_']*ncolumns\n",
    "    for clusterNumber in np.arange(ncolumns):\n",
    "        #each column name is \"cluster_\" followed by the cluster number\n",
    "        clusterColumNames[clusterNumber] += str(clusterNumber)\n",
    "\n",
    "    #One-Hot Encoded DataFrame\n",
    "    clusteredCategoriesDfOneHotEnc = pd.DataFrame(onehot_encoded,columns=clusterColumNames)\n",
    "    \n",
    "    if trainClusterColumNames is not None:\n",
    "        #this function is called both in the training phase and the testing phase.\n",
    "        #For the training phase, trainClusterColumNames = None\n",
    "        #For the testing phase, trainClusterColumNames contains the column names\n",
    "        #of the One-Hot encoded DataFrame obtained during the training phase.\n",
    "        for trainColumnName in trainClusterColumNames:\n",
    "            if trainColumnName not in clusterColumNames:\n",
    "                #It may happen that a product category that appeared in the training phase\n",
    "                #does not appear in the testing phase. However, since the model is given \n",
    "                #the training One-Hot encoded DataFrame column values as input, it is necessary\n",
    "                #that the testing One-Hot encoded DataFrame contains the same columns\n",
    "                \n",
    "                #Therefore, if a category that appeared in the training phase does not\n",
    "                #appear in the testing phase, a column filled in with \"0\" for all rows\n",
    "                #is created.\n",
    "                clusteredCategoriesDfOneHotEnc[trainColumnName] = 0.0\n",
    "            \n",
    "    return clusteredCategoriesDfOneHotEnc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way as in the previous set of models, the following lines of code calculate the metrics associated to each one of the prediction models using 5-fold cross-validation.\n",
    "\n",
    "During the training part, the K-Means algorithm is used to obtain clusters for the word embedding vectors. \n",
    "\n",
    "The dataset contains several auctions in which the same item was auctioned. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>item</th>\n",
       "      <th>desc</th>\n",
       "      <th>retail</th>\n",
       "      <th>price</th>\n",
       "      <th>finalprice</th>\n",
       "      <th>bidincrement</th>\n",
       "      <th>bidfee</th>\n",
       "      <th>winner</th>\n",
       "      <th>...</th>\n",
       "      <th>freebids</th>\n",
       "      <th>endtime_str</th>\n",
       "      <th>flg_click_only</th>\n",
       "      <th>flg_beginnerauction</th>\n",
       "      <th>flg_fixedprice</th>\n",
       "      <th>flg_endprice</th>\n",
       "      <th>bids_placed</th>\n",
       "      <th>swoopo_sale_price</th>\n",
       "      <th>swoopo_profit</th>\n",
       "      <th>winner_benefit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86827</td>\n",
       "      <td>10009602</td>\n",
       "      <td>sony-ericsson-s500i-unlocked-mysterious-</td>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>499.99</td>\n",
       "      <td>13.35</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Racer11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-09-16 19:52:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>77.060489</td>\n",
       "      <td>-422.929511</td>\n",
       "      <td>467.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88638</td>\n",
       "      <td>10006115</td>\n",
       "      <td>sony-ericsson-s500i-unlocked-mysterious-</td>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>499.99</td>\n",
       "      <td>19.65</td>\n",
       "      <td>19.65</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Mokkis</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-23 22:02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>113.426113</td>\n",
       "      <td>-386.563887</td>\n",
       "      <td>472.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88639</td>\n",
       "      <td>10006115</td>\n",
       "      <td>sony-ericsson-s500i-unlocked-mysterious-</td>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>499.99</td>\n",
       "      <td>47.10</td>\n",
       "      <td>47.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Superloeffel</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-24 14:23:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>271.876331</td>\n",
       "      <td>-228.113669</td>\n",
       "      <td>392.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88693</td>\n",
       "      <td>10008975</td>\n",
       "      <td>sony-ericsson-s500i-unlocked-mysterious-</td>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>499.99</td>\n",
       "      <td>55.20</td>\n",
       "      <td>55.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Danydemir80</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2008-08-22 22:44:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>318.632133</td>\n",
       "      <td>-181.357867</td>\n",
       "      <td>444.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>88694</td>\n",
       "      <td>10008975</td>\n",
       "      <td>sony-ericsson-s500i-unlocked-mysterious-</td>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>499.99</td>\n",
       "      <td>86.10</td>\n",
       "      <td>86.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Destination8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-24 07:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>496.996860</td>\n",
       "      <td>-2.993140</td>\n",
       "      <td>371.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>90526</td>\n",
       "      <td>10009642</td>\n",
       "      <td>sony-ericsson-s500i-unlocked-mysterious-</td>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>499.99</td>\n",
       "      <td>48.60</td>\n",
       "      <td>48.60</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Wadenbeisser</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-09-02 00:06:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>280.534813</td>\n",
       "      <td>-219.455187</td>\n",
       "      <td>431.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>90527</td>\n",
       "      <td>10009642</td>\n",
       "      <td>sony-ericsson-s500i-unlocked-mysterious-</td>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>499.99</td>\n",
       "      <td>113.10</td>\n",
       "      <td>113.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Vonluxburg</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-09-04 02:27:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>652.849533</td>\n",
       "      <td>152.859533</td>\n",
       "      <td>172.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>92708</td>\n",
       "      <td>10009642</td>\n",
       "      <td>sony-ericsson-s500i-unlocked-mysterious-</td>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>499.99</td>\n",
       "      <td>75.15</td>\n",
       "      <td>75.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>pauli55</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-25 15:12:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>433.789942</td>\n",
       "      <td>-66.200058</td>\n",
       "      <td>290.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>92709</td>\n",
       "      <td>10009642</td>\n",
       "      <td>sony-ericsson-s500i-unlocked-mysterious-</td>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>499.99</td>\n",
       "      <td>35.10</td>\n",
       "      <td>35.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Voovoo3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-09-05 22:33:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>202.608476</td>\n",
       "      <td>-297.381524</td>\n",
       "      <td>459.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>92723</td>\n",
       "      <td>10009602</td>\n",
       "      <td>sony-ericsson-s500i-unlocked-mysterious-</td>\n",
       "      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n",
       "      <td>499.99</td>\n",
       "      <td>19.20</td>\n",
       "      <td>19.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>barrakuda</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-09-20 18:35:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>110.828568</td>\n",
       "      <td>-389.161432</td>\n",
       "      <td>444.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    auction_id  product_id                                      item  \\\n",
       "0        86827    10009602  sony-ericsson-s500i-unlocked-mysterious-   \n",
       "3        88638    10006115  sony-ericsson-s500i-unlocked-mysterious-   \n",
       "4        88639    10006115  sony-ericsson-s500i-unlocked-mysterious-   \n",
       "5        88693    10008975  sony-ericsson-s500i-unlocked-mysterious-   \n",
       "6        88694    10008975  sony-ericsson-s500i-unlocked-mysterious-   \n",
       "17       90526    10009642  sony-ericsson-s500i-unlocked-mysterious-   \n",
       "18       90527    10009642  sony-ericsson-s500i-unlocked-mysterious-   \n",
       "48       92708    10009642  sony-ericsson-s500i-unlocked-mysterious-   \n",
       "49       92709    10009642  sony-ericsson-s500i-unlocked-mysterious-   \n",
       "50       92723    10009602  sony-ericsson-s500i-unlocked-mysterious-   \n",
       "\n",
       "                                             desc  retail   price  finalprice  \\\n",
       "0   Sony Ericsson S500i Unlocked Mysterious Green  499.99   13.35       13.35   \n",
       "3   Sony Ericsson S500i Unlocked Mysterious Green  499.99   19.65       19.65   \n",
       "4   Sony Ericsson S500i Unlocked Mysterious Green  499.99   47.10       47.10   \n",
       "5   Sony Ericsson S500i Unlocked Mysterious Green  499.99   55.20       55.20   \n",
       "6   Sony Ericsson S500i Unlocked Mysterious Green  499.99   86.10       86.10   \n",
       "17  Sony Ericsson S500i Unlocked Mysterious Green  499.99   48.60       48.60   \n",
       "18  Sony Ericsson S500i Unlocked Mysterious Green  499.99  113.10      113.10   \n",
       "48  Sony Ericsson S500i Unlocked Mysterious Green  499.99   75.15       75.15   \n",
       "49  Sony Ericsson S500i Unlocked Mysterious Green  499.99   35.10       35.10   \n",
       "50  Sony Ericsson S500i Unlocked Mysterious Green  499.99   19.20       19.20   \n",
       "\n",
       "    bidincrement  bidfee        winner       ...        freebids  \\\n",
       "0           0.15    0.75       Racer11       ...               0   \n",
       "3           0.15    0.75        Mokkis       ...               0   \n",
       "4           0.15    0.75  Superloeffel       ...               0   \n",
       "5           0.15    0.75   Danydemir80       ...              13   \n",
       "6           0.15    0.75  Destination8       ...               0   \n",
       "17          0.15    0.75  Wadenbeisser       ...               0   \n",
       "18          0.15    0.75    Vonluxburg       ...               0   \n",
       "48          0.15    0.75       pauli55       ...               0   \n",
       "49          0.15    0.75       Voovoo3       ...               0   \n",
       "50          0.15    0.75     barrakuda       ...               0   \n",
       "\n",
       "            endtime_str flg_click_only  flg_beginnerauction  flg_fixedprice  \\\n",
       "0   2008-09-16 19:52:00              0                    0               0   \n",
       "3   2008-08-23 22:02:00              0                    0               0   \n",
       "4   2008-08-24 14:23:00              0                    0               0   \n",
       "5   2008-08-22 22:44:00              0                    0               0   \n",
       "6   2008-08-24 07:10:00              0                    0               0   \n",
       "17  2008-09-02 00:06:00              0                    0               0   \n",
       "18  2008-09-04 02:27:00              0                    0               0   \n",
       "48  2008-08-25 15:12:00              0                    0               0   \n",
       "49  2008-09-05 22:33:00              0                    0               0   \n",
       "50  2008-09-20 18:35:00              0                    0               0   \n",
       "\n",
       "    flg_endprice  bids_placed  swoopo_sale_price  swoopo_profit  \\\n",
       "0              0         89.0          77.060489    -422.929511   \n",
       "3              0        131.0         113.426113    -386.563887   \n",
       "4              0        314.0         271.876331    -228.113669   \n",
       "5              0        368.0         318.632133    -181.357867   \n",
       "6              0        574.0         496.996860      -2.993140   \n",
       "17             0        324.0         280.534813    -219.455187   \n",
       "18             0        754.0         652.849533     152.859533   \n",
       "48             0        501.0         433.789942     -66.200058   \n",
       "49             0        234.0         202.608476    -297.381524   \n",
       "50             0        128.0         110.828568    -389.161432   \n",
       "\n",
       "    winner_benefit  \n",
       "0           467.14  \n",
       "3           472.84  \n",
       "4           392.89  \n",
       "5           444.79  \n",
       "6           371.14  \n",
       "17          431.89  \n",
       "18          172.39  \n",
       "48          290.59  \n",
       "49          459.64  \n",
       "50          444.04  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomesDf[outcomesDf[\"desc\"] == \"Sony Ericsson S500i Unlocked Mysterious Green\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the item that is auctioned is the same in these cases, the description of the item (and so, its word embedding vector) is the same. In each iteration, the K-Means algorithm assigns every data point to the nearest centroid. Replication of data points (the word embedding vectors in this case) influences the centroids of the clusters.\n",
    "\n",
    "The objective of this clustering is to provide the prediction model with a grouping of the items according to their categories, so that it is easier for the model to find a pattern (if it exists) within products belonging to the same category. Duplicated items have been removed from the input data given to the clustering algorithm so that each different product has the same weight for the product category clustering.\n",
    "\n",
    "The duplicated items have instead not been removed from the input data given to the prediction algorithms, so that the weight of the evidence is higher on cases of duplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once that each different item has been assigned a cluster, a DataFrame containing the product description and the corresponding cluster number is created. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cat_cluster                                               desc\n",
      "0               2      Sony Ericsson S500i Unlocked Mysterious Green\n",
      "3               2                     LG KU990 Viewty Unlocked Black\n",
      "10              2                         Sony Ericsson P1i Unlocked\n",
      "11              2          LG Electronics KE850 Prada Unlocked Black\n",
      "12              2                      Nokia N95 8 GB Unlocked Black\n",
      "53              2                 Sony Ericsson W910i Unlocked Black\n",
      "76              2     Philips SE7452B Advanced Cordless Phone System\n",
      "79              2                                    Nokia N78 black\n",
      "93              2                             Samsung SGH-i900 OMNIA\n",
      "94              2                               Nokia 7310 supernova\n",
      "95              2                                LG KM380 - unlocked\n",
      "187             2         Panasonic KX-TG9332T Cordless Phone System\n",
      "188             2         Panasonic KX-TG9342T Cordless Phone System\n",
      "191             2         Panasonic KX-TG8232B Cordless Phone System\n",
      "210             2                           LG KE770 Unlocked Silver\n",
      "225             2       Sony Ericsson W760i Intense Black (Unlocked)\n",
      "228             2             Samsung SGH-U800 Soul B Unlocked Phone\n",
      "230             2                      Nokia E65 Unlocked Smartphone\n",
      "269             2        Nokia N96 16 GB Unlocked Cell Phone (Black)\n",
      "276             2               Motorola ROKR E6 Unlocked Cell Phone\n",
      "282             2       Siemens S450 DECT 6.0 Digital Cordless Phone\n",
      "349             2     Philips SE7452B Advanced Cordless Phone System\n",
      "354             2            Sony Ericsson W880i Unlocked Cell Phone\n",
      "356             2  Philips CD1502B/17 Cordless Phones & Answer Sy...\n",
      "398             2          Motorola MOTOZINE ZN5 Unlocked Cell Phone\n",
      "407             2      Sony Ericsson XPERIA X1 Cell Phone - Unlocked\n",
      "463             2              Sony Ericsson C905 - Black (Unlocked)\n",
      "493             2                 Pharos PTL600 GPS Phone (Unlocked)\n",
      "534             2                     Nokia 6300 Unlocked Cell Phone\n",
      "577             2                     LG KC910 Renoir (Black-Silver)\n",
      "...           ...                                                ...\n",
      "1298            2              HTC Snap S521 Unlocked Cellular Phone\n",
      "1299            2     Samsung i900 Omnia Unlocked Phone 16 GB Memory\n",
      "1339            2          Iqua BHS-603 Sun Bluetooth Stereo Headset\n",
      "1342            2               Samsung M7600 Beat DJ Cellular Phone\n",
      "1353            2             Samsung I8510 16GB Cell Phone Unlocked\n",
      "1356            2      HTC Touch Cruise 09 T4242 Unlocked Smartphone\n",
      "1359            2                           Nokia N97 Unlocked Phone\n",
      "1360            2       Motorola Aura Silver Unlocked Cellular Phone\n",
      "1380            2                     HTC Touch Pro 2 Unlocked Phone\n",
      "1395            2                    Jawbone Prime Bluetooth Headset\n",
      "1397            2             Siemens Gigaset Digital Cordless Phone\n",
      "1398            2              Nokia 5800 XpressMusic Unlocked Phone\n",
      "1465            2             HTC Hero White Unlocked Cellular Phone\n",
      "1496            2         Samsung i8910 Omnia HD Unlocked Cell Phone\n",
      "1497            2                     LG KP500 Cookie Unlocked Phone\n",
      "1498            2           Blackberry Tour 9630 Unlocked Cell Phone\n",
      "1553            2     Vtech DECT 6.0 3-Handset Cordless Phone System\n",
      "1555            2                            Plantronics Voyager 510\n",
      "1600            2                     Nokia N900 Unlocked Cell Phone\n",
      "1617            2                LG GC900 Viewty unlocked Smartphone\n",
      "1649            2          Blackberry Curve 8520 Unlocked Cell Phone\n",
      "1675            2       BlackBerry Storm 2 9550 Odin Unlocked  Phone\n",
      "1691            2                        Motorola DROID Mobile Phone\n",
      "1700            2                               Nokia N97 + 150 Bids\n",
      "1732            2             Philips DECT 6.0 Enhanced Phone System\n",
      "1743            2              Apple iPhone 3GS 32GB Black+ 150 Bids\n",
      "1744            2         Apple iPhone 3GS 32GB Black + 150 FreeBids\n",
      "1746            2   BlackBerry Bold 2 9700 Black Unlocked Cell Phone\n",
      "1748            2        Sony Ericsson U1i Satio Idou Unlocked Phone\n",
      "1767            2         Apple iPhone 3GS 32GB Black + 200 FreeBids\n",
      "\n",
      "[108 rows x 2 columns]\n",
      "      cat_cluster                                              desc\n",
      "1               0                  PSP Slim & Lite Sony Piano Black\n",
      "7               0              Mario Kart with Wheel (Nintendo Wii)\n",
      "8               0         PS3 | Playstation 3 Sony Console 40GB HDD\n",
      "9               0                       DS | Nintendo DS Lite White\n",
      "16              0            Super Smash Bros. Brawl (Nintendo Wii)\n",
      "17              0                       DS | Nintendo DS Lite Black\n",
      "22              0       Microsoft Xbox 360 Deluxe Bundle + Forza  2\n",
      "23              0                      DS | Nintendo DS Lite (pink)\n",
      "24              0               Wii | Nintendo Console + Wii Sports\n",
      "26              0     DS | Nintendo DS Lite (Crimson Red and Black)\n",
      "27              0     DS | Nintendo DS Lite (Cobalt Blue and Black)\n",
      "28              0                Guitar Hero: On Tour (Nintendo DS)\n",
      "83              0                          Sony PlayStation 3 80 GB\n",
      "91              0                 Lego Indiana Jones (Nintendo Wii)\n",
      "112             0             Microsoft Xbox 360 console 60 GB HDMI\n",
      "148             0                   Rock Band Special Edition (PS3)\n",
      "149             0               Battlefield: Bad Company (Xbox 360)\n",
      "150             0                    Battlefield: Bad Company (PS3)\n",
      "151             0                        Deca Sports (Nintendo Wii)\n",
      "152             0                         Monster Jam (Nintendo DS)\n",
      "153             0                  Dragon Ball Z: Burst Limit (PS3)\n",
      "154             0                         Grand Theft Auto IV (PS3)\n",
      "155             0                         Top Spin 3 (Nintendo Wii)\n",
      "156             0                     Gran Turismo 5 Prologue (PS3)\n",
      "158             0                             Top Spin 3 (Xbox 360)\n",
      "159             0                     My French Coach (Nintendo DS)\n",
      "161             0  Mario & Sonic at the Olympic Games (Nintendo DS)\n",
      "162             0                 Lego: Indiana Jones (Nintendo DS)\n",
      "163             0    Metal Gear Solid 4: Guns of the Patriots (PS3)\n",
      "164             0                                  Top Spin 3 (PS3)\n",
      "...           ...                                               ...\n",
      "1647            0              Call of Duty: Modern Warfare 2 (PS3)\n",
      "1648            0         Call of Duty: Modern Warfare 2 (Xbox 360)\n",
      "1652            0           Call of Duty: Modern Warfare 2 (PC DVD)\n",
      "1657            0                               Tekken 6 (Xbox 360)\n",
      "1658            0                                    Tekken 6 (PS3)\n",
      "1659            0              Tekken 6 Fighting Stick Bundle (PS3)\n",
      "1660            0         Tekken 6 Fighting Stick Bundle (XBOX 360)\n",
      "1662            0             PS3 Modern Warfare 2 Wireless Headset\n",
      "1663            0     Xbox 360 Modern Warfare 2 Throat Communicator\n",
      "1667            0  Star Wars: The Clone Wars - Republic Heroes (PC)\n",
      "1668            0                           CSI: Deadly Intent (PC)\n",
      "1673            0                             Football Manager 2010\n",
      "1674            0                          Dragon Age: Origins (PC)\n",
      "1680            0   Playstation 3 160 GB Uncharted: Drake's Fortune\n",
      "1681            0                       Tony Hawk - Ride (XBox 360)\n",
      "1682            0                              Tony Hawk Ride (Wii)\n",
      "1683            0                              Tony Hawk Ride (PS3)\n",
      "1684            0       Xbox 360 Modern Warfare 2 Combat Controller\n",
      "1685            0   PS3 Modern Warfare 2 Wireless Combat Controller\n",
      "1687            0        Black Wii Remote with Black Wii MotionPlus\n",
      "1697            0           Sony PlayStation 3 Slim 120GB + 50 Bids\n",
      "1701            0           Sony PS3 160GB with Uncharted + 50 Bids\n",
      "1713            0                                          Dominion\n",
      "1720            0                                      EyePet (PS3)\n",
      "1738            0           Sony PlayStation 3 Slim 250GB + 50 Bids\n",
      "1739            0       Sony PlayStation 3 Slim 250GB + 50 FreeBids\n",
      "1740            0                    New Super Mario Brothers (Wii)\n",
      "1747            0                                  Borderlands (PC)\n",
      "1750            0                       God of War Collection (PS3)\n",
      "1759            0       Sony PS3 160GB with Uncharted + 50 FreeBids\n",
      "\n",
      "[319 rows x 2 columns]\n",
      "      cat_cluster                                               desc\n",
      "2               4         iPod Touch Apple 8GB with Software Upgrade\n",
      "18              4              Apple iPod Shuffle 2GB Silver 2nd Gen\n",
      "19              4       Canon Digital Rebel XSi + 18-55mm Lens Black\n",
      "20              4              Apple iPod Shuffle 1GB Silver 2nd Gen\n",
      "21              4          Toshiba Regza 37RV530U 37\" 1080p LCD HDTV\n",
      "25              4                Samsung PN50A450 50\" HDTV Plasma TV\n",
      "30              4                Samsung PN42A450 42\" HDTV Plasma TV\n",
      "31              4           Philips 42PFL5603D/27 42\" 1080p LCD HDTV\n",
      "32              4     Panasonic Viera TH-42PX80 42\" 720p Plasma HDTV\n",
      "33              4                        Casio Exilim EX-Z100 Silver\n",
      "50              4                Samsung LN37A550 37\" 1080p LCD HDTV\n",
      "63              4      Vtech Kidizoom Multimedia Digital Camera Blue\n",
      "84              4          Toshiba Regza 40XF550U 40\" 1080p LCD HDTV\n",
      "86              4          Toshiba Regza 42RV530U 42\" 1080p LCD HDTV\n",
      "87              4         Sony Bravia KDL-40S4100 40\" 1080p LCD HDTV\n",
      "88              4                Philips PFL5603D 42\" 1080p LCD HDTV\n",
      "89              4                       Casio Exilim EX-Z1080 Silver\n",
      "90              4      Panasonic Viera TC-37LZ800 37\" 1080p LCD HDTV\n",
      "132             4                               Nero 8 Ultra Edition\n",
      "143             4     Creative Zen V Plus 2 GB Portable Media Player\n",
      "145             4         Sony KDL-26M4000/T 26\" 720p LCD HDTV Brown\n",
      "146             4             Sony Cybershot DSC-W300 Digital Camera\n",
      "184             4          Samsung T220HD 22\" 1080p LCD HDTV Monitor\n",
      "197             4          Toshiba Regza 32RV530U 32\" 1080p LCD HDTV\n",
      "198             4       Panasonic SC-PT960 5 DVD Home Theater System\n",
      "199             4             Apple iPod touch 8 GB (new generation)\n",
      "206             4      Samsung LN40A650 40-Inch 1080p 120Hz LCD HDTV\n",
      "207             4     Philips 42PFL7403D/27 42\" 1080p 120Hz LCD HDTV\n",
      "208             4              Samsung PN50A450 50\" 720p Plasma HDTV\n",
      "209             4   Panasonic Viera TH-42PZ85U 42\" 1080p Plasma HDTV\n",
      "...           ...                                                ...\n",
      "1612            4        Apple iPod nano 8 GB Black (5th Generation)\n",
      "1613            4  Epson PowerLite  720p 3LCD Home Theater Projector\n",
      "1614            4  Nikon Coolpix S1000PJ 12MP Digital Camera (Black)\n",
      "1615            4  SanDisk Sansa Fuze 8GB Flash Portable Media Pl...\n",
      "1616            4                 Haier HLT71 7-Inch Portable LCD TV\n",
      "1623            4     VTech Kidizoom: Multimedia Digital Camera Pink\n",
      "1627            4          Samsung PN42B450 42-Inch 720p Plasma HDTV\n",
      "1656            4           Sony Alpha DSLR-A550L Digital SLR Camera\n",
      "1661            4           Nikon Coolpix P90 12.1 MP Digital Camera\n",
      "1686            4            Samsung LN37B550 37-Inch 1080p LCD HDTV\n",
      "1696            4   Canon EOS Rebel T1i with 18-55mm lens + 150 Bids\n",
      "1698            4             Nikon D90 with 18-105mm Kit + 150 Bids\n",
      "1718            4             Samsung LN26B460 26-Inch 720p LCD HDTV\n",
      "1719            4                  Sony BDVE500W Home theater System\n",
      "1721            4           iHome iP9SR Clock Radio for iPod, iPhone\n",
      "1722            4     Panasonic Lumix DMC-FZ35 12.1MP Digital Camera\n",
      "1724            4  Sony Cyber-shot DSC-W290  Digital Camera (Silver)\n",
      "1728            4       Philips 47PFL5603D/27 47-Inch 1080p LCD HDTV\n",
      "1729            4             LG 42SL80 42-Inch 240Hz 1080p LCD HDTV\n",
      "1730            4                      Archos Clipper 2GB MP3 Player\n",
      "1736            4       Canon EOS Rebel T1i + 18-55mm + 150 FreeBids\n",
      "1737            4         Nikon D90 with 18-105mm Kit + 150 FreeBids\n",
      "1745            4         Samsung BD-P4600 1080p Blu-ray Disc Player\n",
      "1749            4          Pioneer BDP-320 1080p Blu-ray Disc Player\n",
      "1760            4  Onkyo HT-S9100THX 7.1 Channel Receiver and Spe...\n",
      "1761            4            Philips AJL303 3.5-Inch LCD Clock Radio\n",
      "1763            4         Samsung PN50B860 50-Inch 1080p Plasma HDTV\n",
      "1764            4        JVC PICSIO GC-FM1A HD Camcorder (Black Ice)\n",
      "1765            4                      Philips 32PFL6704D 32\" LCD TV\n",
      "1768            4              Western Digital WD TV HD Media Player\n",
      "\n",
      "[314 rows x 2 columns]\n",
      "      cat_cluster                                               desc\n",
      "4               3          Logitech Cordless Wave Keyboard and Mouse\n",
      "5               3       Apple Macbook Air 1.6GHz Core 2 Duo Notebook\n",
      "6               3                         SanDisk Cruzer Contour 4GB\n",
      "13              3    Acer Aspire AS6920-6508 16\" Core 2 Duo Notebook\n",
      "14              3                Corsair Voyager Mini 4 GB USB Flash\n",
      "15              3                           Asus Eee PC 900 XP White\n",
      "29              3                        TomTom Go 730 GPS Navigator\n",
      "52              3                   Apple iMac 20\" Core 2 Duo 2.4GHz\n",
      "54              3       Sony VAIO VGN-AR610E 17\" Core 2 Duo Notebook\n",
      "55              3    HP Pavilion Elite M9150F Core 2 Quad Desktop PC\n",
      "56              3                       Asus Eee PC 900 XP Black 12G\n",
      "57              3     Acer Aspire One A110L 8.9\" Mini Notebook White\n",
      "58              3       Toshiba Satellite A305D-S6851 15.4\" Notebook\n",
      "59              3                           Asus Eee PC 900 XP Black\n",
      "61              3     Sony VAIO VGN-AR720E/B 17\" Core 2 Duo Notebook\n",
      "77              3                              Asus Eee PC 901 black\n",
      "78              3                              Asus Eee PC 901 white\n",
      "80              3                    Logitech LX3 Optical Mouse Blue\n",
      "81              3                                     TomTom Go 930T\n",
      "82              3  Toshiba Qosmio G55-Q801 18.4\" Core 2 Duo Notebook\n",
      "85              3                     Kingston 8 GB SDHC Memory Card\n",
      "92              3    Garmin Nuvi 770 4.3-Inch Portable GPS Navigator\n",
      "113             3   Western Digital My Passport Elite 320GB Titanium\n",
      "114             3                   Canon PIXMA iP3500 Photo Printer\n",
      "115             3        Canon Pixma MX300 All-in-one Inkjet Printer\n",
      "116             3     HP Pavilion DV6880SE 15.4\" Core 2 Duo Notebook\n",
      "117             3   Maxtor OneTouch 4 Lite 500GB External Hard Drive\n",
      "118             3        Epson Stylus Photo RX595 All-in-One Printer\n",
      "119             3              D-Link Wireless N Rangebooster Router\n",
      "120             3    Garmin nÃ¼vi 250 3.5-Inch Portable GPS Navigator\n",
      "...           ...                                                ...\n",
      "1596            3                         Logitech MX Anywhere Mouse\n",
      "1597            3           Microsoft Natural Ergonomic Desktop 7000\n",
      "1598            3  Canon PIXMA MP640 Inkjet Photo All-In-One Printer\n",
      "1601            3                          HP LP2065 20\" TFT Monitor\n",
      "1618            3        HP TouchSmart 600 Series 23-Inch Desktop PC\n",
      "1628            3           Apple MacBook MC207LL/A 13.3-Inch Laptop\n",
      "1629            3                   Apple Mac mini MC238LL/A Desktop\n",
      "1650            3                         Zotac IONITX-A-U Atom N330\n",
      "1651            3        Acer Aspire Timeline 11.6-Inch Black Laptop\n",
      "1653            3       ASUS Eee PC 1101HA-MU1X-BK 11.6-Inch Netbook\n",
      "1654            3           Sony VAIO VGN-NW280F/B 15.5-Inch  Laptop\n",
      "1655            3                     Kindle Wireless Reading Device\n",
      "1664            3       HP Pavilion Slimline S5220F Black Desktop PC\n",
      "1665            3                 HP Pavilion dv6-1360us Notebook PC\n",
      "1666            3       ASUS K50IJ-X8 15.6-Inch Entertainment Laptop\n",
      "1676            3            HP Pavilion DM3 Series 13.3-Inch Laptop\n",
      "1677            3                       Samsung Go N310-13GB Netbook\n",
      "1678            3    HP TouchSmart TX2-1370US 12.1-Inch Black Laptop\n",
      "1692            3        Call of Duty: Modern Warfare 2 Sniper Mouse\n",
      "1693            3       ASUS Eee Top 21.6-Inch All-in-One Desktop PC\n",
      "1694            3        Sony VAIO VGN-SR510 Series 13.3-Inch Laptop\n",
      "1695            3      HP Pavilion dv4-2040us Entertainment Notebook\n",
      "1699            3                 Apple MacBook Pro 13.3\" + 200 Bids\n",
      "1723            3               Kingston flash memory card 8 GB SDHC\n",
      "1725            3   Garmin nÃ¼vi 765T 4.3-Inch Portable GPS Navigator\n",
      "1726            3      Sony VAIO VPC-L113FX/B 24-Inch All-in-One  PC\n",
      "1727            3    HP TouchSmart 600-1055 23-Inch Black Desktop PC\n",
      "1742            3             Apple MacBook Pro 13.3\" + 200 FreeBids\n",
      "1762            3              ASUS UL50VT-A1 15.6-Inch Black Laptop\n",
      "1766            3      Samsung SyncMaster P2570 24-inch  LCD Monitor\n",
      "\n",
      "[387 rows x 2 columns]\n",
      "      cat_cluster                                               desc\n",
      "34              6                                          $80 Cash!\n",
      "35              6                                       $1,000 Cash!\n",
      "36              6                                50 FreeBids Voucher\n",
      "37              6                               300 FreeBids Voucher\n",
      "38              6                    Oster 4207 Electric Wine Opener\n",
      "39              6     Philips Norelco BG2022 Silver Bodygroom Shaver\n",
      "42              6                      Lego City Fire Station (7945)\n",
      "43              6                 Vtech - V.Smile TV Learning System\n",
      "45              6                    LEGO Starwars Sandcrawler 10144\n",
      "46              6             LEGO City 7743 - Police Command Center\n",
      "47              6                 Fisher-Price Bounce and Spin Zebra\n",
      "48              6  Spinmaster Air Hogs Battling Havoc R/C Helicop...\n",
      "49              6                                         $320 Cash!\n",
      "51              6                Lego City Police Pontoon Plane 7723\n",
      "60              6      Calvin Klein Eternity For Men 3.4oz edt Spray\n",
      "62              6           Nino Cerruti 1881 Womens 3.3oz edt Spray\n",
      "64              6       Braun Silk-Epil 7781 Xpressive Body Epilator\n",
      "66              6          Philips Norelco Arcitec 1090 Men's Shaver\n",
      "68              6         Braun PocketGo 370 Battery Operated Shaver\n",
      "69              6  Malibu Solar Resin Rock Flood Landscape LED Light\n",
      "71              6      Philips Norelco 8160XLCC Speed XL Shaving Set\n",
      "72              6                 Braun 5885 Contour Electric Shaver\n",
      "73              6    Calvin Klein CK One 6.7oz Eau De Toilette Spray\n",
      "96              6                     Lego City 7944 Fire Hovercraft\n",
      "97              6     Skil 2352-01 3.6 Volt Lithium-Ion Multi-Cutter\n",
      "98              6  Dolce & Gabbana Light Blue 1.7oz Women's edt S...\n",
      "99              6              Nina Ricci L'Air du Temps EdT box set\n",
      "100             6                 Davidoff Echo Mens 1.7oz edt Spray\n",
      "101             6                      Deep Red by Hugo Boss box set\n",
      "102             6  Vtech - Winnie the Pooh - Pooh's Picture Computer\n",
      "...           ...                                                ...\n",
      "1506            6  Philips Sonicare FlexCare Rechargeable Toothbrush\n",
      "1515            6                             LEGO DUPLO Castle 4864\n",
      "1564            6       DEWALT Cordless 18-Volt Compact Drill/Driver\n",
      "1608            6   ION Audio iCUE MP3 Computer Music Mixing Station\n",
      "1619            6                      Toy Story Collection RC Buggy\n",
      "1620            6    Carrera USA Digital 132, GT Racers Race Car Set\n",
      "1621            6  Carrera Evolution Winner's Challenge Slot Car Set\n",
      "1622            6               Fisher-Price Imaginext Ultimate Dino\n",
      "1624            6            Transformers Movie 2 Ultimate Bumblebee\n",
      "1625            6                                     V.Smile Motion\n",
      "1626            6        Carrera Digital 143 Double Police Chase Set\n",
      "1630            6      Fisher-Price Grand Central Rail & Road System\n",
      "1631            6                                     Blue PlasmaCar\n",
      "1632            6                          Schoenhut Junior Drum Set\n",
      "1633            6       1:16 Scale Hobby Grade R/C Mercedes Benz SLR\n",
      "1669            6              LEGO Duplo Legoville Deluxe Train Set\n",
      "1670            6                   LEGO Racers Lamborghini Gallardo\n",
      "1671            6            MGA Zapf Baby Born Doll with Potty Pink\n",
      "1672            6                   Fisher Price Smart Cycle Extreme\n",
      "1709            6     DEWALT XRP Hammerdrill/Impact Driver Combo Kit\n",
      "1710            6             Calphalon LX Series 15-Piece Knife Set\n",
      "1711            6                              Carrera Go Mario Kart\n",
      "1712            6  Fisher-Price GeoTrax System Remote Control Rai...\n",
      "1714            6                                  LEGO DUPLO Castle\n",
      "1715            6                           LEGO Creator Fire Rescue\n",
      "1716            6       LeapFrog Zippity High-Energy Learning System\n",
      "1731            6            Panasonic ES-LA93-K Vortex Men's Shaver\n",
      "1741            6              LEGO Indiana Jones Venice Canal Chase\n",
      "1756            6           Air Hogs Laser Micro Zero Gravity - Blue\n",
      "1758            6                Escali High-Capacity Bathroom Scale\n",
      "\n",
      "[326 rows x 2 columns]\n",
      "      cat_cluster                                               desc\n",
      "40              1      Heineken and Krups BeerTender B90 Home System\n",
      "41              1   Karcher K2.16 Electric Pressure Washer 1,400 PSI\n",
      "44              1  Oregon Scientific Wireless In/Outdoor Thermometer\n",
      "65              1               Dyson DC 21 Stowaway Canister Vacuum\n",
      "67              1       Lavazza Crema & Aroma Coffee Beans 8 x 2.2lb\n",
      "70              1      Lavazza Crema & Aroma Coffee Beans 12 x 2.2lb\n",
      "74              1           Krups 468-42 Moka Brew 8-Cup Coffeemaker\n",
      "75              1  Cusinart ICE-30BC Pure Indulgence Ice Cream Maker\n",
      "104             1        Black & Decker G48TD Grill and Waffle Baker\n",
      "105             1               DeLonghi CGH800-U Retro Panini Grill\n",
      "107             1        DeLonghi Stiromeglio Compact Ironing System\n",
      "109             1      Char-Broil Grill 2 Go Advantage Outdoor Grill\n",
      "111             1       Back to Basics 4-Slot Egg-and-Muffin Toaster\n",
      "181             1    Deni 6100 Automatic Stainless Steel Ice Crusher\n",
      "200             1                          Saeco S-PR-SG Primea Ring\n",
      "205             1   KitchenAid KSM150 Artisan Stand Mixer Empire Red\n",
      "217             1  Dyson DC25 Ball All-Floors Upright Vacuum Cleaner\n",
      "261             1          Dyson DC16 Root 6 Handheld Vacuum Cleaner\n",
      "268             1              Deni 7600 3-Tier Digital Food Steamer\n",
      "290             1           Oregon Scientific Wireless Bike Computer\n",
      "292             1      Sanyo U-K170S Stainless-Steel Electric Kettle\n",
      "294             1         Saeco S-TT-ST Talea Touch Espresso Machine\n",
      "301             1                  iRobot 560 Roomba Vacuuming Robot\n",
      "303             1             KitchenAid Artisan 5-Quart Stand Mixer\n",
      "304             1               Staub Square Fondue Set, Black Matte\n",
      "343             1  Screwpull Elegance Lever Model Corkscrew Gift Set\n",
      "344             1  Bosch TAS4511UC Tassimo Single-Serve Coffee Br...\n",
      "345             1                          Amco Double Digital Timer\n",
      "346             1              Cuisinox Venezia Espresso Coffeemaker\n",
      "347             1   Dyson DC17 Animal Cyclone Upright Vacuum Cleaner\n",
      "...           ...                                                ...\n",
      "1566            1     KitchenAid Professional 600 Series Stand Mixer\n",
      "1567            1           Calphalon Nonstick 10-Piece Cookware Set\n",
      "1574            1             Whirlpool Tall Tub Built-In Dishwasher\n",
      "1575            1                   LG 7-Cycle Large Capacity Washer\n",
      "1576            1                       Henckels Cutlery Starter Set\n",
      "1580            1                       Cuisinart White Hand Blender\n",
      "1603            1      Krups BW4000 2-Quart Die-Cast Electric Kettle\n",
      "1604            1  Delonghi DTT900 2-Slice Toaster with Warming Rack\n",
      "1634            1           Rachel Ray Gusto-Grip 10-Piece Knife Set\n",
      "1635            1         KitchenAid Pro line Onyx Black Waffle Iron\n",
      "1636            1   All-Clad Stainless-Steel 6-1/2-Quart Slow Cooker\n",
      "1637            1        Jarden Margaritaville Frozen Beverage Maker\n",
      "1638            1        Zojirushi Home Bakery Supreme Bread Machine\n",
      "1639            1          KitchenAid Onyx Black Burr Coffee Grinder\n",
      "1640            1     Breville Juice Fountain 1000-Watt Elite Juicer\n",
      "1679            1     Emerilware from All-Clad Nonstick Cookware Set\n",
      "1688            1                            Cuisinart Red Teakettle\n",
      "1689            1      Zojirushi Thermal Carafe Coffee Maker (10-c.)\n",
      "1690            1                       T-Fal Avante 4 Slice Toaster\n",
      "1708            1             Saeco Fully Automatic Espresso Machine\n",
      "1717            1                FrancisFrancis! X1 Espresso Machine\n",
      "1733            1                       Rowenta DZ9080 Advancer Iron\n",
      "1734            1         Whirlpool WFW9450WL Duet Front-Load Washer\n",
      "1735            1          LG 26.5 Cu. Ft. Side by Side Refrigerator\n",
      "1751            1                              Godiva Pure Decadence\n",
      "1752            1               igourmet Truffle Lover's Gift Basket\n",
      "1753            1                         Krups Cream Coffee Machine\n",
      "1754            1      DeLonghi Nespresso Latissima Espresso Machine\n",
      "1755            1         Whirlpool Duet 4.4 Cu. Ft. 12-Cycle Washer\n",
      "1757            1      Cuisinart Convection Microwave Oven and Grill\n",
      "\n",
      "[200 rows x 2 columns]\n",
      "      cat_cluster                                               desc\n",
      "203             5                   Men's Titanium Link Bracelet, 8\"\n",
      "204             5     Sterling Silver, Blue Topaz  Butterfly Pendant\n",
      "221             5   Sterling Silver Dyed Black & Grey Pearl Bracelet\n",
      "249             5     Casio Men's Ana-Digi Edifice Thermometer Watch\n",
      "250             5           Invicta Men's Speedway Chronograph Watch\n",
      "256             5      Invicta Men's Speedway Collection Chronograph\n",
      "260             5  Invicta Men's Corduba Collection Chronograph W...\n",
      "300             5  Invicta Men's  Mechanical Chronograph Watch #5102\n",
      "306             5          Citizen Eco-Drive Men's Chronograph Watch\n",
      "319             5               Bulova Women's Crystal Watch #96L001\n",
      "320             5  Stuhrling Original Classic Men's 'Heritage' Watch\n",
      "335             5      Jacques Lemans Men's Classic Collection Watch\n",
      "336             5  Invicta Men's Gold-Tone Chronograph S Series W...\n",
      "341             5   Sterling Silver Amethyst Pendant and Earring Set\n",
      "366             5  Invicta Men's Sport Chronograph Elite Watch #4891\n",
      "367             5       Star Wars Clone Trooper Voice Changer Helmet\n",
      "452             5                       JanSport Wool Ginko Backpack\n",
      "458             5        Osprey Pack Sojourn 40L Wheeled Travel Pack\n",
      "506             5                Juwelis Selina Diamond Ladies Watch\n",
      "510             5                 Bossart Automatic City Gents Watch\n",
      "511             5             Krug BaÃ¼men Regatta Diamond Mens Watch\n",
      "512             5               Rothenschild Grand Caree Gents Watch\n",
      "513             5                  Rothenschild Stingray Gents Watch\n",
      "514             5                  Perigaum Global Timer Gents Watch\n",
      "515             5       Perigaum Monte Carlo Chronograph Gents Watch\n",
      "516             5             Bossart Ladies Automatic Vintage Watch\n",
      "517             5                Juwelis Selina Ladies Diamond Watch\n",
      "518             5          Adee Kaye Sparrow Chronograph Gents Watch\n",
      "519             5                    PerigÃ¡um Llandudno Ladies Watch\n",
      "576             5  Invicta Women's Wildflower Diamond Two-Tone Watch\n",
      "...           ...                                                ...\n",
      "1429            5            10k White Gold Diamond Teardrop Pendant\n",
      "1430            5                      Diamond Heart and Key Pendant\n",
      "1431            5             Slip-On Cuff Bangle in Sterling Silver\n",
      "1432            5  Freshwater Cultured Pearl & Smoky Quartz Necklace\n",
      "1433            5        Blue Sapphire Gemstone and Diamond Necklace\n",
      "1434            5         Dangling Amber Necklace in Sterling Silver\n",
      "1444            5               Invicta Men's Diamond Two-Tone Watch\n",
      "1452            5                  HOBO INTERNATIONAL Katrina Clutch\n",
      "1453            5           Betsey Johnson Snake Charmer Medium Tote\n",
      "1454            5               Nine West Madeline Flap Shoulder Bag\n",
      "1455            5              Hobo International Avery Shoulder Bag\n",
      "1456            5                                GUESS Rocky Satchel\n",
      "1457            5                                  Dakine Hustle Bag\n",
      "1458            5                           Roxy Shimmy Shoulder Bag\n",
      "1459            5                 Jessica Simpson Runway Small Frame\n",
      "1461            5                          O'Neill Occy Tote Handbag\n",
      "1473            5                  Kenneth Cole New York Men's Watch\n",
      "1474            5           Seiko Men's Retrograde Chronograph Watch\n",
      "1501            5                Seiko Men's Kinetic Black Ion Watch\n",
      "1571            5             Gold Blue Sapphire and Diamond Pendant\n",
      "1572            5              Citrine Gemstone and Diamond Earrings\n",
      "1573            5           Green Amethyst and Diamond Drop Earrings\n",
      "1578            5                     Freshwater Pearl Drop Earrings\n",
      "1602            5               Marc by Marc Jacobs Nylon Q Wristlet\n",
      "1702            5     10k White Gold Black Diamond Infinity Earrings\n",
      "1703            5        Jessica Simpson Dream Catcher Shrunken Hobo\n",
      "1704            5                         Nine West Sally Small Hobo\n",
      "1705            5                          Fossil Crosstown E/W Flap\n",
      "1706            5                      Roxy Reservation Hobo Handbag\n",
      "1707            5               Juicy Couture Power Crest Snake Tote\n",
      "\n",
      "[115 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Unique product descriptions\n",
    "productDescription = outcomesDf['desc'].unique()\n",
    "    \n",
    "productDescriptionToVector={}\n",
    "for item in productDescription:\n",
    "    #Word2Vec vector obtained for each product description\n",
    "    productDescriptionToVector[item] = productDescriptionToVectorDf[item]\n",
    "    \n",
    "productVectors = list(productDescriptionToVector.values())\n",
    "   \n",
    "km = KMeans(n_clusters=7,random_state=2)\n",
    "#the clustering is performed with the Word2Vec vectors for the product categories given as input\n",
    "km.fit(productVectors)\n",
    "clusters = km.labels_.tolist()\n",
    "#DataFrame containing columns for the product description and the category cluster that it is associated to\n",
    "clusteredCategoriesDf = pd.DataFrame({'desc': list(productDescriptionToVector.keys()), 'cat_cluster': clusters})\n",
    "\n",
    "for catCluster in clusteredCategoriesDf['cat_cluster'].unique():\n",
    "    print(clusteredCategoriesDf[clusteredCategoriesDf['cat_cluster'] == catCluster])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame containing the product description and the corresponding cluster number is given as input for the function explained at the beginning of this section, which returns the one-hot encoded version of the DataFrame. The input variables for the prediction models are the retail price of the item, the bid increment, the bid fee, the flags that indicate the type of auction, and the one-hot encoded cluster identifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, for each row contained in the test data, the word embedding vector associated to the product description is obtained. Then, the nearest cluster (according to the distance defined by the word embedding vector) obtained during the training part is assigned to the product. This process is done for all rows of the test data, and then, in the same way as in the training part, a one-hot encoded version of the DataFrame containing the product description and the corresponding cluster number is obtained.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean absolute error and the median absolute error (as the average of the results obtained for these two metrics over the 5 cross-validation folds) is then calculated for each prediction model. The results are analyzed after the lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "--\n",
      "Random Forest Regressor\n",
      "Median absolute error: 10.3695943096\n",
      "Mean absolute error: 28.2917930555\n",
      "--\n",
      "K Neighbors Regressor\n",
      "Median absolute error: 11.0048\n",
      "Mean absolute error: 31.3873834655\n",
      "--\n",
      "Decision Tree Regressor\n",
      "Median absolute error: 10.4475408408\n",
      "Mean absolute error: 28.9652640762\n",
      "--\n",
      "Linear Regression\n",
      "Median absolute error: 21.5956271431\n",
      "Mean absolute error: 39.2957860884\n",
      "--\n",
      "RANSAC Regressor\n",
      "Median absolute error: 15.2715519949\n",
      "Mean absolute error: 44.8184361425\n"
     ]
    }
   ],
   "source": [
    "kFoldMedianAbsoluteErrorsRandomForestRegressor = []\n",
    "kFoldMedianAbsoluteErrorsKNeighborsRegressor = []\n",
    "kFoldMedianAbsoluteErrorsDecisionTreeRegressor = []\n",
    "kFoldMedianAbsoluteErrorsLinearRegression = []\n",
    "kFoldMedianAbsoluteErrorsRANSACRegressor = []\n",
    "\n",
    "kFoldMeanAbsoluteErrorsRandomForestRegressor = []\n",
    "kFoldMeanAbsoluteErrorsKNeighborsRegressor = []\n",
    "kFoldMeanAbsoluteErrorsDecisionTreeRegressor = []\n",
    "kFoldMeanAbsoluteErrorsLinearRegression = []\n",
    "kFoldMeanAbsoluteErrorsRANSACRegressor = []\n",
    "\n",
    "kFoldNumber = 1\n",
    "kf = KFold(n_splits=5, random_state=1)\n",
    "for train_index, test_index in kf.split(outcomesDf):\n",
    "    #5-fold cross-validation\n",
    "    print(\"Executing k fold = \"+str(kFoldNumber))\n",
    "    kFoldNumber=kFoldNumber+1\n",
    "    \n",
    "    #train and test split\n",
    "    outcomesDf_train, outcomesDf_test = outcomesDf.iloc[train_index], outcomesDf.iloc[test_index]   \n",
    "    \n",
    "    #TRAINING PART\n",
    "    \n",
    "    #Unique product descriptions present in the training dataset\n",
    "    productDescriptionTrain = outcomesDf_train['desc'].unique()\n",
    "    \n",
    "    productDescriptionToVector={}\n",
    "    for item in productDescriptionTrain:\n",
    "        #Word2Vec vector obtained for each product description\n",
    "        productDescriptionToVector[item] = productDescriptionToVectorDf[item]\n",
    "    \n",
    "    productVectors = list(productDescriptionToVector.values())\n",
    "   \n",
    "    km = KMeans(n_clusters=20,random_state=2)\n",
    "    #the clustering is performed with the Word2Vec vectors for the product categories given as input\n",
    "    km.fit(productVectors)\n",
    "    clusters = km.labels_.tolist()\n",
    "    #DataFrame containing columns for the product description and the category cluster that it is associated to\n",
    "    clusteredCategoriesDf = pd.DataFrame({'desc': list(productDescriptionToVector.keys()), 'cat_cluster': clusters})\n",
    "    #One-Hot encoded version of the DataFrame containing a column for each cluster\n",
    "    clusteredCategoriesDfOneHotEnc = convertCategoryDataFrameToOneHotEncodedVersion(clusteredCategoriesDf,'cat_cluster')  \n",
    "    #column names of the clusters\n",
    "    cluster_column_names = clusteredCategoriesDfOneHotEnc.columns.values\n",
    "    clusteredCategoriesDfOneHotEnc['desc'] = clusteredCategoriesDf['desc']\n",
    "    #the training dataset is merged so that it contains a one hot-encoded \n",
    "    #column for each one of the clusters obtained.\n",
    "    outcomesDfWithCatOneHot = outcomesDf_train.merge(clusteredCategoriesDfOneHotEnc,how='left')\n",
    "    normal_x_column_names = [\"retail\",\"bidincrement\",\"bidfee\",\"flg_click_only\",\"flg_beginnerauction\",\"flg_fixedprice\",\"flg_endprice\"]\n",
    "    #column names to be used in the prediction model: they include the columns corresponding to the clusters obtained.\n",
    "    column_names_with_clusters = np.concatenate([normal_x_column_names,cluster_column_names])\n",
    "    \n",
    "    #training phase variables\n",
    "    X_train = outcomesDfWithCatOneHot[column_names_with_clusters]\n",
    "    y_train = outcomesDfWithCatOneHot[\"price\"]\n",
    "    \n",
    "    #TEST PART\n",
    "    \n",
    "    #Unique product descriptions present in the training dataset\n",
    "    productDescriptionTest = outcomesDf_test['desc'].unique()\n",
    "    \n",
    "    productDescriptionToVector={}\n",
    "    for item in productDescriptionTest:\n",
    "        #Word2Vec vector obtained for each product description\n",
    "        productDescriptionToVector[item] = productDescriptionToVectorDf[item]\n",
    "   \n",
    "    productDescriptionToTrainCluster = {}\n",
    "    for productDescription, vector in productDescriptionToVector.items():\n",
    "        #The K-Means model obtained during the training phase is used to associate\n",
    "        #an existing cluster to each one of the product vectors contained in the test data.\n",
    "        clusterCategory = km.predict([vector])\n",
    "        productDescriptionToTrainCluster[productDescription] = clusterCategory[0]\n",
    "    \n",
    "    #DataFrame containing columns for the product description and the category cluster that it is associated to\n",
    "    clusteredCategoriesDf = pd.DataFrame(list(productDescriptionToTrainCluster.items()), columns=['desc', 'cat_cluster'])\n",
    "    #One-Hot encoded version of the DataFrame containing a column for each cluster.\n",
    "    #The columns are the same ones as in the training phase\n",
    "    clusteredCategoriesDfOneHotEnc = convertCategoryDataFrameToOneHotEncodedVersion(clusteredCategoriesDf,'cat_cluster',cluster_column_names)\n",
    "    #column names of the clusters\n",
    "    cluster_column_names = clusteredCategoriesDfOneHotEnc.columns.values\n",
    "    clusteredCategoriesDfOneHotEnc['desc'] = clusteredCategoriesDf['desc']\n",
    "    #the test dataset is merged so that it contains a one hot-encoded \n",
    "    #column for each one of the clusters obtained.\n",
    "    outcomesDfWithCatOneHot = outcomesDf_test.merge(clusteredCategoriesDfOneHotEnc,how='left')\n",
    "    normal_x_column_names = [\"retail\",\"bidincrement\",\"bidfee\",\"flg_click_only\",\"flg_beginnerauction\",\"flg_fixedprice\",\"flg_endprice\"]\n",
    "    #column names to be used in the prediction model: they include the columns corresponding to the clusters obtained.\n",
    "    column_names_with_clusters = np.concatenate([normal_x_column_names,cluster_column_names])\n",
    "    \n",
    "    #test phase variables\n",
    "    X_test = outcomesDfWithCatOneHot[column_names_with_clusters]\n",
    "    y_test = outcomesDfWithCatOneHot[\"price\"]\n",
    "    \n",
    "    #Predictors\n",
    "    \n",
    "    #RandomForestRegressor\n",
    "    model=RandomForestRegressor(random_state=1)\n",
    "    model.fit(X_train,y_train)\n",
    "    P_price = model.predict(X_test)\n",
    "    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsRandomForestRegressor.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsRandomForestRegressor.append(kFoldMeanAbsoluteError)  \n",
    "\n",
    "    #KNeighborsRegressor\n",
    "    model = KNeighborsRegressor()\n",
    "    model.fit(X_train,y_train)\n",
    "    P_price = model.predict(X_test)\n",
    "    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsKNeighborsRegressor.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsKNeighborsRegressor.append(kFoldMeanAbsoluteError)  \n",
    "    \n",
    "    #DecisionTreeRegressor\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_train,y_train)\n",
    "    P_price = model.predict(X_test)\n",
    "    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsDecisionTreeRegressor.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsDecisionTreeRegressor.append(kFoldMeanAbsoluteError)  \n",
    "    \n",
    "    #LinearRegression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    P_price = model.predict(X_test)\n",
    "    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsLinearRegression.append(kFoldMedianAbsoluteError) \n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsLinearRegression.append(kFoldMeanAbsoluteError)  \n",
    "    \n",
    "    #RANSACRegressor\n",
    "    model = RANSACRegressor(random_state=1)\n",
    "    model.fit(X_train,y_train)\n",
    "    P_price = model.predict(X_test)\n",
    "    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsRANSACRegressor.append(kFoldMedianAbsoluteError) \n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsRANSACRegressor.append(kFoldMeanAbsoluteError)  \n",
    "    \n",
    "medianAbsoluteErrorsRandomForestRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsRandomForestRegressor)\n",
    "meanAbsoluteErrorsRandomForestRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsRandomForestRegressor)\n",
    "medianAbsoluteErrorsKNeighborsRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsKNeighborsRegressor)\n",
    "meanAbsoluteErrorsKNeighborsRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsKNeighborsRegressor)\n",
    "medianAbsoluteErrorsDecisionTreeRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsDecisionTreeRegressor)\n",
    "meanAbsoluteErrorsDecisionTreeRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsDecisionTreeRegressor)\n",
    "medianAbsoluteErrorsLinearRegressionAverage = np.mean(kFoldMedianAbsoluteErrorsLinearRegression)\n",
    "meanAbsoluteErrorsLinearRegressionAverage = np.mean(kFoldMeanAbsoluteErrorsLinearRegression)\n",
    "medianAbsoluteErrorsRANSACRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsRANSACRegressor)\n",
    "meanAbsoluteErrorsRANSACRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsRANSACRegressor)\n",
    "\n",
    "print(\"--\")\n",
    "print(\"Random Forest Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsRandomForestRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsRandomForestRegressorAverage))\n",
    "print(\"--\")\n",
    "print(\"K Neighbors Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsKNeighborsRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsKNeighborsRegressorAverage))\n",
    "print(\"--\")\n",
    "print(\"Decision Tree Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsDecisionTreeRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsDecisionTreeRegressorAverage))\n",
    "print(\"--\")\n",
    "print(\"Linear Regression\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsLinearRegressionAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsLinearRegressionAverage))\n",
    "print(\"--\")\n",
    "print(\"RANSAC Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsRANSACRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsRANSACRegressorAverage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen above, the model with the best results is the random forest regressor, both in terms of the median absolute error and the mean absolute error. It is closely followed by the decision tree regressor. Although the random forest regressor performs better in terms of the chosen metrics, the decision tree regressor is easier to interpret. Nevertheless, the decision tree regressor is also more likely to overfit the data. The k-neighbors regressor is the next one with the better results, followed by the RANSAC regressor. Ultimatelly, the worst results are obtained with the linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the results are better with this set of models that takes into account the product categories as compared with the results obtained with the set of models that does not take them into account (explained in the previous section).\n",
    "\n",
    "Nevertheless, this set of models requires a bigger effort, since a preprocessing step is necessary to make predictions. This preprocessing step consists on, given the product description of an item in the column \"desc\", its Amazon category must be obtained, and afterwards, the corresponding word embedding vector.\n",
    "\n",
    "Furthermore, during the training part of the model, the product category clusters are obtained, and these clusters are the ones that are used each time that a new prediction is made. After some time, more and more new products will begin to be auctioned, which will not have been considered to form the clusters. Because of this, the clusters may eventually become outdated, and the models will perform worse. Therefore, appart from the preprocessing step, using the product categories also involves having to retrain the prediction models more often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c) Multiple models - Clustering by product categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A third set of models that have into account the product categories has been built. The difference between this set of models and the previous one is that instead of using a single model for all items, a different prediction model is used for each different product category (i.e., each cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomesDf = pd.read_csv('./outcomes_clean.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "productDescriptionToVectorDf = pd.read_excel('./productDescriptionToVector.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way as in the previous set of models, the following lines of code calculate the metrics associated to each one of the prediction models using 5-fold cross-validation. During the training part, the K-Means algorithm is used to obtain clusters for the word embedding vectors. Once that each different item in the training data has been assigned to a cluster, the training data is divided by cluster number. For each set of data belonging to the same cluster, a new set of prediction models is trained. The input variables for the model are the retail price of the item, the bid increment, the bid fee and the flags that indicate the type of auction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the test part, for each row contained in the test data, the word embedding vector associated to the product description is obtained. Then, the nearest cluster (according to the distance defined by the word embedding vector) obtained during the training part is assigned to the product. For each row contained in the test data, the corresponding set of models for that product category (cluster) is used to make the selling price prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean absolute error and the median absolute error (as the average of the results obtained for these two metrics over the 5 cross-validation folds) is then calculated for each prediction model contained in the different sets assigned to each cluster. For each type of prediction model (random forest regressor, decision tree regressor, etc), the mean absolute error and the median absolute error is calculated as the average of the results obtained for each one of the models (with the same type of prediction algorithm) corresponding to each different cluster. The results are analyzed after the lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "--\n",
      "Random Forest Regressor\n",
      "Median absolute error: 10.3682931183\n",
      "Mean absolute error: 28.429692278\n",
      "--\n",
      "K Neighbors Regressor\n",
      "Median absolute error: 11.13\n",
      "Mean absolute error: 30.7647559882\n",
      "--\n",
      "Decision Tree Regressor\n",
      "Median absolute error: 10.4312165268\n",
      "Mean absolute error: 28.9929051615\n",
      "--\n",
      "Linear Regression\n",
      "Median absolute error: 16.4468950152\n",
      "Mean absolute error: 33.9439732817\n",
      "--\n",
      "RANSAC Regressor\n",
      "Median absolute error: 9.99884623609\n",
      "Mean absolute error: 32.1491303303\n"
     ]
    }
   ],
   "source": [
    "kFoldMedianAbsoluteErrorsRandomForestRegressor = []\n",
    "kFoldMedianAbsoluteErrorsKNeighborsRegressor = []\n",
    "kFoldMedianAbsoluteErrorsDecisionTreeRegressor = []\n",
    "kFoldMedianAbsoluteErrorsLinearRegression = []\n",
    "kFoldMedianAbsoluteErrorsRANSACRegressor = []\n",
    "\n",
    "kFoldMeanAbsoluteErrorsRandomForestRegressor = []\n",
    "kFoldMeanAbsoluteErrorsKNeighborsRegressor = []\n",
    "kFoldMeanAbsoluteErrorsDecisionTreeRegressor = []\n",
    "kFoldMeanAbsoluteErrorsLinearRegression = []\n",
    "kFoldMeanAbsoluteErrorsRANSACRegressor = []\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=1)\n",
    "kFoldNumber = 1\n",
    "for train_index, test_index in kf.split(outcomesDf):\n",
    "    #5-fold cross-validation\n",
    "    print(\"Executing k fold = \"+str(kFoldNumber))\n",
    "    kFoldNumber=kFoldNumber+1\n",
    "    \n",
    "    #train and test split\n",
    "    outcomesDf_train, outcomesDf_test = outcomesDf.iloc[train_index], outcomesDf.iloc[test_index]   \n",
    "    \n",
    "    #TRAINING PART\n",
    "                                        \n",
    "    #Unique product descriptions present in the training dataset\n",
    "    productDescriptionTrain = outcomesDf_train['desc'].unique()\n",
    "    \n",
    "    productDescriptionToVector={}\n",
    "    for item in productDescriptionTrain:\n",
    "        #Word2Vec vector obtained for each product description\n",
    "        productDescriptionToVector[item] = productDescriptionToVectorDf[item]\n",
    "        \n",
    "    productVectors = list(productDescriptionToVector.values())\n",
    "    \n",
    "    km = KMeans(n_clusters=15,random_state=2)\n",
    "    #the clustering is performed with the Word2Vec vectors for the product categories given as input\n",
    "    km.fit(productVectors)\n",
    "    clusters = km.labels_.tolist()\n",
    "    #DataFrame containing columns for the product description and the category cluster that it is associated to\n",
    "    clusteredCategoriesDf = pd.DataFrame({'desc': list(productDescriptionToVector.keys()), 'cat_cluster': clusters})\n",
    "    #the training dataset is merged and now it contains a column with the category that\n",
    "    #each product belongs to.\n",
    "    outcomesDfTrainAndCatCluster = outcomesDf_train.merge(clusteredCategoriesDf,how='left')\n",
    "    \n",
    "    clusterIndexToOutcomesDfTrain = {}\n",
    "    for cluster_index in outcomesDfTrainAndCatCluster['cat_cluster'].unique():\n",
    "        #the rows associated to each different product category are stored in a dictionary,\n",
    "        #where the dictionary key is the product category number (cluster number)\n",
    "        clusterIndexToOutcomesDfTrain[cluster_index] = outcomesDfTrainAndCatCluster[outcomesDfTrainAndCatCluster['cat_cluster'] == cluster_index]\n",
    "    \n",
    "    #dictionaries that contain a trained model for each one of the product categories (clusters)\n",
    "    clusterIndexToRandomForestRegressor = {}\n",
    "    clusterIndexToKNeighborsRegressor = {}\n",
    "    clusterIndexToDecisionTreeRegressor = {}\n",
    "    clusterIndexToLinearRegression = {}\n",
    "    clusterIndexToRANSACRegressor = {}\n",
    "    \n",
    "    for cluster_index, outcomesDfClusterIndex in clusterIndexToOutcomesDfTrain.items():\n",
    "        #For each product category (cluster), a different model is trained using\n",
    "        #the rows of the input dataset containing the products associated to that category\n",
    "        X_train = outcomesDfClusterIndex[[\"retail\",\"bidincrement\",\"bidfee\",\"flg_click_only\",\"flg_beginnerauction\",\"flg_fixedprice\",\"flg_endprice\"]].values\n",
    "        y_train = outcomesDfClusterIndex[\"price\"]\n",
    "        \n",
    "        #RandomForestRegressor\n",
    "        model=RandomForestRegressor(random_state=1)\n",
    "        model.fit(X_train,y_train)\n",
    "        clusterIndexToRandomForestRegressor[cluster_index] = model\n",
    "\n",
    "        #KNeighborsRegressor\n",
    "        n_neighbors=5\n",
    "        if outcomesDfClusterIndex.shape[0] < n_neighbors:\n",
    "            #In KNeighborsRegressor it is expected n_neighbors <= n_samples\n",
    "            n_neighbors = outcomesDfClusterIndex.shape[0]\n",
    "            \n",
    "        model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "        model.fit(X_train,y_train)\n",
    "        clusterIndexToKNeighborsRegressor[cluster_index] = model\n",
    "\n",
    "        #DecisionTreeRegressor\n",
    "        model = DecisionTreeRegressor()\n",
    "        model.fit(X_train,y_train)\n",
    "        clusterIndexToDecisionTreeRegressor[cluster_index] = model\n",
    "    \n",
    "        #LinearRegression\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train,y_train)\n",
    "        clusterIndexToLinearRegression[cluster_index] = model\n",
    "        \n",
    "        #RANSACRegressor\n",
    "        model = RANSACRegressor(random_state=1)\n",
    "        model.fit(X_train,y_train)\n",
    "        clusterIndexToRANSACRegressor[cluster_index] = model\n",
    "        \n",
    "    #TEST PART\n",
    "    \n",
    "    #Unique product descriptions present in the test dataset\n",
    "    productDescriptionTest = outcomesDf_test['desc'].unique()\n",
    "    \n",
    "    productDescriptionToVector={}\n",
    "    for item in productDescriptionTest:\n",
    "        #Word2Vec vector obtained for each product description\n",
    "        productDescriptionToVector[item] = productDescriptionToVectorDf[item]\n",
    "   \n",
    "    productDescriptionToTrainCluster = {}\n",
    "    for productDescription, vector in productDescriptionToVector.items(): \n",
    "        #The K-Means model obtained during the training phase is used to associate\n",
    "        #an existing cluster to each one of the product vectors contained in the test data.        \n",
    "        clusterCategory = km.predict([vector])\n",
    "        productDescriptionToTrainCluster[productDescription] = clusterCategory[0]\n",
    "    \n",
    "    #DataFrame containing columns for the product description and the category cluster that it is associated to\n",
    "    clusteredCategoriesDf = pd.DataFrame(list(productDescriptionToTrainCluster.items()), columns=['desc', 'cat_cluster'])\n",
    "    #the test dataset is merged and now it contains a column with the category that\n",
    "    #each product belongs to.\n",
    "    outcomesDfTestAndCatCluster = outcomesDf_test.merge(clusteredCategoriesDf,how='left')\n",
    "    \n",
    "    realAndPredictedValuesRandomForestRegressor = []\n",
    "    realAndPredictedValuesKNeighborsRegressor = []\n",
    "    realAndPredictedValuesDecisionTreeRegressor = []\n",
    "    realAndPredictedValuesLinearRegression = []\n",
    "    realAndPredictedValuesRANSACRegressor = []\n",
    "    \n",
    "    for index, row in outcomesDfTestAndCatCluster.iterrows():\n",
    "        #iteration through each row of the test dataset\n",
    "        \n",
    "        #real value of the column to be predicted\n",
    "        y_test_value = row[\"price\"]\n",
    "        #values given as input for the prediction model\n",
    "        x_test_value = row[[\"retail\",\"bidincrement\",\"bidfee\",\"flg_click_only\",\"flg_beginnerauction\",\"flg_fixedprice\",\"flg_endprice\"]].values\n",
    "        #product category cluster for this row of the dataset\n",
    "        clusterIndex = row[\"cat_cluster\"]\n",
    "        \n",
    "        #the prediction models associated to this product category (cluster) are extracted\n",
    "        modelRandomForestRegressor = clusterIndexToRandomForestRegressor[clusterIndex]\n",
    "        modelKNeighborsRegressor = clusterIndexToKNeighborsRegressor[clusterIndex]\n",
    "        modelDecisionTreeRegressor = clusterIndexToDecisionTreeRegressor[clusterIndex]\n",
    "        modelLinearRegression = clusterIndexToLinearRegression[clusterIndex]\n",
    "        modelRANSACRegressor = clusterIndexToRANSACRegressor[clusterIndex]\n",
    "        \n",
    "        #the real value and the predicted value are stored in a different list for\n",
    "        #each one of the prediction models used.\n",
    "        realAndPredictedValuesRandomForestRegressor.append((y_test_value,modelRandomForestRegressor.predict([x_test_value])[0]))\n",
    "        realAndPredictedValuesKNeighborsRegressor.append((y_test_value,modelKNeighborsRegressor.predict([x_test_value])[0]))\n",
    "        realAndPredictedValuesDecisionTreeRegressor.append((y_test_value,modelDecisionTreeRegressor.predict([x_test_value])[0]))\n",
    "        realAndPredictedValuesLinearRegression.append((y_test_value,modelLinearRegression.predict([x_test_value])[0]))\n",
    "        realAndPredictedValuesRANSACRegressor.append((y_test_value,modelRANSACRegressor.predict([x_test_value])[0]))\n",
    "    \n",
    "    #RandomForestRegressor\n",
    "    #all real and predicted values are extracted and the metrics are calculated\n",
    "    y_test, P_price = zip(*realAndPredictedValuesRandomForestRegressor)    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsRandomForestRegressor.append(kFoldMedianAbsoluteError) \n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsRandomForestRegressor.append(kFoldMeanAbsoluteError)  \n",
    "    \n",
    "    #KNeighborsRegressor\n",
    "    #all real and predicted values are extracted and the metrics are calculated\n",
    "    y_test, P_price = zip(*realAndPredictedValuesKNeighborsRegressor)    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsKNeighborsRegressor.append(kFoldMedianAbsoluteError)  \n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsKNeighborsRegressor.append(kFoldMeanAbsoluteError)  \n",
    "    \n",
    "    #DecisionTreeRegressor\n",
    "    #all real and predicted values are extracted and the metrics are calculated\n",
    "    y_test, P_price = zip(*realAndPredictedValuesDecisionTreeRegressor)    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsDecisionTreeRegressor.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsDecisionTreeRegressor.append(kFoldMeanAbsoluteError)  \n",
    "    \n",
    "    #LinearRegression\n",
    "    #all real and predicted values are extracted and the metrics are calculated\n",
    "    y_test, P_price = zip(*realAndPredictedValuesLinearRegression)    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsLinearRegression.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsLinearRegression.append(kFoldMeanAbsoluteError) \n",
    "    \n",
    "    #RANSACRegressor\n",
    "    #all real and predicted values are extracted and the metrics are calculated\n",
    "    y_test, P_price = zip(*realAndPredictedValuesRANSACRegressor)\n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsRANSACRegressor.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsRANSACRegressor.append(kFoldMeanAbsoluteError) \n",
    "    \n",
    "medianAbsoluteErrorsRandomForestRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsRandomForestRegressor)\n",
    "meanAbsoluteErrorsRandomForestRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsRandomForestRegressor)\n",
    "medianAbsoluteErrorsKNeighborsRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsKNeighborsRegressor)\n",
    "meanAbsoluteErrorsKNeighborsRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsKNeighborsRegressor)\n",
    "medianAbsoluteErrorsDecisionTreeRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsDecisionTreeRegressor)\n",
    "meanAbsoluteErrorsDecisionTreeRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsDecisionTreeRegressor)\n",
    "medianAbsoluteErrorsLinearRegressionAverage = np.mean(kFoldMedianAbsoluteErrorsLinearRegression)\n",
    "meanAbsoluteErrorsLinearRegressionAverage = np.mean(kFoldMeanAbsoluteErrorsLinearRegression)\n",
    "medianAbsoluteErrorsRANSACRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsRANSACRegressor)\n",
    "meanAbsoluteErrorsRANSACRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsRANSACRegressor)\n",
    "\n",
    "print(\"--\")\n",
    "print(\"Random Forest Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsRandomForestRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsRandomForestRegressorAverage))\n",
    "print(\"--\")\n",
    "print(\"K Neighbors Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsKNeighborsRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsKNeighborsRegressorAverage))\n",
    "print(\"--\")\n",
    "print(\"Decision Tree Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsDecisionTreeRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsDecisionTreeRegressorAverage))\n",
    "print(\"--\")\n",
    "print(\"Linear Regression\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsLinearRegressionAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsLinearRegressionAverage))\n",
    "print(\"--\")\n",
    "print(\"RANSAC Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsRANSACRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsRANSACRegressorAverage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen above, the model with the best results in terms of the median absolute error is the RANSAC regressor. Nevertheless, the random forest regressor performs similarly in terms of the median absolute error, and performs way better in terms of the mean absolute error. It is closely followed by the decision tree regresor, which is easier to interpret but is also more likely to overfit the data. The k-neighbors regressor is the next one with the better results, followed by the linear regression with the worst results by far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the results are slightly better with this set of models as compared with the set of models explained in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of effort, this model requires the same preprocessing step to make predictions as the previous set of models: given the product description of an item in the column \"desc\", its Amazon category must be obtained, and afterwards, the corresponding word embedding vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different prediction model is used for each different product category (cluster) that is obtained during the training part of the model. In the same way as with the set of models mentioned in the previous section, more and more new products will begin to be auctioned after some time, and the clusters (and therefore, the model assigned to each cluster) will become outdated and the models will perform worse. Therefore, appart from the preprocessing step, the prediction models have to be retrained after some time (and this time, it is not necessary to retrain a single model, but to retrain as many prediction models as existing clusters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision between using a single model to make the predictions (as explained in the previous section), or using a different model for each product category (as explained in this section) should also be highly influenced by the amount of training data available. The data that is used to train the prediction model corresponding to a single cluster is only the one that contains items associated to the product category corresponding to that cluster. If the amount of training data is low, the model will perform badly when making predictions for that cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the metrics have been calculated as the average results between the models corresponding to the different clusters. Therefore, it may happen that the prediction model associated to a certain cluster performs much worse than the ones associated to the other clusters (because the amount of training data for that cluster is low)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, using a different prediction model for each cluster may be interesting when the amount of training data is big, but if this is not the case, it is better to use a single prediction model for all clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d) Single model - Clustering by product categories and retail prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fourth set of models that have into account the product categories have been built. In this case, a single prediction model is used to make the predictions. The difference is that the product category clusters have not only been built with the word embedding vector representing the product category, but also with the retail price of the item.\n",
    "\n",
    "This has been done to divide the products not only by their category, but also by their retail price. For example, mobile phone auctions can consist on high-end and mid-range mobile phones. The product category in both cases is mobile phones, but the selling price of high-end mobile phones will likely be higher than for mid-range mobile phones. Therefore, if different clusters are created for these two cases, the prediction model may perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomesDf = pd.read_csv('./outcomes_clean.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "productDescriptionToVectorDf = pd.read_excel('./productDescriptionToVector.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, the same product can be auctioned more than once. The retail price of the same item in different auctions can also change. For example, the retail price of this external hard drive changes over time: it starts with 169.99\\$ in the first auctions in the dataset, and then changes to 79.00\\$, then 86.26\\$ and ends up having a retail price of 94.99\\$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>retail</th>\n",
       "      <th>endtime_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-09-27 07:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-09-26 08:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-09-22 07:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-09-23 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-09-24 07:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-09-25 06:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-09-28 06:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-05 06:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-04 06:29:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-03 07:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5743</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-02 03:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5744</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-09-29 03:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5745</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-09-30 03:29:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5746</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-01 03:37:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-13 15:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9548</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-14 15:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9549</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-15 15:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9550</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-17 11:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-17 23:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9552</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-19 00:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9553</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-31 06:24:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9554</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-11-01 01:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10158</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-26 12:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10159</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-24 18:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10160</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-24 11:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10161</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-22 16:24:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10162</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-22 07:48:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10163</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-20 15:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10164</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-10-26 16:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12251</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>169.99</td>\n",
       "      <td>2008-11-02 05:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111094</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2009-11-01 17:31:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111095</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2009-11-08 15:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111096</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2009-11-07 15:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111097</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2009-11-06 15:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111098</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2009-11-05 15:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111099</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2009-11-04 15:16:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111100</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2009-11-03 15:06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113974</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2009-11-13 07:34:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113975</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2009-11-12 07:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113976</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2009-11-11 07:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113977</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2009-11-10 07:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113978</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2009-11-09 14:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113979</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2009-11-14 19:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113980</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2009-11-13 20:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116048</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>86.26</td>\n",
       "      <td>2009-11-16 02:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116049</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>86.26</td>\n",
       "      <td>2009-11-17 02:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116050</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>94.99</td>\n",
       "      <td>2009-11-18 02:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116051</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>94.99</td>\n",
       "      <td>2009-11-19 02:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116052</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>94.99</td>\n",
       "      <td>2009-11-20 02:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116053</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>94.99</td>\n",
       "      <td>2009-11-21 02:28:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116054</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>94.99</td>\n",
       "      <td>2009-11-22 02:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117698</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>86.26</td>\n",
       "      <td>2009-11-22 21:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117699</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>86.26</td>\n",
       "      <td>2009-11-23 21:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117700</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>86.26</td>\n",
       "      <td>2009-11-24 21:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117701</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>86.26</td>\n",
       "      <td>2009-11-25 21:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117702</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>86.26</td>\n",
       "      <td>2009-11-26 21:24:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117703</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>86.26</td>\n",
       "      <td>2009-11-27 21:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117704</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>86.26</td>\n",
       "      <td>2009-11-28 21:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119398</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>94.99</td>\n",
       "      <td>2009-11-30 05:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119399</th>\n",
       "      <td>Western Digital My Passport Essential 320GB Blue</td>\n",
       "      <td>94.99</td>\n",
       "      <td>2009-12-01 05:44:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    desc  retail  \\\n",
       "2163    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "2164    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "2165    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "2166    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "2167    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "2168    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "2169    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "2170    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "2171    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "2172    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "5743    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "5744    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "5745    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "5746    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "5747    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "9548    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "9549    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "9550    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "9551    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "9552    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "9553    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "9554    Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "10158   Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "10159   Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "10160   Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "10161   Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "10162   Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "10163   Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "10164   Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "12251   Western Digital My Passport Essential 320GB Blue  169.99   \n",
       "...                                                  ...     ...   \n",
       "111094  Western Digital My Passport Essential 320GB Blue   79.00   \n",
       "111095  Western Digital My Passport Essential 320GB Blue   79.00   \n",
       "111096  Western Digital My Passport Essential 320GB Blue   79.00   \n",
       "111097  Western Digital My Passport Essential 320GB Blue   79.00   \n",
       "111098  Western Digital My Passport Essential 320GB Blue   79.00   \n",
       "111099  Western Digital My Passport Essential 320GB Blue   79.00   \n",
       "111100  Western Digital My Passport Essential 320GB Blue   79.00   \n",
       "113974  Western Digital My Passport Essential 320GB Blue   79.00   \n",
       "113975  Western Digital My Passport Essential 320GB Blue   79.00   \n",
       "113976  Western Digital My Passport Essential 320GB Blue   79.00   \n",
       "113977  Western Digital My Passport Essential 320GB Blue   79.00   \n",
       "113978  Western Digital My Passport Essential 320GB Blue   79.00   \n",
       "113979  Western Digital My Passport Essential 320GB Blue   79.00   \n",
       "113980  Western Digital My Passport Essential 320GB Blue   79.00   \n",
       "116048  Western Digital My Passport Essential 320GB Blue   86.26   \n",
       "116049  Western Digital My Passport Essential 320GB Blue   86.26   \n",
       "116050  Western Digital My Passport Essential 320GB Blue   94.99   \n",
       "116051  Western Digital My Passport Essential 320GB Blue   94.99   \n",
       "116052  Western Digital My Passport Essential 320GB Blue   94.99   \n",
       "116053  Western Digital My Passport Essential 320GB Blue   94.99   \n",
       "116054  Western Digital My Passport Essential 320GB Blue   94.99   \n",
       "117698  Western Digital My Passport Essential 320GB Blue   86.26   \n",
       "117699  Western Digital My Passport Essential 320GB Blue   86.26   \n",
       "117700  Western Digital My Passport Essential 320GB Blue   86.26   \n",
       "117701  Western Digital My Passport Essential 320GB Blue   86.26   \n",
       "117702  Western Digital My Passport Essential 320GB Blue   86.26   \n",
       "117703  Western Digital My Passport Essential 320GB Blue   86.26   \n",
       "117704  Western Digital My Passport Essential 320GB Blue   86.26   \n",
       "119398  Western Digital My Passport Essential 320GB Blue   94.99   \n",
       "119399  Western Digital My Passport Essential 320GB Blue   94.99   \n",
       "\n",
       "                endtime_str  \n",
       "2163    2008-09-27 07:01:00  \n",
       "2164    2008-09-26 08:20:00  \n",
       "2165    2008-09-22 07:08:00  \n",
       "2166    2008-09-23 07:00:00  \n",
       "2167    2008-09-24 07:03:00  \n",
       "2168    2008-09-25 06:52:00  \n",
       "2169    2008-09-28 06:51:00  \n",
       "2170    2008-10-05 06:39:00  \n",
       "2171    2008-10-04 06:29:00  \n",
       "2172    2008-10-03 07:15:00  \n",
       "5743    2008-10-02 03:14:00  \n",
       "5744    2008-09-29 03:19:00  \n",
       "5745    2008-09-30 03:29:00  \n",
       "5746    2008-10-01 03:37:00  \n",
       "5747    2008-10-13 15:22:00  \n",
       "9548    2008-10-14 15:50:00  \n",
       "9549    2008-10-15 15:12:00  \n",
       "9550    2008-10-17 11:56:00  \n",
       "9551    2008-10-17 23:32:00  \n",
       "9552    2008-10-19 00:09:00  \n",
       "9553    2008-10-31 06:24:00  \n",
       "9554    2008-11-01 01:14:00  \n",
       "10158   2008-10-26 12:52:00  \n",
       "10159   2008-10-24 18:10:00  \n",
       "10160   2008-10-24 11:57:00  \n",
       "10161   2008-10-22 16:24:00  \n",
       "10162   2008-10-22 07:48:00  \n",
       "10163   2008-10-20 15:20:00  \n",
       "10164   2008-10-26 16:25:00  \n",
       "12251   2008-11-02 05:15:00  \n",
       "...                     ...  \n",
       "111094  2009-11-01 17:31:00  \n",
       "111095  2009-11-08 15:12:00  \n",
       "111096  2009-11-07 15:09:00  \n",
       "111097  2009-11-06 15:03:00  \n",
       "111098  2009-11-05 15:14:00  \n",
       "111099  2009-11-04 15:16:00  \n",
       "111100  2009-11-03 15:06:00  \n",
       "113974  2009-11-13 07:34:00  \n",
       "113975  2009-11-12 07:26:00  \n",
       "113976  2009-11-11 07:44:00  \n",
       "113977  2009-11-10 07:21:00  \n",
       "113978  2009-11-09 14:56:00  \n",
       "113979  2009-11-14 19:53:00  \n",
       "113980  2009-11-13 20:04:00  \n",
       "116048  2009-11-16 02:25:00  \n",
       "116049  2009-11-17 02:25:00  \n",
       "116050  2009-11-18 02:07:00  \n",
       "116051  2009-11-19 02:50:00  \n",
       "116052  2009-11-20 02:05:00  \n",
       "116053  2009-11-21 02:28:00  \n",
       "116054  2009-11-22 02:46:00  \n",
       "117698  2009-11-22 21:30:00  \n",
       "117699  2009-11-23 21:08:00  \n",
       "117700  2009-11-24 21:18:00  \n",
       "117701  2009-11-25 21:10:00  \n",
       "117702  2009-11-26 21:24:00  \n",
       "117703  2009-11-27 21:39:00  \n",
       "117704  2009-11-28 21:18:00  \n",
       "119398  2009-11-30 05:55:00  \n",
       "119399  2009-12-01 05:44:00  \n",
       "\n",
       "[243 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomesDf[outcomesDf['desc'] == \"Western Digital My Passport Essential 320GB Blue\"][['desc','retail','endtime_str']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though it is the same hard drive, an item that was before considered a high-end item might become obsolote in terms of technology as time passes by, and end up being considered a mid-range item and finally a low-cost item. The evolution of the retail price of the item over time is a good indicator of this effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way as in the set of models explained before where clusters were obtained for the product categories, the objective of this clustering is to provide the prediction model with a grouping of the items, so that it is easier for the model to find a pattern (if it exists) within products belonging to the same group. In the cases in which the retail price of the same product changes throughout the different auctions, each unique combination of the product description and retail price has been considered as a different item.\n",
    "\n",
    "Duplicated combinations of product description and retail prices have been removed from the input data given to the clustering algorithm so that each different product has the same weight for the clustering. This way, the same product might be associated to a different cluster according to the retail price that it has at a certain point of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 1769 unique products (according to their product description) contained in the dataset, 1298 products have only one retail price over time, 307 products have two different retail prices, 135 products have three different retail prices, 25 products have four different retail prices, 2 products have five different retail prices, 1 product has six different retail prices, and 1 product has 14 different retail prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1769"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outcomesDf['desc'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     1298\n",
       "2      307\n",
       "3      135\n",
       "4       25\n",
       "5        2\n",
       "6        1\n",
       "14       1\n",
       "Name: desc_count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame containing unique combinations of the columns \"desc\" and \"retail\" (the same product\n",
    "#is auctioned more than once over time, and sometimes it is associated to a different retail price)\n",
    "descAndRetailAllPricesCombinations = outcomesDf.groupby(['desc','retail']).size().reset_index()\n",
    "descAndRetailAllPricesCombinations = descAndRetailAllPricesCombinations.drop(0,axis=1)\n",
    "#count of unique different retail prices for each unique product description\n",
    "countOfDifferentRetailPricesOverTime = descAndRetailAllPricesCombinations['desc'].value_counts()\n",
    "descAndRetailAllPricesCombinations = descAndRetailAllPricesCombinations.merge(countOfDifferentRetailPricesOverTime.to_frame(),how='left',left_on='desc',right_index=True)\n",
    "descAndRetailAllPricesCombinations = descAndRetailAllPricesCombinations.rename(columns={'desc_x': 'desc', 'desc_y': 'desc_count'})\n",
    "\n",
    "descAndRetailAllPricesCombinationsCount = descAndRetailAllPricesCombinations.groupby(['desc','desc_count']).size().reset_index()\n",
    "descAndRetailAllPricesCombinationsCount = descAndRetailAllPricesCombinationsCount.drop(0,axis=1)\n",
    "descAndRetailAllPricesCombinationsCount['desc_count'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training part, the K-Means algorithm is used to obtain the clusters. The input given to the clustering algorithm is the word embedding vector and the retail price of each different product (where, as explained above, unique combinations of the same product description with a different retail price counts as a different product)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word embedding vector length is 300 features, and in total, there are 1769 word embedding vectors (unique products):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 1769)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productDescriptionToVectorDf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics for all values contained in all word embedding products are shown below. The values range approximately from -0.5 to 0.5, and the mean and median of the values are approximately zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value: -0.494140625\n",
      "Maximum value: 0.50732421875\n",
      "Mean value: -0.008482887480809824\n",
      "Median value: -0.007725306919642857\n",
      "Standard deviation: 0.09389948714274118\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum value: \"+str(productDescriptionToVectorDf.stack().min()))\n",
    "print(\"Maximum value: \"+str(productDescriptionToVectorDf.stack().max()))\n",
    "print(\"Mean value: \"+str(productDescriptionToVectorDf.stack().mean()))\n",
    "print(\"Median value: \"+str(productDescriptionToVectorDf.stack().median()))\n",
    "print(\"Standard deviation: \"+str(productDescriptionToVectorDf.stack().std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retail prices of the items are much higher, and therefore, if they are not scaled accordingly, they would have a higher influence when forming the clusters than the product categories. A Min-Max scaler could be used to scale the retail prices (of the unique combinations of product descriptions and retail prices) between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "descAndRetailPricesCombinations = outcomesDf.groupby(['desc','retail']).size().reset_index()\n",
    "descAndRetailPricesCombinations = descAndRetailPricesCombinations.drop(0,axis=1)\n",
    "#min-max scaler\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "#retail prices now range from 0 to 1\n",
    "retail_std = scaler.fit_transform(pd.DataFrame(descAndRetailPricesCombinations['retail']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nevertheless, the mean and median that are obtained after scaling are very close to the minimum value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value: 0.0\n",
      "Maximum value: 1.0\n",
      "Mean value: 0.0155919137861\n",
      "Median value: 0.00610957230143\n",
      "Standard deviation: 0.0277558148788\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum value: \"+str(np.min(retail_std)))\n",
    "print(\"Maximum value: \"+str(np.max(retail_std)))\n",
    "print(\"Mean value: \"+str(np.mean(retail_std)))\n",
    "print(\"Median value: \"+str(np.median(retail_std)))\n",
    "print(\"Standard deviation: \"+str(np.std(retail_std)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because the Min-Max scaler is very sensitive to the presence of outliers. While the median of the retail prices of all auctioned items is approximately 90\\$, the maximum retail price found in the dataset corresponds to a car with a retail price of 24550\\$. Therefore, a robust scaler is more appropiate in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.989999999999995"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(outcomesDf['retail'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>item</th>\n",
       "      <th>desc</th>\n",
       "      <th>retail</th>\n",
       "      <th>price</th>\n",
       "      <th>finalprice</th>\n",
       "      <th>bidincrement</th>\n",
       "      <th>bidfee</th>\n",
       "      <th>winner</th>\n",
       "      <th>...</th>\n",
       "      <th>freebids</th>\n",
       "      <th>endtime_str</th>\n",
       "      <th>flg_click_only</th>\n",
       "      <th>flg_beginnerauction</th>\n",
       "      <th>flg_fixedprice</th>\n",
       "      <th>flg_endprice</th>\n",
       "      <th>bids_placed</th>\n",
       "      <th>swoopo_sale_price</th>\n",
       "      <th>swoopo_profit</th>\n",
       "      <th>winner_benefit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95421</th>\n",
       "      <td>217223</td>\n",
       "      <td>10013607</td>\n",
       "      <td>2009-mini-cooper-chili-red-and-black-con</td>\n",
       "      <td>2009 Mini Cooper Chili Red and Black Convertible</td>\n",
       "      <td>24550.0</td>\n",
       "      <td>3939.36</td>\n",
       "      <td>3939.36</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.6</td>\n",
       "      <td>CaCO3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-07 15:08:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32828.0</td>\n",
       "      <td>22739.251441</td>\n",
       "      <td>-1810.748559</td>\n",
       "      <td>19017.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       auction_id  product_id                                      item  \\\n",
       "95421      217223    10013607  2009-mini-cooper-chili-red-and-black-con   \n",
       "\n",
       "                                                   desc   retail    price  \\\n",
       "95421  2009 Mini Cooper Chili Red and Black Convertible  24550.0  3939.36   \n",
       "\n",
       "       finalprice  bidincrement  bidfee winner       ...        freebids  \\\n",
       "95421     3939.36          0.12     0.6  CaCO3       ...               0   \n",
       "\n",
       "               endtime_str flg_click_only  flg_beginnerauction  \\\n",
       "95421  2009-09-07 15:08:00              0                    0   \n",
       "\n",
       "       flg_fixedprice  flg_endprice  bids_placed  swoopo_sale_price  \\\n",
       "95421               0             0      32828.0       22739.251441   \n",
       "\n",
       "       swoopo_profit  winner_benefit  \n",
       "95421   -1810.748559        19017.64  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomesDf.sort_values(by='retail',ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure shows the histogram of the retail prices corresponding to the unique combinations of product description and retail prices. As it can be seen, the distribution is right skewed and most of the retail prices range up to 500\\$. The retail prices above 500\\$ can be considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f5ecc4f63c8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/EAAAFTCAYAAABxioxZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5ebfe3abe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(17,5))\n",
    "\n",
    "plt.xticks(np.arange(0, 3000, 50),rotation=90)\n",
    "plt.hist(descAndRetailPricesCombinations['retail'], color = 'blue', edgecolor = 'black', bins = 2000)\n",
    "plt.xlim(0,3000)\n",
    "plt.xlabel('Retail price')\n",
    "plt.ylabel('Number of items')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retail price of 500\\$ is reached at the 75% percentile of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499.97000000000003"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(descAndRetailPricesCombinations['retail'],75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following robust scaler uses a similar method to the Min-Max scaler, but instead of the maximum and minimum values, it uses percentiles instead, and so it is robust to outliers because it is not influenced by a few number of very large marginal outliers. In this case, the distribution is right skewed and the outliers have been considered to be at the 75% percentile, so the percentiles have been set to 0% and 75%. Of course, this means that it is using less data for scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "descAndRetailPricesCombinations = outcomesDf.groupby(['desc','retail']).size().reset_index()\n",
    "descAndRetailPricesCombinations = descAndRetailPricesCombinations.drop(0,axis=1)\n",
    "#robust scaler\n",
    "scaler = preprocessing.RobustScaler(quantile_range=(0.0, 75.0))\n",
    "retail_std = scaler.fit_transform(pd.DataFrame(descAndRetailPricesCombinations['retail']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, the median of the scaled prices is zero, in the same way as with the word embedding vectors. Note that the outliers themselves are still present in the transformed data, and so, the minimum and maximum values are not 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value: -0.29999799988\n",
      "Maximum value: 48.8029481769\n",
      "Mean value: 0.465610903552\n",
      "Median value: 0.0\n",
      "Standard deviation: 1.36289228409\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum value: \"+str(np.min(retail_std)))\n",
    "print(\"Maximum value: \"+str(np.max(retail_std)))\n",
    "print(\"Mean value: \"+str(np.mean(retail_std)))\n",
    "print(\"Median value: \"+str(np.median(retail_std)))\n",
    "print(\"Standard deviation: \"+str(np.std(retail_std)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word embedding vector length is 300 features. Therefore, the scaled retail prices values have to be multiplied by 300 so that they have a similar weight as the word embedding vectors during the cluster calculation process. \n",
    "\n",
    "Since the robust scaler percentiles have been defined as 0% and 75%, only 75% of the data will have a similar weight as the word embedding vectors during the cluster calculation process. The other 25% of data has been considered to contain outliers during the scaling and will have a higher weight than the word embedding vectors during the cluster calculation process. Therefore, some clusters will be formed almost exclusively by the condition that the retail prices of the items belonging to it are extremely high. This behaviour is alright, since items with very high retail prices will most likely reach very high selling prices accordingly, independently of the product category that they belong to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of the clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   desc  cat_cluster   retail\n",
      "0            LG  26.5 Cu. Ft. Side by Side Refrigerator            3  1399.99\n",
      "102             ASUS N90 Series N90Sv-X1 18.4\" NoteBook            3  1599.99\n",
      "104                      ASUS N90Sv-A2 18.4-Inch Laptop            3  1599.99\n",
      "105                      ASUS N90Sv-B1 18.4-Inch Laptop            3  1445.00\n",
      "109                              ATV 200cc XLarge Sport            3  1650.00\n",
      "118                   Acer AS8730-6951 18.4-Inch Laptop            3  1449.99\n",
      "124       Acer Aspire 8930G 18\" Core2Duo Laptop (Vista)            3  1599.00\n",
      "132              Acer Aspire AS8930-6243 18-Inch Laptop            3  1470.68\n",
      "141                  Acer Aspire Predator G7710 Desktop            3  1599.99\n",
      "142                  Acer Aspire Predator G7710 Desktop            3  1659.00\n",
      "176            Apple LED iMac M952LL/A  27-Inch Desktop            3  1688.00\n",
      "177            Apple LED iMac M952LL/A  27-Inch Desktop            3  1699.00\n",
      "195                  Apple MacBook Pro 13.3\" + 200 Bids            3  1719.00\n",
      "196              Apple MacBook Pro 13.3\" + 200 FreeBids            3  1719.00\n",
      "198        Apple MacBook Pro MB991LL/A 13.3-Inch Laptop            3  1499.00\n",
      "199        Apple MacBook Pro MB991LL/A 13.3-Inch Laptop            3  1599.00\n",
      "200        Apple MacBook Pro MB991LL/A 13.3-Inch Laptop            3  1599.99\n",
      "201        Apple MacBook Pro MB991LL/A 13.3-Inch Laptop            3  1699.84\n",
      "202        Apple MacBook Pro MB991LL/A 13.3-Inch Laptop            3  1749.00\n",
      "208                Apple iMac MB418LL/A 24-Inch Desktop            3  1478.98\n",
      "256                      Asus N90Sv-A1 18.4-Inch Laptop            3  1468.99\n",
      "257                      Asus N90Sv-A1 18.4-Inch Laptop            3  1599.00\n",
      "657   Epson PowerLite  720p 3LCD Home Theater Projector            3  1599.99\n",
      "736      Gaggia Platinum Vision 90950  Espresso Machine            3  1699.99\n",
      "827                      HP IQ506 TouchSmart Desktop PC            3  1499.99\n",
      "843               HP Pavilion DV5-1000US 15.4\" Notebook            3  1375.00\n",
      "847      HP Pavilion DV6880SE 15.4\" Core 2 Duo Notebook            3  1499.99\n",
      "851                 HP Pavilion Elite M9180F Desktop PC            3  1399.00\n",
      "853                 HP Pavilion Elite M9520F Desktop PC            3  1444.00\n",
      "855           HP Pavilion HDX16-1160US 16.0-Inch Laptop            3  1687.00\n",
      "...                                                 ...          ...      ...\n",
      "1988         Sony Bravia KDL-40V5100 40\" 1080p LCD HDTV            3  1499.99\n",
      "1990      Sony Bravia KDL-40XBR9 40\" 1080p 240Hz LCD TV            3  1499.99\n",
      "1991      Sony Bravia KDL-40XBR9 40\" 1080p 240Hz LCD TV            3  1599.00\n",
      "1998  Sony Bravia V-Series KDL-40V4100 40\" 1080p LCD TV            3  1399.00\n",
      "1999  Sony Bravia V-Series KDL-40V4100 40\" 1080p LCD TV            3  1499.99\n",
      "2037     Sony KDL-40VE5 40\" 1080p Eco-friendly LCD HDTV            3  1699.99\n",
      "2058       Sony VAIO VGN-AR610E 17\" Core 2 Duo Notebook            3  1599.99\n",
      "2059     Sony VAIO VGN-AR720E/B 17\" Core 2 Duo Notebook            3  1499.99\n",
      "2061        Sony VAIO VGN-AW110J/H 18.4\" Laptop (Vista)            3  1599.00\n",
      "2062        Sony VAIO VGN-AW110J/H 18.4\" Laptop (Vista)            3  1599.99\n",
      "2066            Sony VAIO VGN-AW220J/B 18.4-Inch Laptop            3  1449.99\n",
      "2067            Sony VAIO VGN-AW350J/B 18.4-Inch Laptop            3  1516.99\n",
      "2075              Sony VAIO VGN-FW170J/H 16.4\" Notebook            3  1399.99\n",
      "2078   Sony VAIO VGN-FW285J 16.4\" Core2Duo Vista Laptop            3  1649.99\n",
      "2079          Sony VAIO VGN-FW285J/B 16\" Laptop (Vista)            3  1549.99\n",
      "2080          Sony VAIO VGN-FW285J/B 16\" Laptop (Vista)            3  1649.99\n",
      "2087        Sony VAIO VGN-SR210J/S 13.3\" Laptop (Vista)            3  1399.99\n",
      "2089      Sony VAIO VPC-L113FX/B 24-Inch All-in-One  PC            3  1399.00\n",
      "2093   Sony Vaio VGN-FW170J/H 16.4\" Core 2 Duo Notebook            3  1399.99\n",
      "2094   Sony Vaio VGN-FW170J/H 16.4\" Core 2 Duo Notebook            3  1455.72\n",
      "2095   Sony Vaio VGN-FW170J/H 16.4\" Core 2 Duo Notebook            3  1509.95\n",
      "2229             Toshiba Qosmio X505-Q830 Gaming Laptop            3  1449.00\n",
      "2230      Toshiba REGZA 42XV540U 42-Inch 1080p LCD HDTV            3  1399.99\n",
      "2233          Toshiba REGZA 46RV535U 46\" 1080p LCD HDTV            3  1499.99\n",
      "2234      Toshiba REGZA 46SV670U 46-Inch 1080p LCD HDTV            3  1699.99\n",
      "2236      Toshiba REGZA 47ZV650U 47-Inch 1080p LCD HDTV            3  1699.99\n",
      "2311               Velocity Micro Edge Gx440 Desktop PC            3  1599.99\n",
      "2324           Viewsonic Pro8100 Home Theater Projector            3  1399.00\n",
      "2364   Whirlpool 21.8 Cu. Ft. Side-By-Side Refrigerator            3  1399.00\n",
      "2365   Whirlpool 21.8 Cu. Ft. Side-By-Side Refrigerator            3  1499.99\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "                                                   desc  cat_cluster  retail\n",
      "1        Philips SE7452B Advanced Cordless Phone System            1  149.99\n",
      "30       10k White Gold Black Diamond Infinity Earrings            1  129.99\n",
      "31              10k White Gold Diamond Teardrop Pendant            1  129.99\n",
      "32           12' x 30\" Family Size Metal Frame Pool Set            1  134.99\n",
      "33           12' x 30\" Family Size Metal Frame Pool Set            1  159.99\n",
      "34     14k White Gold \"Key-to-My-Heart\" Diamond Pendant            1  129.99\n",
      "36           14k White Gold Round Diamond Stud Earrings            1  199.99\n",
      "51                                     300 Bids Voucher            1  150.00\n",
      "52                                     300 Bids Voucher            1  180.00\n",
      "53                                     300 Bids Voucher            1  225.00\n",
      "54                                 300 FreeBids Voucher            1  225.00\n",
      "66                 8-Piece Stainless-Steel Cookware Set            1  169.99\n",
      "67                 8-Piece Stainless-Steel Cookware Set            1  189.99\n",
      "163     All-Clad Stainless All-Purpose Steamer with Lid            1  154.99\n",
      "164    All-Clad Stainless-Steel 6-1/2-Quart Slow Cooker            1  199.99\n",
      "166   Alton's Angles by Shun Angled 6-Inch Chef's Knife            1  140.00\n",
      "221     Apple iPod classic 120 GB Black (6h generation)            1  224.89\n",
      "222     Apple iPod classic 120 GB Black (6h generation)            1  249.00\n",
      "223   Apple iPod classic 120 GB Silver (6th generation)            1  249.00\n",
      "224          Apple iPod classic 160 GB (7th Generation)            1  234.99\n",
      "225          Apple iPod classic 160 GB (7th Generation)            1  249.99\n",
      "226          Apple iPod classic 160 GB (7th Generation)            1  259.99\n",
      "227        Apple iPod nano 16 GB Black (4th generation)            1  199.00\n",
      "228       Apple iPod nano 16 GB Silver (4th generation)            1  199.00\n",
      "229         Apple iPod nano 8 GB Black (5th Generation)            1  139.99\n",
      "230         Apple iPod nano 8 GB Black (5th Generation)            1  169.99\n",
      "231         Apple iPod nano 8 GB Black (5th Generation)            1  179.99\n",
      "239              Apple iPod touch 8 GB (new generation)            1  214.99\n",
      "240              Apple iPod touch 8 GB (new generation)            1  229.00\n",
      "260         Audiovox 7\" Twin Screen Portable DVD Player            1  199.99\n",
      "...                                                 ...          ...     ...\n",
      "2226                    Toshiba Portable External 500GB            1  149.99\n",
      "2259        Towle 45 Piece Stainless 18/10 Flatware Set            1  270.00\n",
      "2280  TrekStor DataStation 1.8\" Mini External Hard D...            1  209.99\n",
      "2283  TropiLight Lighted Bronze Aluminum Market Umbr...            1  119.99\n",
      "2295       URC-R50 Digital R50 Universal Remote Control            1  169.99\n",
      "2304                   Uniflame Black Outdoor Fireplace            1  199.95\n",
      "2318        Verizon VZ-V300AM-2 DECT 6.0 Cordless Phone            1  119.99\n",
      "2321   ViewSonic VX2240w 22-inch Widescreen LCD Monitor            1  205.98\n",
      "2332    VitaClay Gourmet 6-Cup Rice and Slow Cooker Pro            1  160.00\n",
      "2356     Western Digital My Passport 500 GB  Hard Drive            1  118.99\n",
      "2357     Western Digital My Passport 500 GB  Hard Drive            1  119.99\n",
      "2358   Western Digital My Passport Elite 320GB Titanium            1  189.99\n",
      "2362   Western Digital My Passport Essential 320GB Blue            1  169.99\n",
      "2393                Wii | Nintendo Console + Wii Sports            1  199.99\n",
      "2394                Wii | Nintendo Console + Wii Sports            1  219.99\n",
      "2395                Wii | Nintendo Console + Wii Sports            1  249.99\n",
      "2397              Wilson / Staff 88 Series Blade Putter            1  129.99\n",
      "2398                   Wilson Staff Tour Carry Golf Bag            1  179.99\n",
      "2407                            Xbox 360 Arcade Console            1  199.99\n",
      "2408  Xbox 360 Arcade Console with Sega Superstar Te...            1  199.99\n",
      "2409  Xbox 360 Arcade Console with Sega Superstar Te...            1  269.99\n",
      "2422        Zojirushi Home Bakery Supreme Bread Machine            1  214.99\n",
      "2425                         Zotac IONITX-A-U Atom N330            1  189.99\n",
      "2426                         Zotac IONITX-A-U Atom N330            1  219.99\n",
      "2427               Zune 120 GB Video MP3 Player (Black)            1  249.99\n",
      "2428                Zune 16 GB Video MP3 Player (Black)            1  199.99\n",
      "2429             Zune 8 GB Digital Media Player (Black)            1  179.00\n",
      "2430             Zune 8 GB Digital Media Player (Black)            1  199.00\n",
      "2441               igourmet Truffle Lover's Gift Basket            1  129.99\n",
      "2444         iriver P7 16 GB Multimedia Player (Silver)            1  209.99\n",
      "\n",
      "[440 rows x 3 columns]\n",
      "                                                   desc  cat_cluster  retail\n",
      "2                                        Tekken 6 (PS3)            8   49.99\n",
      "3        VTech Kidizoom: Multimedia Digital Camera Pink            8   69.99\n",
      "4        VTech Kidizoom: Multimedia Digital Camera Pink            8   71.99\n",
      "8                                   $15 Florist Voucher            8   15.00\n",
      "9                                   $30 Florist Voucher            8   30.00\n",
      "13                                            $80 Cash!            8   80.00\n",
      "37         1:16 Scale Hobby Grade R/C Mercedes Benz SLR            8   47.98\n",
      "38         1:16 Scale Hobby Grade R/C Mercedes Benz SLR            8   56.99\n",
      "39           1TB LaCie Hard Disk Design by Neil Poulton            8   95.99\n",
      "40           1TB LaCie Hard Disk Design by Neil Poulton            8   99.99\n",
      "41                                      20 Bids Voucher            8   10.00\n",
      "42                                      20 Bids Voucher            8   12.00\n",
      "43                                      20 Bids Voucher            8   15.00\n",
      "45     3-Feet Carolina Artificial Prelit Christmas Tree            8   64.99\n",
      "50                                        300 (Blu-ray)            8   34.99\n",
      "56            32GB DataTraveler 200 USB 2.0 Flash Drive            8   99.99\n",
      "57                             5 g Gold Bar (0.16 t oz)            8  114.82\n",
      "58                                      50 Bids Voucher            8   25.00\n",
      "59                                      50 Bids Voucher            8   30.00\n",
      "60                                      50 Bids Voucher            8   37.50\n",
      "61                             50 First Dates [Blu-ray]            8   28.95\n",
      "62                                  50 FreeBids Voucher            8   37.50\n",
      "63                                  50 FreeBids Voucher            8   50.00\n",
      "64                                      75 Bids Voucher            8   45.00\n",
      "65                                      75 Bids Voucher            8   56.25\n",
      "68                                 A Vampyre Story (PC)            8   29.99\n",
      "69               AMF Bowling Pinbusters! (Nintendo Wii)            8   19.99\n",
      "111                       AccuSharp 001 Knife Sharpener            8   13.99\n",
      "130              Acer Aspire AS8930-6243 18-Inch Laptop            8    0.00\n",
      "154                    Aion: The Tower of Eternity (PC)            8   46.99\n",
      "...                                                 ...          ...     ...\n",
      "2382             Wii Play (includes Wii Remote Control)            8   44.49\n",
      "2383             Wii Play (includes Wii Remote Control)            8   44.96\n",
      "2384             Wii Play (includes Wii Remote Control)            8   49.99\n",
      "2385                           Wii Play with Wii Remote            8   49.99\n",
      "2386              Wii Sports Resort with Wii MotionPlus            8   46.99\n",
      "2387              Wii Sports Resort with Wii MotionPlus            8   49.99\n",
      "2388              Wii Sports Resort with Wii MotionPlus            8   59.95\n",
      "2389              Wii Sports Resort with Wii MotionPlus            8   59.99\n",
      "2390                            Wii Wireless Sensor Bar            8   14.99\n",
      "2391                            Wii Wireless Sensor Bar            8   15.99\n",
      "2392                            Wii Wireless Sensor Bar            8   19.99\n",
      "2400       World in Conflict: Soviet Assault (XBox 360)            8   59.99\n",
      "2401     World of WarCraft: Wrath of the Lich King (PC)            8   39.99\n",
      "2410       Xbox 360 Live 3-month Subscription Gold Card            8   19.99\n",
      "2411        Xbox 360 Modern Warfare 2 Combat Controller            8   49.99\n",
      "2412      Xbox 360 Modern Warfare 2 Throat Communicator            8   29.63\n",
      "2418        YogaAccessories Nylon Zippered Yoga Mat Bag            8   12.99\n",
      "2419   Yves Saint Laurent Body Kouros 3.3oz EdT For Men            8   65.00\n",
      "2420       Yves Saint Laurent Kouros 1.6oz. edt for men            8   32.00\n",
      "2421             Ziga DF710-ZUS/IR 7-Inch Digital Frame            8   59.99\n",
      "2423      Zojirushi Thermal Carafe Coffee Maker (10-c.)            8   89.99\n",
      "2424                         Zoo Hospital (Nintendo DS)            8   29.99\n",
      "2433                                    Zune HD AV Dock            8   64.99\n",
      "2434                                    Zune HD AV Dock            8   89.99\n",
      "2436         iHome Rechargeable Mini Speakers for iPods            8   56.25\n",
      "2437           iHome iP9SR Clock Radio for iPod, iPhone            8   81.99\n",
      "2438  iLive Stereo Speaker System with iPod Dock (Bl...            8   49.99\n",
      "2442          iriver E100 4 GB Multimedia Player (Blue)            8   99.99\n",
      "2443          iriver E100 4 GB Multimedia Player (Pink)            8   99.99\n",
      "2446     lHannah Montana: The Movie Enhanced Soundtrack            8   18.98\n",
      "\n",
      "[1066 rows x 3 columns]\n",
      "                                                   desc  cat_cluster   retail\n",
      "5                                          $1,000 Cash!            0  1000.00\n",
      "6                             $1000 iPhone 3G Gift Card            0   748.22\n",
      "7                             $1000 iPhone 3G Gift Card            0  1000.00\n",
      "12                             $799 iPhone 3G Gift Card            0   799.99\n",
      "14                            1 Ounce Gold Bar (31.10g)            0  1007.00\n",
      "15                            1 Ounce Gold Bar (31.10g)            0  1020.34\n",
      "16                            1 Ounce Gold Bar (31.10g)            0  1020.35\n",
      "91                                     ASUS Eee PC S101            0   749.99\n",
      "94         ASUS Eee Top 21.6-Inch All-in-One Desktop PC            0   899.99\n",
      "99                            ASUS N10J-A2 10.2\" Laptop            0   799.00\n",
      "106               ASUS UL50VT-A1 15.6-Inch Black Laptop            0   825.00\n",
      "107                   ASUS X71SL-C1 17-Inch WXGA Laptop            0   774.51\n",
      "112             Acer AS7720-6135 17-inch Laptop (Vista)            0   849.99\n",
      "114                   Acer AS8730-6918 18.4-Inch Laptop            0   899.99\n",
      "115                   Acer AS8730-6951 18.4-Inch Laptop            0   905.24\n",
      "119           Acer AS8730-6951 18.4-Inch Laptop (Vista)            0   905.24\n",
      "123                Acer Aspire 7720-4428 17-Inch Laptop            0   799.99\n",
      "126                     Acer Aspire AS6530 16\" Notebook            0   899.99\n",
      "127     Acer Aspire AS6920-6508 16\" Core 2 Duo Notebook            0   999.99\n",
      "149                                  Acer M670G Desktop            0   868.69\n",
      "150                                  Acer M670G Desktop            0   869.99\n",
      "151                                  Acer M670G Desktop            0   875.99\n",
      "152                          Acer Veriton M670G Desktop            0   899.99\n",
      "153           Adee Kaye Sparrow Chronograph Gents Watch            0   749.81\n",
      "175                      Apple $898 iPhone 3G Gift Card            0   898.00\n",
      "192            Apple MacBook MB881LL/A 13.3-Inch Laptop            0   999.00\n",
      "193            Apple MacBook MC207LL/A 13.3-Inch Laptop            0   959.99\n",
      "194            Apple MacBook MC207LL/A 13.3-Inch Laptop            0   999.99\n",
      "215                       Apple iPhone 3GS 32GB (Black)            0   898.00\n",
      "216          Apple iPhone 3GS 32GB Black + 150 FreeBids            0   988.00\n",
      "...                                                 ...          ...      ...\n",
      "1985         Sony Bravia KDL-40V5100 40\" 1080p LCD HDTV            0   861.99\n",
      "1986         Sony Bravia KDL-40V5100 40\" 1080p LCD HDTV            0   979.99\n",
      "1987         Sony Bravia KDL-40V5100 40\" 1080p LCD HDTV            0   993.43\n",
      "1993   Sony Bravia KDL-46V5100 46\" 1080p 120Hz LCD HDTV            0   999.99\n",
      "1997  Sony Bravia M-Series KDL-32M4000/T 32\" 720p LC...            0   899.99\n",
      "2024      Sony Ericsson XPERIA X1 Cell Phone - Unlocked            0   754.37\n",
      "2025      Sony Ericsson XPERIA X1 Cell Phone - Unlocked            0   999.99\n",
      "2055        Sony VAIO Lifestyle VGN-P688E 8-Inch Laptop            0   899.99\n",
      "2056      Sony VAIO Lifestyle VGN-P688E/G 8-Inch Laptop            0   899.99\n",
      "2057                  Sony VAIO VGC-JS110J/B Desktop PC            0   999.99\n",
      "2081            Sony VAIO VGN-NW120J/W 15.5-Inch Laptop            0   799.99\n",
      "2082            Sony VAIO VGN-NW120J/W 15.5-Inch Laptop            0   833.99\n",
      "2083           Sony VAIO VGN-NW280F/B 15.5-Inch  Laptop            0   919.99\n",
      "2084           Sony VAIO VGN-NW280F/B 15.5-Inch  Laptop            0   929.99\n",
      "2085            Sony VAIO VGN-P530H/G 8\" (Vista, Green)            0   799.99\n",
      "2086            Sony VAIO VGN-P530H/G 8\" (Vista, Green)            0   899.99\n",
      "2088        Sony VAIO VGN-SR510 Series 13.3-Inch Laptop            0   999.99\n",
      "2231      Toshiba REGZA 42ZV650U 42-Inch 1080p LCD HDTV            0  1019.17\n",
      "2238          Toshiba Regza 32RV530U 32\" 1080p LCD HDTV            0   899.99\n",
      "2243      Toshiba Satellite A215-S6814 15.4-inch Laptop            0   929.99\n",
      "2244       Toshiba Satellite A305D-S6851 15.4\" Notebook            0   799.99\n",
      "2246    Toshiba Satellite A355-S6935 16\" Laptop (Vista)            0   899.99\n",
      "2248      Toshiba Satellite A355-S6943 16.0-Inch Laptop            0   948.97\n",
      "2250                       Toshiba Satellite L355-S7835            0   849.99\n",
      "2251   Toshiba Satellite L355D-S7809 17\" Laptop (Vista)            0   799.99\n",
      "2369           Whirlpool WED9400SW Duet  Electric Dryer            0   899.00\n",
      "2370           Whirlpool WED9400SW Duet  Electric Dryer            0   905.00\n",
      "2371         Whirlpool WFW9400SW Duet Front-Load Washer            0   919.00\n",
      "2372         Whirlpool WFW9450WL Duet Front-Load Washer            0   999.99\n",
      "2417     Yamaha YSP-900 Digital Sound Projector (Black)            0   899.95\n",
      "\n",
      "[154 rows x 3 columns]\n",
      "                                                   desc  cat_cluster  retail\n",
      "10                                           $320 Cash!            4  320.00\n",
      "29                                     10 Gram Gold Bar            4  337.39\n",
      "35              14k White Gold 3-Stone Teardrop Pendant            4  359.99\n",
      "55                                 300 FreeBids Voucher            4  300.00\n",
      "70           ASUS Eee PC 1000 10\" 40GB HD Linux (White)            4  373.36\n",
      "72             ASUS Eee PC 1000 10\" 40GB HD Linux Black            4  373.36\n",
      "75             ASUS Eee PC 1000 10\" 40GB HD Linux White            4  373.36\n",
      "78               ASUS Eee PC 1000 10-Inch Mini-Notebook            4  373.36\n",
      "82               ASUS Eee PC 1000HE 10\" Netbook (Black)            4  399.00\n",
      "83                ASUS Eee PC 1000HE 10\" Netbook (Blue)            4  399.00\n",
      "84             ASUS Eee PC 1002HA 10-Inch Mini-Notebook            4  410.94\n",
      "85             ASUS Eee PC 1002HA 10-Inch Mini-Notebook            4  429.99\n",
      "86          ASUS Eee PC 1005HA-PU1X-BU Seashell Netbook            4  358.99\n",
      "87          ASUS Eee PC 1005HA-PU1X-BU Seashell Netbook            4  379.99\n",
      "88          ASUS Eee PC 1005HA-PU1X-BU Seashell Netbook            4  389.99\n",
      "89         ASUS Eee PC 1101HA-MU1X-BK 11.6-Inch Netbook            4  429.99\n",
      "90         ASUS Eee PC 1101HA-MU1X-BK 11.6-Inch Netbook            4  459.99\n",
      "125                Acer Aspire AH340-UA230N Home Server            4  399.99\n",
      "133              Acer Aspire One 10.1-Inch Blue Netbook            4  329.99\n",
      "134      Acer Aspire One A110L 8.9\" Mini Notebook White            4  399.99\n",
      "135        Acer Aspire One AOD150 10.1\" Netbook (Black)            4  329.99\n",
      "136        Acer Aspire One AOD150 10.1\" Netbook (Black)            4  349.99\n",
      "137          Acer Aspire One AOD150 10.2\" Mini-Notebook            4  349.00\n",
      "138      Acer Aspire One AOD150-1165 10\" Netbook (Blue)            4  349.99\n",
      "139     Acer Aspire One AOD150-1920 10.1\" Netbook (Red)            4  349.99\n",
      "140                  Acer Aspire One D150 10.1\" Netbook            4  379.99\n",
      "148     Acer B193W Bdmh 19-Inch Wide-screen LCD Monitor            4  281.33\n",
      "156                            Aiptek Pocket Cinema V10            4  299.99\n",
      "158                     Airzone 14-Foot Band Trampoline            4  339.99\n",
      "167                                     Amazon Kindle 2            4  359.00\n",
      "...                                                 ...          ...     ...\n",
      "2157                TaylorMade Men's r7 Quad 425 Driver            4  399.00\n",
      "2188                           TiVo TCD658000 HD XL DVR            4  457.50\n",
      "2196      TomTom GO 730 4.3-Inch Portable GPS Navigator            4  299.99\n",
      "2197   TomTom GO 730 4.3-Inch Touchscreen GPS Navigator            4  449.95\n",
      "2198               TomTom GO 740 4.3-Inch GPS Navigator            4  399.99\n",
      "2199   TomTom GO 930 4.3-Inch Touchscreen GPS Navigator            4  399.99\n",
      "2204    TomTom ONE 130S 3.5-Inch Portable GPS Navigator            4  279.95\n",
      "2216     Toshiba 19AV500U 19-Inch 720p LCD HDTV (Black)            4  299.99\n",
      "2290           Twin Cuisine Knife Block Set by Henckels            4  359.99\n",
      "2322   ViewSonic VX2240w 22-inch Widescreen LCD Monitor            4  451.13\n",
      "2343        WORX ECO WG780 Cordless Electric Lawn Mower            4  429.99\n",
      "2367             Whirlpool Tall Tub Built-In Dishwasher            4  399.99\n",
      "2368             Whirlpool Tall Tub Built-In Dishwasher            4  459.99\n",
      "2396                Wii | Nintendo Console + Wii Sports            4  349.99\n",
      "2399        Windows Vista Ultimate 32 Bit (OEM Version)            4  289.99\n",
      "2402                         WowWee Robosapien RS Media            4  299.00\n",
      "2403                              XBOX 360 Elite Bundle            4  299.99\n",
      "2404                              XBOX 360 Elite Bundle            4  329.99\n",
      "2405                   XBOX 360 Modern Warfare 2 Bundle            4  399.99\n",
      "2406                   XBOX 360 Modern Warfare 2 Bundle            4  429.99\n",
      "2413       Xbox 360 Red Elite Edition & Resident Evil 5            4  399.99\n",
      "2414  Xfx Geforce Gtx 285 Pcie 1GB DDR3 2PORT Dvi 67...            4  475.49\n",
      "2415    Yamaha MCR-230BL Micro Component System (Black)            4  349.95\n",
      "2416              Yamaha TSX-120WH Desktop Audio System            4  399.95\n",
      "2431          Zune HD 32 GB Video MP3 Player (Platinum)            4  289.99\n",
      "2432          Zune HD 32 GB Video MP3 Player (Platinum)            4  319.99\n",
      "2435                            Zuo Carter Office Chair            4  384.00\n",
      "2439         iPod Touch Apple 8GB with Software Upgrade            4  299.99\n",
      "2440                  iRobot 560 Roomba Vacuuming Robot            4  449.99\n",
      "2445        iriver SPINN 8 GB Video MP3 Player (Silver)            4  289.99\n",
      "\n",
      "[302 rows x 3 columns]\n",
      "                                                   desc  cat_cluster  retail\n",
      "11                                           $500 Cash!            7  500.00\n",
      "28     1/2 Carat Diamond 14K White Gold Solitaire Studs            7  495.00\n",
      "46                                     30 Ounces Silver            7  492.00\n",
      "47                                     30 Ounces Silver            7  533.59\n",
      "48                                     30 Ounces Silver            7  623.98\n",
      "49                                     30 Ounces Silver            7  661.58\n",
      "71           ASUS Eee PC 1000 10\" 40GB HD Linux (White)            7  499.00\n",
      "73             ASUS Eee PC 1000 10\" 40GB HD Linux Black            7  499.00\n",
      "74             ASUS Eee PC 1000 10\" 40GB HD Linux Black            7  699.99\n",
      "76             ASUS Eee PC 1000 10\" 40GB HD Linux White            7  499.00\n",
      "77             ASUS Eee PC 1000 10\" 40GB HD Linux White            7  699.99\n",
      "79               ASUS Eee PC 1000 10-Inch Mini-Notebook            7  499.00\n",
      "80               ASUS Eee PC 1000 10-Inch Mini-Notebook            7  508.04\n",
      "81                   ASUS Eee PC 1000H 80G Win XP Black            7  549.99\n",
      "92        ASUS Eee PC Touch T91 8.9-Inch Tablet Netbook            7  484.99\n",
      "93        ASUS Eee PC Touch T91 8.9-Inch Tablet Netbook            7  499.99\n",
      "95         ASUS K50IJ-X8 15.6-Inch Entertainment Laptop            7  675.99\n",
      "96                        ASUS N10E-A1 10.2-Inch Laptop            7  669.99\n",
      "97                ASUS N10J-A1 10.2-Inch Laptop (Vista)            7  683.98\n",
      "98                ASUS N10J-A1 10.2-Inch Laptop (Vista)            7  699.00\n",
      "100                      ASUS N10Jh A1 10.2-Inch Laptop            7  699.99\n",
      "113                   Acer AS8730-6918 18.4-Inch Laptop            7  678.93\n",
      "122      Acer Aspire 5720-4649 15.4-inch Laptop (Vista)            7  699.99\n",
      "143         Acer Aspire Timeline 11.6-Inch Black Laptop            7  549.99\n",
      "144         Acer Aspire Timeline 11.6-Inch Black Laptop            7  599.99\n",
      "145               Acer Aspire Timeline 13.3-Inch Laptop            7  599.00\n",
      "146               Acer Aspire Timeline 13.3-Inch Laptop            7  658.90\n",
      "147               Acer Aspire Timeline 13.3-Inch Laptop            7  699.00\n",
      "174                      Apple $898 iPhone 3G Gift Card            7  699.00\n",
      "181                                      Apple Mac Mini            7  599.00\n",
      "...                                                 ...          ...     ...\n",
      "1962          Sony 32L4000 - 32\" HD Ready Bravia LCD TV            7  699.99\n",
      "1966     Sony Alpha A200K 10.2MP Digital SLR Camera Kit            7  499.99\n",
      "1967  Sony Alpha A350K 14MP DSLR Camera & 18-70mm Le...            7  699.99\n",
      "1978        Sony BRAVIA XBR KDL-32XBR9 32-Inch LCD HDTV            7  645.99\n",
      "1979        Sony BRAVIA XBR KDL-32XBR9 32-Inch LCD HDTV            7  675.99\n",
      "1980        Sony BRAVIA XBR KDL-32XBR9 32-Inch LCD HDTV            7  699.99\n",
      "2012              Sony Ericsson C905 - Black (Unlocked)            7  621.90\n",
      "2014                         Sony Ericsson P1i Unlocked            7  599.99\n",
      "2016      Sony Ericsson S500i Unlocked Mysterious Green            7  499.99\n",
      "2018        Sony Ericsson U1i Satio Idou Unlocked Phone            7  725.00\n",
      "2021       Sony Ericsson W760i Intense Black (Unlocked)            7  499.99\n",
      "2022            Sony Ericsson W880i Unlocked Cell Phone            7  599.99\n",
      "2023                 Sony Ericsson W910i Unlocked Black            7  549.99\n",
      "2027      Sony HDR-SR10 40GB Handycam Digital Camcorder            7  649.00\n",
      "2028          Sony HDRXR100 80GB HDD Camcorder (Silver)            7  569.95\n",
      "2029          Sony HDRXR100 80GB HDD Camcorder (Silver)            7  629.99\n",
      "2036         Sony KDL-26M4000/T 26\" 720p LCD HDTV Brown            7  599.99\n",
      "2041        Sony PS3 160 GB + Uncharted: Drakes Fortune            7  499.99\n",
      "2131  Stuhrling Original Classic Men's 'Heritage' Watch            7  610.00\n",
      "2155  Tamron AF 18-200mm f/3.5-6.3 XR Di II LD Zoom ...            7  490.95\n",
      "2187  TiVo TCD648250B Series3 HD Digital Media Recorder            7  504.00\n",
      "2189                           TiVo TCD658000 HD XL DVR            7  599.99\n",
      "2192                          Tivo HD & Slingbox Bundle            7  715.91\n",
      "2200                        TomTom Go 730 GPS Navigator            7  499.99\n",
      "2201                                     TomTom Go 930T            7  549.95\n",
      "2202                                     TomTom Go 930T            7  569.00\n",
      "2217             Toshiba 26AV502R 26-Inch 720p LCD HDTV            7  499.99\n",
      "2218   Toshiba 26LV610U 720p 26\" LCD TV with DVD Player            7  549.99\n",
      "2219             Toshiba 32AV502U 32-Inch 720p LCD HDTV            7  599.99\n",
      "2331                         Vita Mix Super 5200 Series            7  649.00\n",
      "\n",
      "[216 rows x 3 columns]\n",
      "                                                   desc  cat_cluster   retail\n",
      "17                            1 Ounce Gold Bar (31.10g)            5  1035.55\n",
      "18                            1 Ounce Gold Bar (31.10g)            5  1046.06\n",
      "19                            1 Ounce Gold Bar (31.10g)            5  1050.00\n",
      "20                            1 Ounce Gold Bar (31.10g)            5  1060.00\n",
      "21                            1 Ounce Gold Bar (31.10g)            5  1149.00\n",
      "22                            1 Ounce Gold Bar (31.10g)            5  1175.00\n",
      "23                            1 Ounce Gold Bar (31.10g)            5  1199.00\n",
      "24                            1 Ounce Gold Bar (31.10g)            5  1200.00\n",
      "25                            1 Ounce Gold Bar (31.10g)            5  1269.00\n",
      "26                            1 Ounce Gold Bar (31.10g)            5  1299.00\n",
      "27                            1 Ounce Gold Bar (31.10g)            5  1349.00\n",
      "101                      ASUS N51Vf-A1 15.6-Inch Laptop            5  1299.99\n",
      "108                   ASUS X71SL-C1 17-Inch WXGA Laptop            5  1099.00\n",
      "116                   Acer AS8730-6951 18.4-Inch Laptop            5  1199.00\n",
      "117                   Acer AS8730-6951 18.4-Inch Laptop            5  1199.99\n",
      "120           Acer AS8730-6951 18.4-Inch Laptop (Vista)            5  1199.99\n",
      "121                       Acer AS8920-6048 18.4\" Laptop            5  1299.99\n",
      "128                  Acer Aspire AS6920-6886 16\" Laptop            5  1049.99\n",
      "129          Acer Aspire AS6920-6886 16\" Laptop (Vista)            5  1049.99\n",
      "131              Acer Aspire AS8930-6243 18-Inch Laptop            5  1109.44\n",
      "190            Apple MacBook MB466LL/A 13.3-Inch Laptop            5  1094.00\n",
      "191            Apple MacBook MB466LL/A 13.3-Inch Laptop            5  1299.00\n",
      "207                    Apple iMac 20\" Core 2 Duo 2.4GHz            5  1199.00\n",
      "352                  Bossart Automatic City Gents Watch            5  1090.07\n",
      "586   DeLonghi Magnifica Super-Automatic Coffee Machine            5  1260.00\n",
      "718   Frigidaire 22.6 cu. ft. Side by Side Refrigerator            5  1115.99\n",
      "826        HP HDX16-1370US 16-Inch Entertainment Laptop            5  1099.99\n",
      "845             HP Pavilion DV6-1050US 16.0-Inch Laptop            5  1312.00\n",
      "848     HP Pavilion DV9650US 17\" Entertainment Notebook            5  1149.99\n",
      "852                 HP Pavilion Elite M9510F Desktop PC            5  1150.00\n",
      "...                                                 ...          ...      ...\n",
      "1989      Sony Bravia KDL-40XBR9 40\" 1080p 240Hz LCD TV            5  1336.99\n",
      "1994   Sony Bravia KDL-46V5100 46\" 1080p 120Hz LCD HDTV            5  1049.99\n",
      "1995   Sony Bravia KDL-46V5100 46\" 1080p 120Hz LCD HDTV            5  1210.99\n",
      "2026      Sony Ericsson XPERIA X1 Cell Phone - Unlocked            5  1200.00\n",
      "2054                     Sony VAIO CR520E/J  14\" Silver            5  1149.99\n",
      "2060        Sony VAIO VGN-AW110J/H 18.4\" Laptop (Vista)            5  1299.99\n",
      "2065            Sony VAIO VGN-AW220J/B 18.4-Inch Laptop            5  1290.00\n",
      "2068                Sony VAIO VGN-CR408E/B 14.1\" Laptop            5  1249.99\n",
      "2069                        Sony VAIO VGN-CR520E/N Gold            5  1149.99\n",
      "2070                     Sony VAIO VGN-CR520E/R 14\" Red            5  1149.99\n",
      "2071            Sony VAIO VGN-CS180J/W 14.1-Inch Laptop            5  1349.99\n",
      "2072            Sony VAIO VGN-CS260J/Q 14.1-Inch Laptop            5  1099.99\n",
      "2073   Sony VAIO VGN-FW140E 16.4\" Core2Duo Vista Laptop            5  1149.99\n",
      "2074   Sony VAIO VGN-FW140E 16.4\" Core2Duo Vista Laptop            5  1299.99\n",
      "2076        Sony VAIO VGN-FW240J/H 16.4\" Laptop (Vista)            5  1099.99\n",
      "2077        Sony VAIO VGN-FW260J/B 16.4\" Laptop (Vista)            5  1199.99\n",
      "2092                  Sony Vaio VGN-AR820E 17\" Notebook            5  1149.99\n",
      "2227  Toshiba Qosmio G55-Q801 18.4\" Core 2 Duo Notebook            5  1299.99\n",
      "2228             Toshiba Qosmio X505-Q830 Gaming Laptop            5  1349.99\n",
      "2232      Toshiba REGZA 42ZV650U 42-Inch 1080p LCD HDTV            5  1299.99\n",
      "2239          Toshiba Regza 37RV530U 37\" 1080p LCD HDTV            5  1099.99\n",
      "2240          Toshiba Regza 37RV530U 37\" 1080p LCD HDTV            5  1199.99\n",
      "2242          Toshiba Regza 42RV530U 42\" 1080p LCD HDTV            5  1299.99\n",
      "2245       Toshiba Satellite A305D-S6851 15.4\" Notebook            5  1199.00\n",
      "2247      Toshiba Satellite A355-S6940 16.0-Inch Laptop            5  1049.99\n",
      "2249      Toshiba Satellite A355-S6943 16.0-Inch Laptop            5  1149.99\n",
      "2252    Toshiba Satellite P205-S6287 17\" Laptop (Vista)            5  1299.99\n",
      "2323           Viewsonic Pro8100 Home Theater Projector            5  1318.00\n",
      "2349   Weber Genesis S-310 LP Stainless Steel Gas Grill            5  1045.99\n",
      "2366         Whirlpool Duet 4.4 Cu. Ft. 12-Cycle Washer            5  1150.00\n",
      "\n",
      "[118 rows x 3 columns]\n",
      "                                                desc  cat_cluster   retail\n",
      "44  2009 Mini Cooper Chili Red and Black Convertible            2  24550.0\n",
      "                                                   desc  cat_cluster   retail\n",
      "103             ASUS N90 Series N90Sv-X1 18.4\" NoteBook            9  1798.00\n",
      "110                              ATV 200cc XLarge Sport            9  1790.00\n",
      "178            Apple LED iMac MB953LL/A 27-Inch Desktop            9  1999.99\n",
      "179            Apple LED iMac MB953LL/A 27-Inch Desktop            9  2099.00\n",
      "189        Apple MacBook Air MC234LL/A 13.3-Inch Laptop            9  1799.00\n",
      "197                         Apple MacBook Pro MB470LL/A            9  1999.00\n",
      "203        Apple MacBook Pro MB991LL/A 13.3-Inch Laptop            9  1799.00\n",
      "204        Apple Macbook Air 1.6GHz Core 2 Duo Notebook            9  1799.00\n",
      "209                Apple iMac MB419LL/A 24-Inch Desktop            9  1799.00\n",
      "428   Canon Digital SLR Camera Kit-EOS 50D + EF-S 18...            9  2099.97\n",
      "593             Dell Adamo Admire 13.4\" Notebook (Onyx)            9  1999.00\n",
      "737      Gaggia Platinum Vision 90950  Espresso Machine            9  2099.00\n",
      "857       HP Pavilion HDX18-1020US 18.4\" Laptop (Vista)            9  2101.00\n",
      "858           HP Pavilion HDX18-1180US 18.4-Inch Laptop            9  1899.99\n",
      "859           HP Pavilion HDX18-1180US 18.4-Inch Laptop            9  2287.00\n",
      "1164       LG 47LH90 47-Inch 1080p LED Backlit LCD HDTV            9  2087.97\n",
      "1165       LG 47LH90 47-Inch 1080p LED Backlit LCD HDTV            9  2199.95\n",
      "1171      LG 50PS80 50-Inch 1080p Plasma Broadband HDTV            9  1999.95\n",
      "1192                          Lance Milan 150cc Scooter            9  2099.99\n",
      "1769         Saeco S-TT-ST Talea Touch Espresso Machine            9  2099.99\n",
      "1784         Samsung 61-Inch 1080p LED Powered DLP HDTV            9  1899.99\n",
      "1793    Samsung HL61A750 61\" 1080p LED Powered DLP HDTV            9  1899.99\n",
      "1814                Samsung LN37A550 37\" 1080p LCD HDTV            9  1999.99\n",
      "1822      Samsung LN40A650 40-Inch 1080p 120Hz LCD HDTV            9  1899.99\n",
      "1823                        Samsung LN40A750 40\" LCD TV            9  1899.99\n",
      "1827      Samsung LN40B750 40-Inch 1080p 240Hz LCD HDTV            9  1999.99\n",
      "1830                        Samsung LN46A650 46\" LCD TV            9  2099.99\n",
      "1831      Samsung LN46A650 46-Inch 1080p 120Hz LCD HDTV            9  2199.99\n",
      "1888     Samsung UN40B6000 40-Inch 1080p 120Hz LED HDTV            9  2199.99\n",
      "1891           Samsung UN46B6000 46-Inch 1080p LED HDTV            9  1849.00\n",
      "1977   Sony BRAVIA KDL-40Z5100 40\" 1080p 240Hz LCD HDTV            9  2199.99\n",
      "1992      Sony Bravia KDL-40XBR9 40\" 1080p 240Hz LCD TV            9  2299.99\n",
      "1996   Sony Bravia KDL-46V5100 46\" 1080p 120Hz LCD HDTV            9  1799.99\n",
      "2000  Sony Bravia W-Series KDL-40W4100 40\" 1080p LCD TV            9  1899.99\n",
      "2001    Sony Bravia Z-Series KDL-46Z4100/S 46\" LCD HDTV            9  2199.99\n",
      "2063                      Sony VAIO VGN-AW120J/H Laptop            9  1799.99\n",
      "2064        Sony VAIO VGN-AW125J/H 18.4\" Laptop (Vista)            9  1813.30\n",
      "2235      Toshiba REGZA 46SV670U 46-Inch 1080p LCD HDTV            9  1766.19\n",
      "2237  Toshiba REGZA Cinema Series 46XV545U 46\" LCD HDTV            9  1899.99\n",
      "2241          Toshiba Regza 40XF550U 40\" 1080p LCD HDTV            9  1999.99\n",
      "                                                desc  cat_cluster   retail\n",
      "429          Canon EOS 50D 15.1MP Digital SLR Camera            6  2600.00\n",
      "870        HP TouchSmart IQ816 All-in-One Desktop PC            6  2479.00\n",
      "936                            InFocus X10 Projector            6  2622.99\n",
      "1383   Mitsubishi HC5500 Full HD 1080P LCD Projector            6  2499.99\n",
      "1384                    Mitsubishi WD-73735 73\" HDTV            6  2999.99\n",
      "1385      Mitsubishi WD-73736 73-Inch 1080p DLP HDTV            6  2799.00\n",
      "1770      Saeco S-TT-ST Talea Touch Espresso Machine            6  2400.00\n",
      "1794    Samsung HL72A650 72-Inch 1080p Slim DLP HDTV            6  2799.99\n",
      "1890  Samsung UN40B7000 40-Inch 1080p 120Hz LED HDTV            6  2499.99\n",
      "1892        Samsung UN46B6000 46-Inch 1080p LED HDTV            6  2799.99\n"
     ]
    }
   ],
   "source": [
    "productDescriptionToVector={}\n",
    "for item in outcomesDf['desc'].unique():\n",
    "    #Word2Vec vector obtained for each product description\n",
    "    productDescriptionToVector[item] = productDescriptionToVectorDf[item]\n",
    "    \n",
    "#DataFrame containing unique combinations of the columns \"desc\" and \"retail\" (the same product\n",
    "#is auctioned more than once over time, and sometimes it is associated to a different retail price)\n",
    "descAndRetailPricesCombinations = outcomesDf.groupby(['desc','retail']).size().reset_index()\n",
    "descAndRetailPricesCombinations = descAndRetailPricesCombinations.drop(0,axis=1)\n",
    "    \n",
    "#robust scaler\n",
    "scaler = preprocessing.RobustScaler(quantile_range=(0, 75.0))\n",
    "retail_std = scaler.fit_transform(pd.DataFrame(descAndRetailPricesCombinations['retail']))\n",
    "#Google's pre-trained Word2Vec model vector length is 300 features.\n",
    "#Since the 300 features are given as input for the clustering, and the\n",
    "#retail price has been scaled,the retail price is multiplied by 300\n",
    "#so that it has the same importance for the clustering as the\n",
    "#300 vector features altogether.\n",
    "descAndRetailPricesCombinations['retail_std'] = retail_std*300\n",
    "    \n",
    "productVectorColumnValuesAndRetail = []\n",
    "for index, row in descAndRetailPricesCombinations.iterrows():\n",
    "    #iteration through each unique combination of the columns \"desc\" and \"retail\"\n",
    "    productDescription=row['desc']\n",
    "    auctionProductVector = np.array(productDescriptionToVector[productDescription])\n",
    "    #the Word2Vec vector for the product description and the retail price will be given\n",
    "    #as input for the clustering\n",
    "    productVectorColumnValuesAndRetail.append(np.append(auctionProductVector,row['retail_std']))\n",
    "    \n",
    "km = KMeans(n_clusters=10,random_state=2)\n",
    "#clustering with the Word2Vec vectors and retail prices given as input\n",
    "km.fit(productVectorColumnValuesAndRetail)\n",
    "clusters = km.labels_.tolist()\n",
    "descAndRetailPricesCombinations['cat_cluster'] = clusters\n",
    "\n",
    "for catCluster in descAndRetailPricesCombinations['cat_cluster'].unique():\n",
    "    print(descAndRetailPricesCombinations[descAndRetailPricesCombinations['cat_cluster'] == catCluster][['desc','cat_cluster','retail']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way as in the previous set of models, the following lines of code calculate the metrics associated to each one of the prediction models using 5-fold cross-validation. During the training part, the retail prices are scaled and the K-Means algorithm is used to obtain clusters for the unique combinations of word embedding vectors and scaled retail prices.\n",
    "\n",
    "Once that each different item has been assigned a cluster, a one-hot encoded version of the corresponding cluster numbers is added to the training data. The input variables for the prediction models are the retail price of the item, the bid increment, the bid fee, the flags that indicate the type of auction, and the one-hot encoded cluster identifier.\n",
    "\n",
    "During the test part, the retail prices of the unique combinations of product descriptions and retail prices have to be scaled too. The same scaler instance obtained during the training part is used on the test data to transform it in the same way (with the statistics calculated for the samples in the training set). Then, the nearest cluster obtained during the training part is assigned to each row in the test data. Once that each different row has been assigned a cluster, a one-hot encoded version of the corresponding cluster identifiers is added to the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean absolute error and the median absolute error (as the average of the results obtained for these two metrics over the 5 cross-validation folds) is then calculated for each prediction model. The results are analyzed after the lines of code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "--\n",
      "Random Forest Regressor\n",
      "Median absolute error: 11.1213084905\n",
      "Mean absolute error: 32.5591795213\n",
      "--\n",
      "K Neighbors Regressor\n",
      "Median absolute error: 11.6736\n",
      "Mean absolute error: 31.6176039332\n",
      "--\n",
      "Decision Tree Regressor\n",
      "Median absolute error: 10.9829866069\n",
      "Mean absolute error: 35.8479446051\n",
      "--\n",
      "Linear Regression\n",
      "Median absolute error: 88.90648655\n",
      "Mean absolute error: 146.484095711\n",
      "--\n",
      "RANSAC Regressor\n",
      "Median absolute error: 38.3213749265\n",
      "Mean absolute error: 63.4435851497\n"
     ]
    }
   ],
   "source": [
    "kFoldMedianAbsoluteErrorsRandomForestRegressor = []\n",
    "kFoldMedianAbsoluteErrorsKNeighborsRegressor = []\n",
    "kFoldMedianAbsoluteErrorsDecisionTreeRegressor = []\n",
    "kFoldMedianAbsoluteErrorsLinearRegression = []\n",
    "kFoldMedianAbsoluteErrorsRANSACRegressor = []\n",
    "\n",
    "kFoldMeanAbsoluteErrorsRandomForestRegressor = []\n",
    "kFoldMeanAbsoluteErrorsKNeighborsRegressor = []\n",
    "kFoldMeanAbsoluteErrorsDecisionTreeRegressor = []\n",
    "kFoldMeanAbsoluteErrorsLinearRegression = []\n",
    "kFoldMeanAbsoluteErrorsRANSACRegressor = []\n",
    "\n",
    "kFoldNumber = 1\n",
    "kf = KFold(n_splits=5, random_state=1)\n",
    "for train_index, test_index in kf.split(outcomesDf):\n",
    "    #5-fold cross-validation\n",
    "    print(\"Executing k fold = \"+str(kFoldNumber))\n",
    "    kFoldNumber=kFoldNumber+1\n",
    "    \n",
    "    #train and test split\n",
    "    outcomesDf_train, outcomesDf_test = outcomesDf.iloc[train_index], outcomesDf.iloc[test_index]   \n",
    "    \n",
    "    #TRAINING PART\n",
    "        \n",
    "    productDescriptionToVector={}\n",
    "    for item in outcomesDf['desc'].unique():\n",
    "        #Word2Vec vector obtained for each product description\n",
    "        productDescriptionToVector[item] = productDescriptionToVectorDf[item]\n",
    "    \n",
    "    #DataFrame containing unique combinations of the columns \"desc\" and \"retail\" (the same product\n",
    "    #is auctioned more than once over time, and sometimes it is associated to a different retail price)\n",
    "    descAndRetailPricesCombinationsTrain = outcomesDf_train.groupby(['desc','retail']).size().reset_index()\n",
    "    descAndRetailPricesCombinationsTrain = descAndRetailPricesCombinationsTrain.drop(0,axis=1)\n",
    "    \n",
    "    #robust scaler\n",
    "    scaler = preprocessing.RobustScaler(quantile_range=(0, 75.0))\n",
    "    retail_std = scaler.fit_transform(pd.DataFrame(descAndRetailPricesCombinationsTrain['retail']))\n",
    "    #Google's pre-trained Word2Vec model vector length is 300 features.\n",
    "    #Since the 300 features are given as input for the clustering, and the\n",
    "    #retail price has been scaled,the retail price is multiplied by 300\n",
    "    #so that it has the same importance for the clustering as the\n",
    "    #300 vector features altogether.\n",
    "    descAndRetailPricesCombinationsTrain['retail_std'] = retail_std*300\n",
    "    \n",
    "    productVectorColumnValuesAndRetail = []\n",
    "    for index, row in descAndRetailPricesCombinationsTrain.iterrows():\n",
    "        #iteration through each unique combination of the columns \"desc\" and \"retail\"\n",
    "        productDescription=row['desc']\n",
    "        auctionProductVector = np.array(productDescriptionToVector[productDescription])\n",
    "        #the Word2Vec vector for the product description and the retail price will be given\n",
    "        #as input for the clustering\n",
    "        productVectorColumnValuesAndRetail.append(np.append(auctionProductVector,row['retail_std']))\n",
    "    \n",
    "    km = KMeans(n_clusters=35,random_state=2)\n",
    "    #clustering with the Word2Vec vectors and retail prices given as input\n",
    "    km.fit(productVectorColumnValuesAndRetail)\n",
    "    clusters = km.labels_.tolist()\n",
    "    descAndRetailPricesCombinationsTrain['cat_cluster'] = clusters\n",
    "    \n",
    "    #One-Hot encoded version of the DataFrame containing a column for each cluster\n",
    "    clusteredCategoriesDfOneHotEnc = convertCategoryDataFrameToOneHotEncodedVersion(descAndRetailPricesCombinationsTrain,'cat_cluster')  \n",
    "    \n",
    "    #column names of the clusters\n",
    "    cluster_column_names = clusteredCategoriesDfOneHotEnc.columns.values\n",
    "    \n",
    "    descAndRetailPricesCombinationsTrain[clusteredCategoriesDfOneHotEnc.columns] = clusteredCategoriesDfOneHotEnc\n",
    "        \n",
    "    #the training dataset is merged so that it contains a one hot-encoded \n",
    "    #column for each one of the clusters obtained.\n",
    "    outcomesDfWithCatOneHot = outcomesDf_train.merge(descAndRetailPricesCombinationsTrain,how='left')\n",
    "    \n",
    "    normal_x_column_names = [\"retail\",\"bidincrement\",\"bidfee\",\"flg_click_only\",\"flg_beginnerauction\",\"flg_fixedprice\",\"flg_endprice\"]\n",
    "    #column names to be used in the prediction model: they include the columns corresponding to the clusters obtained.\n",
    "    column_names_with_clusters = np.concatenate([normal_x_column_names,cluster_column_names])\n",
    "    \n",
    "    #training phase variables\n",
    "    X_train = outcomesDfWithCatOneHot[column_names_with_clusters]\n",
    "    y_train = outcomesDfWithCatOneHot[\"price\"]\n",
    "    \n",
    "    #TEST PART\n",
    "    \n",
    "    #DataFrame containing unique combinations of the columns \"desc\" and \"retail\" (the same product\n",
    "    #is auctioned more than once over time, and sometimes it is associated to a different retail price)\n",
    "    descAndRetailPricesCombinationsTest = outcomesDf_test.groupby(['desc','retail']).size().reset_index()\n",
    "    descAndRetailPricesCombinationsTest = descAndRetailPricesCombinationsTest.drop(0,axis=1)\n",
    "    \n",
    "    #The scaler that is used in the test phase is the one that was obtained during the\n",
    "    #training phase.\n",
    "    #The same operations as in the training phase are performed.\n",
    "    retail_std = scaler.transform(pd.DataFrame(descAndRetailPricesCombinationsTest['retail']))\n",
    "    descAndRetailPricesCombinationsTest['retail_std'] = retail_std*300\n",
    "     \n",
    "    clusters = []\n",
    "    for index, row in descAndRetailPricesCombinationsTest.iterrows():\n",
    "        productDescription=row['desc']\n",
    "        auctionProductVector = np.array(productDescriptionToVector[productDescription])\n",
    "        productVectorColumnValuesAndRetail = np.append(auctionProductVector,row['retail_std'])\n",
    "        #The K-Means model obtained during the training phase is used to associate\n",
    "        #an existing cluster to each one of the combinations of product vectors and retail\n",
    "        #prices contained in the test data.   \n",
    "        clusterCategory = km.predict([productVectorColumnValuesAndRetail])\n",
    "        clusters.append(clusterCategory[0])\n",
    "        \n",
    "    descAndRetailPricesCombinationsTest['cat_cluster'] = clusters\n",
    "    \n",
    "    #One-Hot encoded version of the DataFrame containing a column for each cluster.\n",
    "    #The columns are the same ones as in the training phase\n",
    "    clusteredCategoriesDfOneHotEnc = convertCategoryDataFrameToOneHotEncodedVersion(descAndRetailPricesCombinationsTest,'cat_cluster',cluster_column_names)\n",
    "  \n",
    "    #column names of the clusters\n",
    "    cluster_column_names = clusteredCategoriesDfOneHotEnc.columns.values\n",
    "    \n",
    "    descAndRetailPricesCombinationsTest[clusteredCategoriesDfOneHotEnc.columns] = clusteredCategoriesDfOneHotEnc\n",
    "    \n",
    "    #the test dataset is merged so that it contains a one hot-encoded \n",
    "    #column for each one of the clusters obtained.\n",
    "    outcomesDfWithCatOneHot = outcomesDf_test.merge(descAndRetailPricesCombinationsTest,how='left')\n",
    "    \n",
    "    normal_x_column_names = [\"retail\",\"bidincrement\",\"bidfee\",\"flg_click_only\",\"flg_beginnerauction\",\"flg_fixedprice\",\"flg_endprice\"]\n",
    "    #column names to be used in the prediction model: they include the columns corresponding to the clusters obtained.\n",
    "    column_names_with_clusters = np.concatenate([normal_x_column_names,cluster_column_names])\n",
    "    \n",
    "    #test phase variables\n",
    "    X_test = outcomesDfWithCatOneHot[column_names_with_clusters]\n",
    "    y_test = outcomesDfWithCatOneHot[\"price\"]\n",
    "    \n",
    "    #Predictors\n",
    "    \n",
    "    #RandomForestRegressor\n",
    "    model=RandomForestRegressor(random_state=1)\n",
    "    model.fit(X_train,y_train)\n",
    "    P_price = model.predict(X_test)\n",
    "    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsRandomForestRegressor.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsRandomForestRegressor.append(kFoldMeanAbsoluteError)  \n",
    "\n",
    "    #KNeighborsRegressor\n",
    "    model = KNeighborsRegressor()\n",
    "    model.fit(X_train,y_train)\n",
    "    P_price = model.predict(X_test)\n",
    "    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsKNeighborsRegressor.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsKNeighborsRegressor.append(kFoldMeanAbsoluteError)  \n",
    "    \n",
    "    #DecisionTreeRegressor\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_train,y_train)\n",
    "    P_price = model.predict(X_test)\n",
    "    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsDecisionTreeRegressor.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsDecisionTreeRegressor.append(kFoldMeanAbsoluteError)  \n",
    "    \n",
    "    #LinearRegression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    P_price = model.predict(X_test)\n",
    "    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsLinearRegression.append(kFoldMedianAbsoluteError) \n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsLinearRegression.append(kFoldMeanAbsoluteError)  \n",
    "    \n",
    "    #RANSACRegressor\n",
    "    model = RANSACRegressor(random_state=1)\n",
    "    model.fit(X_train,y_train)\n",
    "    P_price = model.predict(X_test)\n",
    "    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsRANSACRegressor.append(kFoldMedianAbsoluteError) \n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsRANSACRegressor.append(kFoldMeanAbsoluteError)  \n",
    "    \n",
    "medianAbsoluteErrorsRandomForestRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsRandomForestRegressor)\n",
    "meanAbsoluteErrorsRandomForestRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsRandomForestRegressor)\n",
    "medianAbsoluteErrorsKNeighborsRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsKNeighborsRegressor)\n",
    "meanAbsoluteErrorsKNeighborsRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsKNeighborsRegressor)\n",
    "medianAbsoluteErrorsDecisionTreeRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsDecisionTreeRegressor)\n",
    "meanAbsoluteErrorsDecisionTreeRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsDecisionTreeRegressor)\n",
    "medianAbsoluteErrorsLinearRegressionAverage = np.mean(kFoldMedianAbsoluteErrorsLinearRegression)\n",
    "meanAbsoluteErrorsLinearRegressionAverage = np.mean(kFoldMeanAbsoluteErrorsLinearRegression)\n",
    "medianAbsoluteErrorsRANSACRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsRANSACRegressor)\n",
    "meanAbsoluteErrorsRANSACRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsRANSACRegressor)\n",
    "\n",
    "print(\"--\")\n",
    "print(\"Random Forest Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsRandomForestRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsRandomForestRegressorAverage))\n",
    "print(\"--\")\n",
    "print(\"K Neighbors Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsKNeighborsRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsKNeighborsRegressorAverage))\n",
    "print(\"--\")\n",
    "print(\"Decision Tree Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsDecisionTreeRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsDecisionTreeRegressorAverage))\n",
    "print(\"--\")\n",
    "print(\"Linear Regression\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsLinearRegressionAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsLinearRegressionAverage))\n",
    "print(\"--\")\n",
    "print(\"RANSAC Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsRANSACRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsRANSACRegressorAverage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen above, the model with the best results is the decision tree regressor. The random forest regressor and the the k-neighbors regressor perform slightly worse. Ultimately, the RANSAC regressor and the linear regression perform significantly worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the results are worse with this set of models as compared with the set of models explained in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of effort, this model requires several preprocessing steps: given the product description of an item in the column \"desc\", its Amazon category must be obtained, and afterwards, the corresponding word embedding vector. Moreover, the retail price of the item has to be scaled before making the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appart from the preprocessing steps, during the training part of the model, the clusters and the scaler instance are obtained, and they are later used everytime that a new prediction is made.  After some time, more and more new products will begin to be auctioned, which will not have been considered to form the clusters and to calculate the scaling values.  Because of this, the clusters and the scaler instance may eventually become outdated, and the models will perform worse. Therefore, appart from the preprocessing step, it is necessary to retrain the prediction models from time to time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the given dataset, this set of models is not interesting, since it is more complex and performs worse than some of the set of models explained in other sections. As the amount of data increases, it could be interesting to analyze the performance of this set of models again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e) Multiple models - Clustering by product categories and retail prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fith set of models that calculate clusters based on the product categories and retail prices has been built. The difference between this set of models and the previous one is that instead of using a single model for all items, a different prediction model is used for each different cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomesDf = pd.read_csv('./outcomes_clean.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "productDescriptionToVectorDf = pd.read_excel('./productDescriptionToVector.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way as in the previous set of models, the following lines of code calculate the metrics associated to each one of the prediction models using 5-fold cross-validation. During the training part, the K-Means algorithm is used to obtain clusters for the unique combinations of product descriptions and retail prices. Once that each different item in the training data has been assigned to a cluster, the training data is divided by cluster identifier. For each set of data belonging to the same cluster, a new set of prediction models is trained. The input variables the retail price of the item, the bid increment, the bid fee and the flags that indicate the type of auction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the test part, the nearest cluster is assigned to each row contained in the test data. Then, the corresponding set of models corresponding to that cluster is used to make the selling price prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean absolute error and the median absolute error (as the average of the results obtained for these two metrics over the 5 cross-validation folds) is then calculated for each prediction model contained in the different sets assigned to each cluster. For each type of prediction model (random forest regressor, decision tree regressor, etc), the mean absolute error and the median absolute error is calculated as the average of the results obtained for each one of the models (with the same type of prediction algorithm) corresponding to each different cluster. The results are analyzed after the lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "--\n",
      "Random Forest Regressor\n",
      "Median absolute error: 11.0684002025\n",
      "Mean absolute error: 29.3948295166\n",
      "--\n",
      "K Neighbors Regressor\n",
      "Median absolute error: 11.7728\n",
      "Mean absolute error: 32.707053489\n",
      "--\n",
      "Decision Tree Regressor\n",
      "Median absolute error: 11.0860943008\n",
      "Mean absolute error: 29.86973394\n",
      "--\n",
      "Linear Regression\n",
      "Median absolute error: 12.3694147353\n",
      "Mean absolute error: 32.0224389864\n",
      "--\n",
      "RANSAC Regressor\n",
      "Median absolute error: 10.6948726442\n",
      "Mean absolute error: 32.986749555\n"
     ]
    }
   ],
   "source": [
    "kFoldMedianAbsoluteErrorsRandomForestRegressor = []\n",
    "kFoldMedianAbsoluteErrorsKNeighborsRegressor = []\n",
    "kFoldMedianAbsoluteErrorsDecisionTreeRegressor = []\n",
    "kFoldMedianAbsoluteErrorsLinearRegression = []\n",
    "kFoldMedianAbsoluteErrorsRANSACRegressor = []\n",
    "\n",
    "kFoldMeanAbsoluteErrorsRandomForestRegressor = []\n",
    "kFoldMeanAbsoluteErrorsKNeighborsRegressor = []\n",
    "kFoldMeanAbsoluteErrorsDecisionTreeRegressor = []\n",
    "kFoldMeanAbsoluteErrorsLinearRegression = []\n",
    "kFoldMeanAbsoluteErrorsRANSACRegressor = []\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=1)\n",
    "kFoldNumber = 1\n",
    "for train_index, test_index in kf.split(outcomesDf):\n",
    "    #5-fold cross-validation\n",
    "    print(\"Executing k fold = \"+str(kFoldNumber))\n",
    "    kFoldNumber=kFoldNumber+1\n",
    "    \n",
    "    #train and test split\n",
    "    outcomesDf_train, outcomesDf_test = outcomesDf.iloc[train_index], outcomesDf.iloc[test_index]   \n",
    "    \n",
    "    #TRAINING PART\n",
    "    \n",
    "    productDescriptionToVector={}\n",
    "    for item in outcomesDf['desc'].unique():\n",
    "        #Word2Vec vector obtained for each product description\n",
    "        productDescriptionToVector[item] = productDescriptionToVectorDf[item]\n",
    "     \n",
    "    #DataFrame containing unique combinations of the columns \"desc\" and \"retail\" (the same product\n",
    "    #is auctioned more than once over time, and sometimes it is associated to a different retail price)\n",
    "    descAndRetailPricesCombinationsTrain = outcomesDf_train.groupby(['desc','retail']).size().reset_index()\n",
    "    descAndRetailPricesCombinationsTrain = descAndRetailPricesCombinationsTrain.drop(0,axis=1)\n",
    "    \n",
    "    #robust scaler\n",
    "    scaler = preprocessing.RobustScaler(quantile_range=(0, 75.0))\n",
    "    retail_std = scaler.fit_transform(pd.DataFrame(descAndRetailPricesCombinationsTrain['retail']))\n",
    "    \n",
    "    #Google's pre-trained Word2Vec model vector length is 300 features.\n",
    "    #Since the 300 features are given as input for the clustering, and the\n",
    "    #retail price has been scaled,the retail price is multiplied by 300\n",
    "    #so that it has the same importance for the clustering as the\n",
    "    #300 vector features altogether.\n",
    "    descAndRetailPricesCombinationsTrain['retail_std'] = retail_std*300\n",
    "       \n",
    "    productVectorColumnValuesAndRetail = []\n",
    "    for index, row in descAndRetailPricesCombinationsTrain.iterrows():\n",
    "        #iteration through each unique combination of the columns \"desc\" and \"retail\"\n",
    "        productDescription=row['desc']\n",
    "        auctionProductVector = np.array(productDescriptionToVector[productDescription])\n",
    "        #the Word2Vec vector for the product description and the retail price will be given\n",
    "        #as input for the clustering\n",
    "        productVectorColumnValuesAndRetail.append(np.append(auctionProductVector,row['retail_std']))\n",
    "    \n",
    "    km = KMeans(n_clusters=20,random_state=2)\n",
    "    #clustering with the Word2Vec vectors and retail prices given as input\n",
    "    km.fit(productVectorColumnValuesAndRetail)\n",
    "    clusters = km.labels_.tolist()\n",
    "    descAndRetailPricesCombinationsTrain['cat_cluster'] = clusters\n",
    "    #the training dataset is merged and now it contains a column with the cluster that\n",
    "    #each product belongs to.\n",
    "    outcomesDfTrainAndCatCluster = outcomesDf_train.merge(descAndRetailPricesCombinationsTrain,how='left')\n",
    "\n",
    "    clusterIndexToOutcomesDfTrain = {}\n",
    "    for cluster_index in outcomesDfTrainAndCatCluster['cat_cluster'].unique():\n",
    "        #the rows associated to each different cluster are stored in a dictionary,\n",
    "        #where the dictionary key is the cluster number\n",
    "        clusterIndexToOutcomesDfTrain[cluster_index] = outcomesDfTrainAndCatCluster[outcomesDfTrainAndCatCluster['cat_cluster'] == cluster_index]\n",
    "    \n",
    "    #dictionaries that contain a trained model for each one of the clusters\n",
    "    clusterIndexToRandomForestRegressor = {}\n",
    "    clusterIndexToKNeighborsRegressor = {}\n",
    "    clusterIndexToDecisionTreeRegressor = {}\n",
    "    clusterIndexToLinearRegression = {}\n",
    "    clusterIndexToRANSACRegressor = {}\n",
    "    \n",
    "    for cluster_index, outcomesDfClusterIndex in clusterIndexToOutcomesDfTrain.items():\n",
    "        #For each cluster, a different model is trained using\n",
    "        #the rows of the input dataset containing the products associated to that cluster\n",
    "        X_train = outcomesDfClusterIndex[[\"retail\",\"bidincrement\",\"bidfee\",\"flg_click_only\",\"flg_beginnerauction\",\"flg_fixedprice\",\"flg_endprice\"]].values\n",
    "        y_train = outcomesDfClusterIndex[\"price\"]\n",
    "        \n",
    "        #RandomForestRegressor\n",
    "        model=RandomForestRegressor(random_state=1)\n",
    "        model.fit(X_train,y_train)\n",
    "        clusterIndexToRandomForestRegressor[cluster_index] = model\n",
    "\n",
    "        #KNeighborsRegressor\n",
    "        n_neighbors=5\n",
    "        if outcomesDfClusterIndex.shape[0] < n_neighbors:\n",
    "            #In KNeighborsRegressor it is expected n_neighbors <= n_samples\n",
    "            n_neighbors = outcomesDfClusterIndex.shape[0]\n",
    "            \n",
    "        model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "        model.fit(X_train,y_train)\n",
    "        clusterIndexToKNeighborsRegressor[cluster_index] = model\n",
    "\n",
    "        #DecisionTreeRegressor\n",
    "        model = DecisionTreeRegressor()\n",
    "        model.fit(X_train,y_train)\n",
    "        clusterIndexToDecisionTreeRegressor[cluster_index] = model\n",
    "    \n",
    "        #LinearRegression\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train,y_train)\n",
    "        clusterIndexToLinearRegression[cluster_index] = model\n",
    "        \n",
    "        #RANSACRegressor\n",
    "        model = RANSACRegressor(random_state=1)\n",
    "        # assume linear model by default\n",
    "        min_samples = X_train.shape[1] + 1\n",
    "        if min_samples > X_train.shape[0]:\n",
    "            #min_samples may not be larger than number X_train.shape[0]\n",
    "            min_samples = X_train.shape[0]\n",
    "            model = RANSACRegressor(min_samples=min_samples,random_state=1)\n",
    "        try:\n",
    "            model.fit(X_train,y_train)\n",
    "            clusterIndexToRANSACRegressor[cluster_index] = model\n",
    "        except Exception as e: \n",
    "            continue\n",
    "        \n",
    "    #TEST PART\n",
    "    \n",
    "    #DataFrame containing unique combinations of the columns \"desc\" and \"retail\" (the same product\n",
    "    #is auctioned more than once over time, and sometimes it is associated to a different retail price)\n",
    "    descAndRetailPricesCombinationsTest = outcomesDf_test.groupby(['desc','retail']).size().reset_index()\n",
    "    descAndRetailPricesCombinationsTest = descAndRetailPricesCombinationsTest.drop(0,axis=1)\n",
    "    \n",
    "    #The scaler that is used in the test phase is the one that was obtained during the\n",
    "    #training phase.\n",
    "    #The same operations as in the training phase are performed.\n",
    "    retail_std = scaler.transform(pd.DataFrame(descAndRetailPricesCombinationsTest['retail']))\n",
    "    descAndRetailPricesCombinationsTest['retail_std'] = retail_std*300\n",
    "     \n",
    "    clusters = []\n",
    "    for index, row in descAndRetailPricesCombinationsTest.iterrows():\n",
    "        productDescription=row['desc']\n",
    "        auctionProductVector = np.array(productDescriptionToVector[productDescription])\n",
    "        productVectorColumnValuesAndRetail = np.append(auctionProductVector,row['retail_std'])\n",
    "        #The K-Means model obtained during the training phase is used to associate\n",
    "        #an existing cluster to each one of the combinations of product vectors and retail\n",
    "        #prices contained in the test data.   \n",
    "        clusterCategory = km.predict([productVectorColumnValuesAndRetail])\n",
    "        clusters.append(clusterCategory[0])\n",
    "        \n",
    "    descAndRetailPricesCombinationsTest['cat_cluster'] = clusters\n",
    "    #the test dataset is merged and now it contains a column with the cluster that\n",
    "    #each product belongs to.\n",
    "    outcomesDfTestAndCatCluster = outcomesDf_test.merge(descAndRetailPricesCombinationsTest,how='left')\n",
    "    \n",
    "    realAndPredictedValuesRandomForestRegressor = []\n",
    "    realAndPredictedValuesKNeighborsRegressor = []\n",
    "    realAndPredictedValuesDecisionTreeRegressor = []\n",
    "    realAndPredictedValuesLinearRegression = []\n",
    "    realAndPredictedValuesRANSACRegressor = []\n",
    "    \n",
    "    for index, row in outcomesDfTestAndCatCluster.iterrows():\n",
    "        #iteration through each row of the test dataset\n",
    "        \n",
    "        #real value of the column to be predicted\n",
    "        y_test_value = row[\"price\"]\n",
    "        #values given as input for the prediction model\n",
    "        x_test_value = row[[\"retail\",\"bidincrement\",\"bidfee\",\"flg_click_only\",\"flg_beginnerauction\",\"flg_fixedprice\",\"flg_endprice\"]].values\n",
    "        #product category cluster for this row of the dataset\n",
    "        clusterIndex = row[\"cat_cluster\"]\n",
    "\n",
    "        #the prediction models associated to this cluster are extracted\n",
    "        modelRandomForestRegressor = clusterIndexToRandomForestRegressor[clusterIndex]\n",
    "        modelKNeighborsRegressor = clusterIndexToKNeighborsRegressor[clusterIndex]\n",
    "        modelDecisionTreeRegressor = clusterIndexToDecisionTreeRegressor[clusterIndex]\n",
    "        modelLinearRegression = clusterIndexToLinearRegression[clusterIndex]\n",
    "        \n",
    "        realAndPredictedValuesRandomForestRegressor.append((y_test_value,modelRandomForestRegressor.predict([x_test_value])[0]))\n",
    "        realAndPredictedValuesKNeighborsRegressor.append((y_test_value,modelKNeighborsRegressor.predict([x_test_value])[0]))\n",
    "        realAndPredictedValuesDecisionTreeRegressor.append((y_test_value,modelDecisionTreeRegressor.predict([x_test_value])[0]))\n",
    "        realAndPredictedValuesLinearRegression.append((y_test_value,modelLinearRegression.predict([x_test_value])[0]))\n",
    "        \n",
    "        if clusterIndex not in clusterIndexToRANSACRegressor:\n",
    "            print(\"clusterIndex not in clusterIndexToRANSACRegressor\")\n",
    "            continue\n",
    "        modelRANSACRegressor = clusterIndexToRANSACRegressor[clusterIndex]\n",
    "        realAndPredictedValuesRANSACRegressor.append((y_test_value,modelRANSACRegressor.predict([x_test_value])[0]))\n",
    "    \n",
    "    #RandomForestRegressor\n",
    "    #all real and predicted values are extracted and the metrics are calculated\n",
    "    y_test, P_price = zip(*realAndPredictedValuesRandomForestRegressor)    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsRandomForestRegressor.append(kFoldMedianAbsoluteError) \n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsRandomForestRegressor.append(kFoldMeanAbsoluteError) \n",
    "    \n",
    "    #KNeighborsRegressor\n",
    "    #all real and predicted values are extracted and the metrics are calculated\n",
    "    y_test, P_price = zip(*realAndPredictedValuesKNeighborsRegressor)    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsKNeighborsRegressor.append(kFoldMedianAbsoluteError) \n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsKNeighborsRegressor.append(kFoldMeanAbsoluteError) \n",
    "    \n",
    "    #DecisionTreeRegressor\n",
    "    #all real and predicted values are extracted and the metrics are calculated\n",
    "    y_test, P_price = zip(*realAndPredictedValuesDecisionTreeRegressor)    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsDecisionTreeRegressor.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsDecisionTreeRegressor.append(kFoldMeanAbsoluteError) \n",
    "    \n",
    "    #LinearRegression\n",
    "    #all real and predicted values are extracted and the metrics are calculated\n",
    "    y_test, P_price = zip(*realAndPredictedValuesLinearRegression)    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsLinearRegression.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsLinearRegression.append(kFoldMeanAbsoluteError) \n",
    "    \n",
    "    #RANSACRegressor\n",
    "    #all real and predicted values are extracted and the metrics are calculated\n",
    "    y_test, P_price = zip(*realAndPredictedValuesRANSACRegressor)    \n",
    "    kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "    kFoldMedianAbsoluteErrorsRANSACRegressor.append(kFoldMedianAbsoluteError)\n",
    "    kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "    kFoldMeanAbsoluteErrorsRANSACRegressor.append(kFoldMeanAbsoluteError) \n",
    "    \n",
    "medianAbsoluteErrorsRandomForestRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsRandomForestRegressor)\n",
    "meanAbsoluteErrorsRandomForestRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsRandomForestRegressor)\n",
    "medianAbsoluteErrorsKNeighborsRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsKNeighborsRegressor)\n",
    "meanAbsoluteErrorsKNeighborsRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsKNeighborsRegressor)\n",
    "medianAbsoluteErrorsDecisionTreeRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsDecisionTreeRegressor)\n",
    "meanAbsoluteErrorsDecisionTreeRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsDecisionTreeRegressor)\n",
    "medianAbsoluteErrorsLinearRegressionAverage = np.mean(kFoldMedianAbsoluteErrorsLinearRegression)\n",
    "meanAbsoluteErrorsLinearRegressionAverage = np.mean(kFoldMeanAbsoluteErrorsLinearRegression)\n",
    "medianAbsoluteErrorsRANSACRegressorAverage = np.mean(kFoldMedianAbsoluteErrorsRANSACRegressor)\n",
    "meanAbsoluteErrorsRANSACRegressorAverage = np.mean(kFoldMeanAbsoluteErrorsRANSACRegressor)\n",
    "\n",
    "print(\"--\")\n",
    "print(\"Random Forest Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsRandomForestRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsRandomForestRegressorAverage))\n",
    "print(\"--\")\n",
    "print(\"K Neighbors Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsKNeighborsRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsKNeighborsRegressorAverage))\n",
    "print(\"--\")\n",
    "print(\"Decision Tree Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsDecisionTreeRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsDecisionTreeRegressorAverage))\n",
    "print(\"--\")\n",
    "print(\"Linear Regression\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsLinearRegressionAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsLinearRegressionAverage))\n",
    "print(\"--\")\n",
    "print(\"RANSAC Regressor\")\n",
    "print(\"Median absolute error: \"+str(medianAbsoluteErrorsRANSACRegressorAverage))\n",
    "print(\"Mean absolute error: \"+str(meanAbsoluteErrorsRANSACRegressorAverage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen above, the model with the best results in terms of the median absolute error is the RANSAC regressor, while the model with the best results in terms of the mean absolute error is the random forest regressor. The results for the decision tree regressor are very similar to the ones obtained with the random forest regressor. The k-neighbors regressor results are, although worse, very similar too. The worst results are obtained with the linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the results obtained with this set of models are worse than the the results obtained with the set of models in other sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of effort, this model requires several preprocessing steps: given the product description of an item in the column \"desc\", its Amazon category must be obtained, and afterwards, the corresponding word embedding vector. Moreover, the retail price of the item has to be scaled before making the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appart from the preprocessing steps, during the training part of the model, the clusters and the scaler instance are obtained, and they are later used everytime that a new prediction is made.  After some time, more and more new products will begin to be auctioned, which will not have been considered to form the clusters and to calculate the scaling values.  Because of this, the clusters and the scaler instance may eventually become outdated, and the models will perform worse. Therefore, appart from the preprocessing step, it is necessary to retrain the prediction models from time to time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As compared with the previous section in which a single model is used, the results obtained with multiple models in this section are better, but when retraining is necessary, multipled models have to be retrained instead of just one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the given dataset, this set of models is not interesting, since it is more complex and performs worse than some of the set of models explained in other sections. As the amount of data increases, it could be interesting to analyze the performance of this set of models again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing and optimizing the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the different models have been analyzed in the above sections. An important remark is that the chosen values for the different variables used in each section have an impact on the results. These variables include: the input parameters of the prediction model algorithms, the number of folds used for the k-fold cross-validation, the number of clusters given as input for the K-Means algorithm for the models that depend on clustering of the data, the input parameters for the scaler algorithm for the models that depend on scaling the input data, etc. \n",
    "\n",
    "All of these variables should ideally be opmitized according to the metric that defines the quality of the prediction model (for example, using the GridSearchCV function available in the sklearn library). This requires a lot of time, since there are a lot of possible combinations for all parameter values. For the input parameters of the prediction models, the default parameter values have been used in the results calculated above, except for the random state that has been set to the same value everytime. The number of clusters for the the K-Means algorithm has been manually modified to find the number of clusters that optimizes the result for the values that have been tried."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the random forest regressor and the decision tree regressor are the algorithms that normally provide the best results. These two models are relatively robust to outliers, since they isolate atypical observations into small leaves. The random forest regressor generally performs a bit better than the decision tree regressor and is less likely to overfit the data. The disadvantage is that random forest regressor are more difficult to interpret than decision tree regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two different clustering options have been analyzed: one that uses the word embedding vectors to cluster the items according to their product categories, and another one that, appart from the word embedding vectors, it also uses the retail prices of the items to obtain the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the available data, the model that obtains the clusters by only using as input the word embedding vectors performs better. Moreover, it also requires less preprocessing steps and having to retrain the model less often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained with the models that take into account the product categories are better than the ones obtained with the models that do not take them into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nevertheless, taking into account the product categories requires a bigger effort, since a preprocessing step is necessary to make a new prediction: given the product description of an item in the column \"desc\", its Amazon category must be obtained, and afterwards, the corresponding word embedding vector.\n",
    "\n",
    "Furthermore, the clusters product category clusters obtained during the trianing part of the model are the ones that are used each time that a new prediction is made. After some time, more and more new products will begin to be auctioned and the clusters may eventually become outdated, causing the model to perform worse. Therefore, appart from the preprocessing step, using the product categories also involves having to retrain the prediction model from time to time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the models that take only take into account the word embedding vectors to form the clusters, two different versions have been analyzed: one consisting on a single prediction model and another one that consists on a set of different models, where the model chosen to make every prediction depends on the cluster that each row in the test data belongs to.\n",
    "\n",
    "The results obtained with the set of multiple models were slightly better than the ones obtained when using a single model. Nevertheless, one of the prediction models corresponding to a certain cluster might perform much worse than the others. \n",
    "\n",
    "Also, in both versions, the clusters will eventually become outdated, and when a retraining is necessary, a single prediction model will have to be retrained in one of the versions, while in the other one, as many prediction models as existing clusters will have to be retrained. Considering this disadvantage, as well as the bigger complexity that using a set of multiple models implies, and the fact that the results are fairly similar for both versions, it has been decided to choose the version consisting on a single prediction model as the final one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the final chosen set of models is the one explained in section \"b) One Model - Having into account the categories\". Of the different prediction algorithms used in that section, the one with the best results is the random forest regressor. This is the one that has been implemented as the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables that have a clear impact on the results for this model are: the number of clusters chosen for the K-Means clustering algorithm, as well as the input parameters for the random forest regressor. A grid of different values for the number of clusters and the number of trees used in the random forest algorithm has been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomesDf = pd.read_csv('./outcomes_clean.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "productDescriptionToVectorDf = pd.read_excel('./productDescriptionToVector.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing grid combination 1 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 2 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 3 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 4 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 5 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 6 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 7 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 8 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 9 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 10 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 11 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 12 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 13 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 14 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 15 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 16 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 17 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 18 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 19 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 20 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 21 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 22 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 23 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 24 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 25 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 26 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 27 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 28 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 29 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n",
      "Executing grid combination 30 out of 30 combinations\n",
      "Executing k fold = 1\n",
      "Executing k fold = 2\n",
      "Executing k fold = 3\n",
      "Executing k fold = 4\n",
      "Executing k fold = 5\n"
     ]
    }
   ],
   "source": [
    "kFoldMedianAbsoluteErrorsRandomForestRegressor = {}\n",
    "kFoldMeanAbsoluteErrorsRandomForestRegressor = {}\n",
    "\n",
    "nClusterGrid = [10,12,13,14,15,16,17,18,19,20,21,22,23,24,25]\n",
    "#nClusterGrid = [15]\n",
    "nEstimatorsGrid=[10,15]\n",
    "\n",
    "gridTotalCombinations = len(nClusterGrid)*len(nEstimatorsGrid)\n",
    "gridCombinationNumber = 1\n",
    "\n",
    "for nClustersGridValue in nClusterGrid:\n",
    "    for nEstimatorsGridValue in nEstimatorsGrid:\n",
    "        gridCombinationString = str(nClustersGridValue)+\"-\"+str(nEstimatorsGridValue)\n",
    "        print(\"Executing grid combination \"+str(gridCombinationNumber)+\" out of \"+str(gridTotalCombinations)+\" combinations\")\n",
    "        gridCombinationNumber=gridCombinationNumber+1\n",
    "\n",
    "        kFoldNumber = 1\n",
    "        kf = KFold(n_splits=5, random_state=1)\n",
    "        for train_index, test_index in kf.split(outcomesDf):\n",
    "            #5-fold cross-validation\n",
    "            print(\"Executing k fold = \"+str(kFoldNumber))\n",
    "            kFoldNumber=kFoldNumber+1\n",
    "\n",
    "            #train and test split\n",
    "            outcomesDf_train, outcomesDf_test = outcomesDf.iloc[train_index], outcomesDf.iloc[test_index]   \n",
    "\n",
    "            #TRAINING PART\n",
    "\n",
    "            #Unique product descriptions present in the training dataset\n",
    "            productDescriptionTrain = outcomesDf_train['desc'].unique()\n",
    "\n",
    "            productDescriptionToVector={}\n",
    "            for item in productDescriptionTrain:\n",
    "                #Word2Vec vector obtained for each product description\n",
    "                productDescriptionToVector[item] = productDescriptionToVectorDf[item]\n",
    "\n",
    "            productVectors = list(productDescriptionToVector.values())\n",
    "\n",
    "            km = KMeans(n_clusters=nClustersGridValue,random_state=2)\n",
    "            #the clustering is performed with the Word2Vec vectors for the product categories given as input\n",
    "            km.fit(productVectors)\n",
    "            clusters = km.labels_.tolist()\n",
    "            #DataFrame containing columns for the product description and the category cluster that it is associated to\n",
    "            clusteredCategoriesDf = pd.DataFrame({'desc': list(productDescriptionToVector.keys()), 'cat_cluster': clusters})\n",
    "            #One-Hot encoded version of the DataFrame containing a column for each cluster\n",
    "            clusteredCategoriesDfOneHotEnc = convertCategoryDataFrameToOneHotEncodedVersion(clusteredCategoriesDf,'cat_cluster')  \n",
    "            #column names of the clusters\n",
    "            cluster_column_names = clusteredCategoriesDfOneHotEnc.columns.values\n",
    "            clusteredCategoriesDfOneHotEnc['desc'] = clusteredCategoriesDf['desc']\n",
    "            #the training dataset is merged so that it contains a one hot-encoded \n",
    "            #column for each one of the clusters obtained.\n",
    "            outcomesDfWithCatOneHot = outcomesDf_train.merge(clusteredCategoriesDfOneHotEnc,how='left')\n",
    "            normal_x_column_names = [\"retail\",\"bidincrement\",\"bidfee\",\"flg_click_only\",\"flg_beginnerauction\",\"flg_fixedprice\",\"flg_endprice\"]\n",
    "            #column names to be used in the prediction model: they include the columns corresponding to the clusters obtained.\n",
    "            column_names_with_clusters = np.concatenate([normal_x_column_names,cluster_column_names])\n",
    "\n",
    "            #training phase variables\n",
    "            X_train = outcomesDfWithCatOneHot[column_names_with_clusters]\n",
    "            y_train = outcomesDfWithCatOneHot[\"price\"]\n",
    "\n",
    "            #TEST PART\n",
    "\n",
    "            #Unique product descriptions present in the training dataset\n",
    "            productDescriptionTest = outcomesDf_test['desc'].unique()\n",
    "\n",
    "            productDescriptionToVector={}\n",
    "            for item in productDescriptionTest:\n",
    "                #Word2Vec vector obtained for each product description\n",
    "                productDescriptionToVector[item] = productDescriptionToVectorDf[item]\n",
    "\n",
    "            productDescriptionToTrainCluster = {}\n",
    "            for productDescription, vector in productDescriptionToVector.items():\n",
    "                #The K-Means model obtained during the training phase is used to associate\n",
    "                #an existing cluster to each one of the product vectors contained in the test data.\n",
    "                clusterCategory = km.predict([vector])\n",
    "                productDescriptionToTrainCluster[productDescription] = clusterCategory[0]\n",
    "\n",
    "            #DataFrame containing columns for the product description and the category cluster that it is associated to\n",
    "            clusteredCategoriesDf = pd.DataFrame(list(productDescriptionToTrainCluster.items()), columns=['desc', 'cat_cluster'])\n",
    "            #One-Hot encoded version of the DataFrame containing a column for each cluster.\n",
    "            #The columns are the same ones as in the training phase\n",
    "            clusteredCategoriesDfOneHotEnc = convertCategoryDataFrameToOneHotEncodedVersion(clusteredCategoriesDf,'cat_cluster',cluster_column_names)\n",
    "            #column names of the clusters\n",
    "            cluster_column_names = clusteredCategoriesDfOneHotEnc.columns.values\n",
    "            clusteredCategoriesDfOneHotEnc['desc'] = clusteredCategoriesDf['desc']\n",
    "            #the test dataset is merged so that it contains a one hot-encoded \n",
    "            #column for each one of the clusters obtained.\n",
    "            outcomesDfWithCatOneHot = outcomesDf_test.merge(clusteredCategoriesDfOneHotEnc,how='left')\n",
    "            normal_x_column_names = [\"retail\",\"bidincrement\",\"bidfee\",\"flg_click_only\",\"flg_beginnerauction\",\"flg_fixedprice\",\"flg_endprice\"]\n",
    "            #column names to be used in the prediction model: they include the columns corresponding to the clusters obtained.\n",
    "            column_names_with_clusters = np.concatenate([normal_x_column_names,cluster_column_names])\n",
    "\n",
    "            #test phase variables\n",
    "            X_test = outcomesDfWithCatOneHot[column_names_with_clusters]\n",
    "            y_test = outcomesDfWithCatOneHot[\"price\"]\n",
    "\n",
    "            #Predictors\n",
    "\n",
    "            #RandomForestRegressor\n",
    "            model=RandomForestRegressor(random_state=1, n_estimators=nEstimatorsGridValue)\n",
    "            model.fit(X_train,y_train)\n",
    "            P_price = model.predict(X_test)\n",
    "\n",
    "            kFoldMedianAbsoluteError = median_absolute_error(y_test,P_price)\n",
    "            if gridCombinationString not in kFoldMedianAbsoluteErrorsRandomForestRegressor:\n",
    "                kFoldMedianAbsoluteErrorsRandomForestRegressor[gridCombinationString] = []\n",
    "            kFoldMedianAbsoluteErrorsRandomForestRegressor[gridCombinationString].append(kFoldMedianAbsoluteError)               \n",
    "            \n",
    "            kFoldMeanAbsoluteError = mean_absolute_error(y_test,P_price)\n",
    "            if gridCombinationString not in kFoldMeanAbsoluteErrorsRandomForestRegressor:\n",
    "                kFoldMeanAbsoluteErrorsRandomForestRegressor[gridCombinationString] = []\n",
    "            kFoldMeanAbsoluteErrorsRandomForestRegressor[gridCombinationString].append(kFoldMeanAbsoluteError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N clusters = 10 ; N estimators = 10\n",
      "Median absolute error = 10.4600742337\n",
      "Mean absolute error   = 28.3928103559\n",
      "--\n",
      "N clusters = 10 ; N estimators = 15\n",
      "Median absolute error = 10.4541755616\n",
      "Mean absolute error   = 28.3287636468\n",
      "--\n",
      "N clusters = 12 ; N estimators = 10\n",
      "Median absolute error = 10.4121693664\n",
      "Mean absolute error   = 28.3481462479\n",
      "--\n",
      "N clusters = 12 ; N estimators = 15\n",
      "Median absolute error = 10.4060284261\n",
      "Mean absolute error   = 28.2630361398\n",
      "--\n",
      "N clusters = 13 ; N estimators = 10\n",
      "Median absolute error = 10.5492960772\n",
      "Mean absolute error   = 28.3659670918\n",
      "--\n",
      "N clusters = 13 ; N estimators = 15\n",
      "Median absolute error = 10.5536345395\n",
      "Mean absolute error   = 28.2897791786\n",
      "--\n",
      "N clusters = 14 ; N estimators = 10\n",
      "Median absolute error = 10.4384989764\n",
      "Mean absolute error   = 28.3397031232\n",
      "--\n",
      "N clusters = 14 ; N estimators = 15\n",
      "Median absolute error = 10.457491468\n",
      "Mean absolute error   = 28.2555242302\n",
      "--\n",
      "N clusters = 15 ; N estimators = 10\n",
      "Median absolute error = 10.5067559321\n",
      "Mean absolute error   = 28.6887268744\n",
      "--\n",
      "N clusters = 15 ; N estimators = 15\n",
      "Median absolute error = 10.5239521751\n",
      "Mean absolute error   = 28.6054910342\n",
      "--\n",
      "N clusters = 16 ; N estimators = 10\n",
      "Median absolute error = 10.4286437528\n",
      "Mean absolute error   = 28.2995682388\n",
      "--\n",
      "N clusters = 16 ; N estimators = 15\n",
      "Median absolute error = 10.4295892271\n",
      "Mean absolute error   = 28.2082201044\n",
      "--\n",
      "N clusters = 17 ; N estimators = 10\n",
      "Median absolute error = 10.4505840588\n",
      "Mean absolute error   = 28.3585533857\n",
      "--\n",
      "N clusters = 17 ; N estimators = 15\n",
      "Median absolute error = 10.4818799252\n",
      "Mean absolute error   = 28.3006732782\n",
      "--\n",
      "N clusters = 18 ; N estimators = 10\n",
      "Median absolute error = 10.3837651768\n",
      "Mean absolute error   = 28.3439120603\n",
      "--\n",
      "N clusters = 18 ; N estimators = 15\n",
      "Median absolute error = 10.3922842474\n",
      "Mean absolute error   = 28.2737346206\n",
      "--\n",
      "N clusters = 19 ; N estimators = 10\n",
      "Median absolute error = 10.5835055952\n",
      "Mean absolute error   = 28.5438549368\n",
      "--\n",
      "N clusters = 19 ; N estimators = 15\n",
      "Median absolute error = 10.5371342501\n",
      "Mean absolute error   = 28.4718779571\n",
      "--\n",
      "N clusters = 20 ; N estimators = 10\n",
      "Median absolute error = 10.3695943096\n",
      "Mean absolute error   = 28.2917930555\n",
      "--\n",
      "N clusters = 20 ; N estimators = 15\n",
      "Median absolute error = 10.3774828774\n",
      "Mean absolute error   = 28.2364238654\n",
      "--\n",
      "N clusters = 21 ; N estimators = 10\n",
      "Median absolute error = 10.923319363\n",
      "Mean absolute error   = 29.9601147561\n",
      "--\n",
      "N clusters = 21 ; N estimators = 15\n",
      "Median absolute error = 10.9759501202\n",
      "Mean absolute error   = 29.9218892957\n",
      "--\n",
      "N clusters = 22 ; N estimators = 10\n",
      "Median absolute error = 10.6002101174\n",
      "Mean absolute error   = 28.9395753549\n",
      "--\n",
      "N clusters = 22 ; N estimators = 15\n",
      "Median absolute error = 10.6107018596\n",
      "Mean absolute error   = 28.891882566\n",
      "--\n",
      "N clusters = 23 ; N estimators = 10\n",
      "Median absolute error = 10.9381481613\n",
      "Mean absolute error   = 30.2791487335\n",
      "--\n",
      "N clusters = 23 ; N estimators = 15\n",
      "Median absolute error = 10.9291463893\n",
      "Mean absolute error   = 30.2056939018\n",
      "--\n",
      "N clusters = 24 ; N estimators = 10\n",
      "Median absolute error = 10.3951699895\n",
      "Mean absolute error   = 28.3200529226\n",
      "--\n",
      "N clusters = 24 ; N estimators = 15\n",
      "Median absolute error = 10.4100309657\n",
      "Mean absolute error   = 28.2503207347\n",
      "--\n",
      "N clusters = 25 ; N estimators = 10\n",
      "Median absolute error = 10.4371148382\n",
      "Mean absolute error   = 28.4703631012\n",
      "--\n",
      "N clusters = 25 ; N estimators = 15\n",
      "Median absolute error = 10.4294678722\n",
      "Mean absolute error   = 28.3555403948\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "minMedianAbsoluteError = None\n",
    "minMedianAbsoluteErrorKey = None\n",
    "meanAbsoluteErrorWithMinMedianAbsoluteError = None\n",
    "\n",
    "\n",
    "minMeanAbsoluteError= None\n",
    "minMeanAbsoluteErrorKey = None\n",
    "medianAbsoluteErrorWithMinMeanAbsoluteError = None\n",
    "\n",
    "\n",
    "for key, value in kFoldMedianAbsoluteErrorsRandomForestRegressor.items():\n",
    "    nClustersGridValue = key[0:2]\n",
    "    nEstimatorsGridValue = key[-2:]\n",
    "    print(\"N clusters = \" + str(nClustersGridValue) + \" ; N estimators = \"+str(nEstimatorsGridValue))\n",
    "    \n",
    "    kFoldMedianAbsoluteErrorsRandomForestRegressorCurrentCombination = kFoldMedianAbsoluteErrorsRandomForestRegressor[key]\n",
    "    kFoldMeanAbsoluteErrorsRandomForestRegressorCurrentCombination = kFoldMeanAbsoluteErrorsRandomForestRegressor[key]    \n",
    "    \n",
    "    combinationMedianAbsoluteError = np.mean(kFoldMedianAbsoluteErrorsRandomForestRegressorCurrentCombination)\n",
    "    combinationMeanAbsoluteError = np.mean(kFoldMeanAbsoluteErrorsRandomForestRegressorCurrentCombination)\n",
    "    \n",
    "    if minMedianAbsoluteError is None:\n",
    "        minMedianAbsoluteError = combinationMedianAbsoluteError\n",
    "        minMedianAbsoluteErrorKey = key\n",
    "        meanAbsoluteErrorWithMinMedianAbsoluteError = combinationMeanAbsoluteError       \n",
    "    elif combinationMedianAbsoluteError < minMedianAbsoluteError:\n",
    "        minMedianAbsoluteError = combinationMedianAbsoluteError\n",
    "        minMedianAbsoluteErrorKey = key     \n",
    "        meanAbsoluteErrorWithMinMedianAbsoluteError = combinationMeanAbsoluteError\n",
    "            \n",
    "    if minMeanAbsoluteError is None:\n",
    "        minMeanAbsoluteError = combinationMeanAbsoluteError\n",
    "        minMeanAbsoluteErrorKey = key\n",
    "        medianAbsoluteErrorWithMinMeanAbsoluteError = combinationMedianAbsoluteError\n",
    "    elif combinationMeanAbsoluteError < minMeanAbsoluteError:\n",
    "        minMeanAbsoluteError = combinationMeanAbsoluteError\n",
    "        minMeanAbsoluteErrorKey = key\n",
    "        medianAbsoluteErrorWithMinMeanAbsoluteError = combinationMedianAbsoluteError\n",
    "    \n",
    "    print(\"Median absolute error = \" + str(combinationMedianAbsoluteError))\n",
    "    print(\"Mean absolute error   = \" + str(combinationMeanAbsoluteError))\n",
    "      \n",
    "    print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal median absolute error is 10.3695943096 with 20 clusters and 10 estimators.\n",
      "With this combination the mean absolute error is 28.2917930555\n",
      "---\n",
      "The optimal median absolute error is 28.2082201044 with 16 clusters and 15 estimators.\n",
      "With this combination the median absolute error is 10.4295892271\n"
     ]
    }
   ],
   "source": [
    "minMedianAbsoluteErrorNClustersGridValue = minMedianAbsoluteErrorKey[0:2]\n",
    "minMedianAbsoluteErrorNEstimatorsGridValue = minMedianAbsoluteErrorKey[-2:]\n",
    "\n",
    "print('The optimal median absolute error is ' + str(minMedianAbsoluteError) + \" with \" + str(minMedianAbsoluteErrorNClustersGridValue) + \" clusters and \" + str(minMedianAbsoluteErrorNEstimatorsGridValue) + \" estimators.\")\n",
    "print('With this combination the mean absolute error is '+str(meanAbsoluteErrorWithMinMedianAbsoluteError))\n",
    "minMeanAbsoluteErrorNClustersGridValue = minMeanAbsoluteErrorKey[0:2]\n",
    "minMeanAbsoluteErrorNEstimatorsGridValue = minMeanAbsoluteErrorKey[-2:]\n",
    "print(\"---\")\n",
    "print('The optimal median absolute error is ' + str(minMeanAbsoluteError) +\" with \" + str(minMeanAbsoluteErrorNClustersGridValue) +\" clusters and \" + str(minMeanAbsoluteErrorNEstimatorsGridValue) + \" estimators.\")\n",
    "print('With this combination the median absolute error is '+str(medianAbsoluteErrorWithMinMeanAbsoluteError))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it has been mentioned at the beginning of this document when the metrics have been introduced, the median absolute error is considered to be more important for auction selling price predictions. Therefore, the optimal parameters and the final metric results are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen set of models : b) One Model - Having into account the categories\n",
      "Chosen model : Random forest regressor\n",
      "K-Means -> N clusters = 20\n",
      "Random forest regressor -> N estimators  = 10\n",
      "Median absolute error = 10.3695943096\n",
      "Mean absolute error = 28.2917930555\n"
     ]
    }
   ],
   "source": [
    "print(\"Chosen set of models : \"+\"b) One Model - Having into account the categories\")\n",
    "print(\"Chosen model : \"+\"Random forest regressor\")\n",
    "print(\"K-Means -> N clusters = \"+str(minMedianAbsoluteErrorNClustersGridValue))\n",
    "print(\"Random forest regressor -> N estimators  = \"+str(minMedianAbsoluteErrorNEstimatorsGridValue))\n",
    "print(\"Median absolute error = \"+str( minMedianAbsoluteError))\n",
    "print(\"Mean absolute error = \"+str(meanAbsoluteErrorWithMinMedianAbsoluteError))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
